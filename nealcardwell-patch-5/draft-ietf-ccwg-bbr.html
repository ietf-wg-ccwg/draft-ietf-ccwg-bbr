<!DOCTYPE html>
<html lang="en" class="Internet-Draft">
<head>
<meta charset="utf-8">
<meta content="Common,Latin" name="scripts">
<meta content="initial-scale=1.0" name="viewport">
<title>BBR Congestion Control</title>
<meta content="Neal Cardwell" name="author">
<meta content="Ian Swett" name="author">
<meta content="Joseph Beshay" name="author">
<meta content="
       This document specifies the BBR congestion control algorithm. BBR (&quot;Bottleneck
Bandwidth and Round-trip propagation time&quot;) uses recent measurements of a
transport connection's delivery rate, round-trip time, and packet loss rate
to build an explicit model of the network path. BBR then uses this model to
control both how fast it sends data and the maximum volume of data it allows
in flight in the network at any time. Relative to loss-based congestion control
algorithms such as Reno   or CUBIC  , BBR offers
substantially higher throughput for bottlenecks
with shallow buffers or random losses, and substantially lower queueing delays
for bottlenecks with deep buffers (avoiding &quot;bufferbloat&quot;). BBR can be
implemented in any transport protocol that supports packet-delivery
acknowledgment. Thus far, open source implementations are available
for TCP   and QUIC  . This document
specifies version 3 of the BBR algorithm, BBRv3. 
    " name="description">
<meta content="xml2rfc 3.30.0" name="generator">
<meta content="Congestion Control" name="keyword">
<meta content="draft-ietf-ccwg-bbr-latest" name="ietf.draft">
<!-- Generator version information:
  xml2rfc 3.30.0
    Python 3.12.11
    ConfigArgParse 1.7
    google-i18n-address 3.1.1
    intervaltree 3.1.0
    Jinja2 3.1.6
    lxml 5.3.1
    platformdirs 4.3.8
    pycountry 24.6.1
    PyYAML 6.0.2
    requests 2.32.4
    setuptools 80.9.0
    wcwidth 0.2.13
-->
<link href="draft-ietf-ccwg-bbr.xml" rel="alternate" type="application/rfc+xml">
<link href="#copyright" rel="license">
<style type="text/css">@font-face {
  font-family: 'Lora';
  font-style: italic;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Italic'), local('Lora-Italic'), url('https://martinthomson.github.io/rfc-css/fonts/lora-italic-cyrillic-ext.woff2') format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
@font-face {
  font-family: 'Lora';
  font-style: italic;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Italic'), local('Lora-Italic'), url('https://martinthomson.github.io/rfc-css/fonts/lora-italic-cyrillic-ext.woff2') format('woff2');
  unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
@font-face {
  font-family: 'Lora';
  font-style: italic;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Italic'), local('Lora-Italic'), url('https://martinthomson.github.io/rfc-css/fonts/lora-italic-vietnamese.woff2') format('woff2');
  unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}
@font-face {
  font-family: 'Lora';
  font-style: italic;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Italic'), local('Lora-Italic'), url('https://martinthomson.github.io/rfc-css/fonts/lora-italic-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}

@font-face {
  font-family: 'Lora';
  font-style: italic;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Italic'), local('Lora-Italic'), url('https://martinthomson.github.io/rfc-css/fonts/lora-italic-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Regular'), local('Lora-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/lora-regular-cyrillic-ext.woff2') format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Regular'), local('Lora-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/lora-regular-cyrillic.woff2') format('woff2');
  unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Regular'), local('Lora-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/lora-regular-vietnamese.woff2') format('woff2');
  unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Regular'), local('Lora-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/lora-regular-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Lora Regular'), local('Lora-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/lora-regular-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: local('Lora Bold'), local('Lora-Bold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-bold-cyrillic-ext.woff2') format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: local('Lora Bold'), local('Lora-Bold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-bold-cyrillic.woff2') format('woff2');
  unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: local('Lora Bold'), local('Lora-Bold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-bold-vietnamese.woff2') format('woff2');
  unicode-range: U+0102-0103, U+0110-0111, U+1EA0-1EF9, U+20AB;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: local('Lora Bold'), local('Lora-Bold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-bold-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 700;
  font-display: swap;
  src: local('Lora Bold'), local('Lora-Bold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-bold-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 600;
  font-display: swap;
  src: local('Lora SemiBold'), local('Lora-SemiBold'), url('https://martinthomson.github.io/rfc-css/fonts/lora-semibold-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

@font-face {
  font-family: 'Oxygen Mono';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Oxygen Mono'), local('OxygenMono-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/oxygenmono-regular-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
@font-face {
  font-family: 'Oxygen Mono';
  font-style: normal;
  font-weight: 400;
  font-display: swap;
  src: local('Oxygen Mono'), local('OxygenMono-Regular'), url('https://martinthomson.github.io/rfc-css/fonts/oxygenmono-regular-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

@font-face {
  font-family: 'Sofia Sans Semi Condensed';
  font-style: italic;
  font-weight: 1 1000;
  src: url('https://martinthomson.github.io/rfc-css/fonts/sofiasanssemicondensed-italic-cyrillic-ext.woff2') format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C8A, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
@font-face {
  font-family: 'Sofia Sans Semi Condensed';
  font-style: italic;
  font-weight: 1 1000;
  src: url('https://martinthomson.github.io/rfc-css/fonts/sofiasanssemicondensed-italic-cyrillic.woff2') format('woff2');
  unicode-range: U+0301, U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
@font-face {
  font-family: 'Sofia Sans Semi Condensed';
  font-style: italic;
  font-weight: 1 1000;
  src: url('https://martinthomson.github.io/rfc-css/fonts/sofiasanssemicondensed-italic-greek.woff2') format('woff2');
  unicode-range: U+0370-0377, U+037A-037F, U+0384-038A, U+038C, U+038E-03A1, U+03A3-03FF;
}
@font-face {
  font-family: 'Sofia Sans Semi Condensed';
  font-style: italic;
  font-weight: 1 1000;
  src: url('https://martinthomson.github.io/rfc-css/fonts/sofiasanssemicondensed-italic-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-02BA, U+02BD-02C5, U+02C7-02CC, U+02CE-02D7, U+02DD-02FF, U+0304, U+0308, U+0329, U+1D00-1DBF, U+1E00-1E9F, U+1EF2-1EFF, U+2020, U+20A0-20AB, U+20AD-20C0, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
@font-face {
  font-family: 'Sofia Sans Semi Condensed';
  font-style: italic;
  font-weight: 1 1000;
  src: url('https://martinthomson.github.io/rfc-css/fonts/sofiasanssemicondensed-italic-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+0304, U+0308, U+0329, U+2000-206F, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
@font-face {
  font-family: 'Sofia Sans Semi Condensed';
  font-style: normal;
  font-weight: 1 1000;
  src: url('https://martinthomson.github.io/rfc-css/fonts/sofiasanssemicondensed-regular-cyrillic-ext.woff2') format('woff2');
  unicode-range: U+0460-052F, U+1C80-1C8A, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
}
@font-face {
  font-family: 'Sofia Sans Semi Condensed';
  font-style: normal;
  font-weight: 1 1000;
  src: url('https://martinthomson.github.io/rfc-css/fonts/sofiasanssemicondensed-regular-cyrillic.woff2') format('woff2');
  unicode-range: U+0301, U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
}
@font-face {
  font-family: 'Sofia Sans Semi Condensed';
  font-style: normal;
  font-weight: 1 1000;
  src: url('https://martinthomson.github.io/rfc-css/fonts/sofiasanssemicondensed-regular-greek.woff2') format('woff2');
  unicode-range: U+0370-0377, U+037A-037F, U+0384-038A, U+038C, U+038E-03A1, U+03A3-03FF;
}
@font-face {
  font-family: 'Sofia Sans Semi Condensed';
  font-style: normal;
  font-weight: 1 1000;
  src: url('https://martinthomson.github.io/rfc-css/fonts/sofiasanssemicondensed-regular-latin-ext.woff2') format('woff2');
  unicode-range: U+0100-02BA, U+02BD-02C5, U+02C7-02CC, U+02CE-02D7, U+02DD-02FF, U+0304, U+0308, U+0329, U+1D00-1DBF, U+1E00-1E9F, U+1EF2-1EFF, U+2020, U+20A0-20AB, U+20AD-20C0, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
@font-face {
  font-family: 'Sofia Sans Semi Condensed';
  font-style: normal;
  font-weight: 1 1000;
  src: url('https://martinthomson.github.io/rfc-css/fonts/sofiasanssemicondensed-regular-latin.woff2') format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+0304, U+0308, U+0329, U+2000-206F, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

:root {
  color-scheme: light dark;
  --background-color: #fff;
  --text-color: #222;
  --title-color: #191919;
  --link-color: #2a6496;
  --highlight-color: #f9f9f9;
  --line-color: #eee;
  --pilcrow-weak: #ddd;
  --pilcrow-strong: #bbb;
  --small-font-size: 14.5px;
  --font-mono: 'Oxygen Mono', monospace;
  --font-title: "Sofia Sans Semi Condensed", sans-serif;
  scrollbar-color: #bbb #eee;
}
body {
  max-width: 600px;
  margin: 75px auto;
  padding: 0 5px;
  color: var(--text-color);
  background-color: var(--background-color);
  font: 16px/22px "Lora", serif;
  scroll-behavior: smooth;
}

.ears {
  display: none;
}

/* headings */
section {
  clear: both;
}
.section-number {
  padding-right: 0.5em;
}
h1, h2, h3, h4, h5, h6 {
  font-family: var(--font-title);
  font-weight: 680;
  margin: 0.8em 0 0.3em;
  font-size-adjust: 0.5;
  color: var(--title-color);
}
h1#title {
  font-size: 32px;
  line-height: 40px;
  clear: both;
}
h1#title, h1#rfcnum {
  margin: 1.5em 0 0.2em;
}
h1#rfcnum + h1#title {
  margin: 0.2em 0;
}

h1, h2, h3 {
  font-size: 22px;
  line-height: 27px;
}
h4, h5, h6 {
  font-size: 20px;
  line-height: 24px;
}

/* general structure */
.author {
  padding-bottom: 0.3em;
  vertical-align: top;
}
#abstract+p {
  font-size: 18px;
  line-height: 24px;
}
#abstract+p code, #abstract+p samp, #abstract+p tt {
  font-size: 16px;
  line-height: 0;
}

p {
  padding: 0;
  margin: 0.5em 0;
  text-align: left;
}
div {
  margin: 0;
}
.alignRight.art-text {
  background-color: var(--highlight-color);
  border: 1px solid var(--line-color);
  border-radius: 3px;
  padding: 0.5em 1em 0;
  margin-bottom: 0.5em;
}
.alignRight.art-text pre {
  padding: 0;
  width: auto;
}
.alignRight {
  margin: 1em 0;
}
.alignRight > *:first-child {
  border: none;
  margin: 0;
  float: right;
  clear: both;
}
.alignRight > *:nth-child(2) {
  clear: both;
  display: block;
  border: none;
}
svg {
  display: block;
}
/* font-family isn't space-separated, but =~ will have to do */
svg[font-family~="monospace" i], svg [font-family~="monospace" i] {
  font-family: var(--font-mono);
}
.alignCenter.art-text {
  background-color: var(--highlight-color);
  border: 1px solid var(--line-color);
  border-radius: 3px;
  padding: 0.5em 1em 0;
  margin-bottom: 0.5em;
}
.alignCenter.art-text pre {
  padding: 0;
  width: auto;
}
.alignCenter {
  margin: 1em 0;
}
.alignCenter > *:first-child {
  border: none;
  /* this isn't optimal, but it's an existence proof.  PrinceXML doesn't
     support flexbox yet.
  */
  display: table;
  margin: 0 auto;
}

/* lists */
ol, ul {
  padding: 0;
  margin: 0 0 0.5em 2em;
  & :is(ol, ul) {
    margin-left: 1em;
  }
}
li {
  margin: 0 0 0.25em 0;
}
ul.empty, .ulEmpty {
  list-style-type: none;
  & li {
    margin-top: 0.5em;
  }
}
:is(ul, ol).compact, .ulCompact, .olCompact {
  margin: 0 0 0 2em;
  & li {
    margin: 0;
    & :first-child { margin-top: 0; }
    & :last-child { margin-bottom: 0; }
  }
}

/* definition lists */
dl {
  clear: left;
  --indent: 3ch;
  /* --indent: attr(indent ch); not supported in any browser, but we can dream */
  &.olPercent {
    --indent: 5ch;
    & > dt {
      min-width: calc(var(--indent) - 2ch);
    }
  }
  &.olPercent > dt {
    float: none;
  }

  dl > dd > & {
    margin-top: 0.5em;
    margin-bottom: 0;
  }
}
dl:not(.dlNewline) > dt {
  float: left;
  margin-right: 2ch;
  min-width: 8ch;
}
dl > dd {
  margin-bottom: .8em;
  margin-left: var(--indent) !important; /* stupid element overrides */
  min-height: 2ex;
}
:is(dl.compact, .dlCompact) > dd {
  margin-bottom: 0;
  & > :is(:first-child, .break:first-child + *) {
    margin-top: 0;
  }
  & > :is(:last-child) {
    margin-bottom: 0;
  }
}
:is(dd, span).break {
  display: none;
}

/* links */
a, a[href].selfRef:hover {
  text-decoration: none;
}
a[href] {
  color: var(--link-color);
}
a[href].selfRef, .iref + a[href].internal {
  color: var(--text-color);
}
a[href]:hover {
  text-decoration: underline;
}
a[href].selfRef:hover {
  background-color: var(--highlight-color);
}
a.xref:is(.cite, .auto), :is(#status-of-memo, #copyright) a {
  white-space: nowrap;
}

/* Figures */
tt, code, pre {
  background-color: var(--highlight-color);
  font: 14px/22px var(--font-mono);
}
tt, code {
  /* changing the font for inline elements leads to different ascender
     and descender heights; as we want to retain baseline alignment,
     remove leading to avoid altering the final height of lines
     note: this fails if these blocks take an entire line,
     a different solution would be great */
  line-height: 0;
}
:is(h1, h2, h3, h4, h5, h6) :is(tt, code) {
  font-size: 84%;
}
pre {
  border: 1px solid var(--line-color);
  font-size: 13.5px;
  line-height: 16px;
  letter-spacing: -0.2px;
  margin: 5px;
  padding: 5px;
}
img {
  max-width: 100%;
}
figure {
  margin: 0.5em 0;
  padding: 0;
}
figure blockquote {
  margin: 0.8em 0.4em 0.4em;
}
figcaption, caption {
  font-style: italic;
  margin: 0.5em 1.5em;
  text-align: left;
  caption-side: bottom;
}
@media screen {
  /* Auto-collapse boilerplate. */
  :is(#status-of-memo, #copyright) p {
    margin: -2px 0;
    max-height: 0;
    transition: max-height 2s ease, margin 0.5s ease 0.5s;
    overflow: hidden;
  }
  :is(#status-of-memo, #copyright):hover p,
  :is(#status-of-memo, #copyright) h2:target ~ p {
    margin: 0.5em 0;
    max-height: 500px;
    overflow: auto;
  }
  pre, svg {
    display: inline-block;
    /* In the horizontal direction, sometimes people make over-sized figures.
       Scrollbars for those is therefore necessary: auto adds them as necessary..
       In the vertical direction, the line-height can combine with the font
       asender/descender height to produce scrollbars: hidden avoids that. */
    overflow: auto hidden;
  }
  pre {
    max-width: 100%;
    width: calc(100% - 22px - 1em);
  }
  svg {
    max-width: calc(100% - 22px - 1em);
  }
  figure pre {
    display: block;
    width: calc(100% - 25px);
  }
  :is(pre, svg) + .pilcrow {
    display: inline-block;
    vertical-align: text-bottom;
    padding-bottom: 8px;
  }
}

/* aside, blockquote */
aside, blockquote {
  margin-left: 0;
  padding: 0 2em;
  font-style: italic;
}
blockquote {
  margin: 1em 0;
}
cite {
  display: block;
  text-align: right;
  font-style: italic;
}

/* tables */
table {
  width: auto;
  max-width: 100%;
  margin: 0 0 1em;
  border-collapse: collapse;
}
table.right {
  margin-left: auto;
}
table.center {
  margin-left: auto;
  margin-right: auto;
}
table.left {
  margin-right: auto;
}
table .text-left {
  text-align: left;
}
table .text-center {
  text-align: center;
}
table .text-right {
  text-align: right;
}

thead, tbody {
  border: 1px solid var(--line-color);
}
th, td {
  text-align: left;
  vertical-align: top;
  padding: 5px 10px;
}
th {
  background-color: var(--line-color);
}
:is(tr:nth-child(2n), thead+tbody > tr:nth-child(2n+1)) > td {
  background-color: var(--background-color);
}
:is(tr:nth-child(2n+1), thead+tbody > tr:nth-child(2n)) > td {
  background-color: var(--highlight-color);
}
table caption {
  margin: 0;
  padding: 3px 0 3px 1em;
}
table p {
  margin: 0;
}

/* pilcrow */
a.pilcrow {
  margin-left: 3px;
  opacity: 0.2;
  user-select: none;
  &[href] {
    color: var(--pilcrow-weak);
    &:hover { text-decoration: none; }
  }
}
@media not print {
  :hover > a.pilcrow {
    opacity: 1;
  }
  a.pilcrow[href]:hover {
    color: var(--pilcrow-strong);
    background-color: transparent;
  }
}
@media print {
  a.pilcrow {
    display: none;
  }
}

/* misc */
hr {
  border: 0;
  border-top: 1px solid var(--line-color);
}
.bcp14 {
  font-variant: small-caps;
  font-weight: 600;
  font-size: var(--small-font-size);
}
.role {
  font-variant: all-small-caps;
}
sub, sup {
  line-height: 1;
  font-size: 80%;
}

/* info block */
#identifiers {
  margin: 0;
  font-size: var(--small-font-size);
  line-height: 18px;
  --identifier-width: 15ch;
  & dt {
    width: var(--identifier-width);
    min-width: var(--identifier-width);
    clear: left;
    float: left;
    text-align: right;
    margin-right: 1ch;
  }
  & dd {
    margin: 0;
    margin-left: calc(1em + var(--identifier-width)) !important;
    min-width: 5em;
  }
  & .authors {
    & .author {
      display: inline-block;
      margin-right: 1.5em;
    }
    & .org {
      font-style: italic;
    }
  }
}

/* The prepared/rendered info at the very bottom of the page */
.docInfo {
  color: #999;
  font-size: 0.9em;
  font-style: italic;
  margin-top: 2em;
}
.docInfo .prepared {
  float: right;
}

/* table of contents */
#toc {
  padding: 0.75em 0 2em 0;
  margin-bottom: 1em;

  & nav {
    & ul {
      margin: 0 0.5em 0 0;
      padding: 0;
      list-style: none;
    }
    & li {
      line-height: 1.3em;
      margin: 2px 0;
      padding-left: 1.2em;
      text-indent: -1.2em;
    }
  }
  & a.xref {
    white-space: normal;
  }
}

.references {
  & > dt {
    text-align: right;
    font-weight: bold;
    min-width: 10ch;
    margin-right: 1.5ch;
    &:target::before {
      content: "⇒";
      margin: 0 10px 0 -25px;
    }
  }
  & > dd {
    margin-left: 12ch !important;
    overflow: visible;
    & .refInstance {
      margin-bottom: 0.8em;
    }
    & .ascii {
      margin-bottom: 0.25em;
    }
  }
}

#rfc\.index\.index + ul {
  margin-left: 0;
}

/* authors */
address.vcard {
  font-style: normal;
  max-width: 20em;
  margin: 1em auto 1em 0;

  & .nameRole {
    font-weight: 700;
    margin-left: 0;
  }
  & .label {
    margin: 0.5em 0;
  }
  & .type {
    display: none;
  }
  & .alternative-contact {
    margin: 0.5em 0 0.25em 0;
  }
  & .non-ascii {
    margin: 0 0 0 2em;
  }
  & div.left {
    text-align: left;
  }
  & div.right {
    text-align: right;
  }
}

hr.addr {
  border-top: 1px dashed;
  margin: 0;
  color: #ddd;
  max-width: calc(100% - 16px);
}
@media (min-width: 500px) {
  #authors-addresses > section {
    column-count: 2;
    column-gap: 20px;
  }
  #authors-addresses > section > h2 {
    column-span: all;
  }
  /* hack for break-inside: avoid-column */
  #authors-addresses address {
    display: inline-block;
    break-inside: avoid-column;
  }
}

/* Comments */
.rfcEditorRemove p:first-of-type {
  font-style: italic;
}
.cref {
  background-color: rgba(249, 232, 105, 0.3);
  padding: 2px 4px;
}
.crefSource {
  font-style: italic;
}

@media screen {
  #toc nav {
    font-family: var(--font-title);
    font-weight: 360;
    & > ul { margin-bottom: 2em; }
    & ul {
      margin: 0 0 0 4px;
      & :is(p, li) {
        margin: 2px 0;
      }
    }
  }
  #toc a.toplink {
    float: right;
  }
}
@media not screen {
  #toc a.toplink {
    display: none;
  }
}


/* TOC layout for smaller screens */
@media screen and (max-width: 929px) {
  #toc {
    position: fixed;
    z-index: 2;
    top: 0;
    right: 0;
    padding: 1px 0 0 0;
    margin: 0;
    border-bottom: 1px solid #ccc;
    opacity: 0.6;
  }
  #toc h2 {
    margin: 0;
    padding: 2px 0 2px 6px;
    padding-right: 1em;
    font-size: 18px;
    line-height: 24px;
    min-width: 190px;
    text-align: right;
    background-color: #444;
    color: white;
    cursor: pointer;
    &::before { /* css hamburger */
      float: right;
      position: relative;
      width: 1em;
      height: 1px;
      left: -164px;
      margin: 8px 0 0 0;
      background: white none repeat scroll 0 0;
      box-shadow: 0 4px 0 0 white, 0 8px 0 0 white;
      content: "";
    }
  }
  #toc nav {
    display: none;
    background-color: var(--background-color);
    padding: 0.5em 1em 1em;
    overflow: auto;
    overscroll-behavior: contain;
    height: calc(100vh - 48px);
    border-left: 1px solid #ddd;
  }
  #toc.active {
    opacity: 1;
    & nav { display: block; }
  }
  /* Make the collapsed ToC header render white on gray also when it's a link */
  #toc h2 a,
  #toc h2 a:is(:link, :focus, :hover),
  #toc a.toplink,
  #toc a.toplink:hover {
    color: white;
    background-color: #444;
    text-decoration: none;
  }
  #toc a.toplink {
    margin: 2px 0.5em 0;
  }
}

/* TOC layout for wide screens */
@media screen and (min-width: 930px) {
  body {
    padding-right: 360px;
    padding-right: calc(min(180px + 20%, 500px));
  }
  #toc {
    position: fixed;
    bottom: 0;
    right: 0;
    right: calc(50vw - 480px);
    width: 312px;
    margin: 0;
    padding: 0;
    z-index: 1;
  }
  #toc h2 {
    margin: 0;
    padding: 0.25em 1em 1em 0;
  }
  #toc nav {
    display: block;
    height: calc(90vh - 84px);
    bottom: 0;
    padding: 0.5em 0 2em;
    overflow: auto;
    overscroll-behavior: contain;
    scrollbar-width: thin;
  }
  img { /* future proofing */
    max-width: 100%;
    height: auto;
  }
  #toc a.toplink {
    margin: 8px 0.5em 0;
  }
}

/* pagination */
@media print {
  body {
    width: 100%;
  }
  p {
    orphans: 3;
    widows: 3;
  }
  #n-copyright-notice {
    border-bottom: none;
  }
  #toc, #n-introduction {
    page-break-before: always;
  }
  #toc {
    border-top: none;
    padding-top: 0;
  }
  figure, pre, .vcard {
    page-break-inside: avoid;
  }
  h1, h2, h3, h4, h5, h6 {
    page-break-after: avoid;
  }
  :is(h2, h3, h4, h5, h6)+*, dd {
    page-break-before: avoid;
  }
  pre {
    white-space: pre-wrap;
    word-wrap: break-word;
    font-size: 10pt;
  }
  table {
    border: 1px solid #ddd;
  }
  td {
    border-top: 1px solid #ddd;
  }
}

@page :first {
  padding-top: 0;
  @top-left {
    content: normal;
    border: none;
  }
  @top-center {
    content: normal;
    border: none;
  }
  @top-right {
    content: normal;
    border: none;
  }
}

@page {
  size: A4;
  margin-bottom: 45mm;
  padding-top: 20px;
}

/* Dark mode. */
@media (prefers-color-scheme: dark) {
:root {
  --background-color: #121212;
  --text-color: #f0f0f0;
  --title-color: #fff;
  --link-color: #4da4f0;
  --highlight-color: #282828;
  --line-color: #444;
  --pilcrow-weak: #444;
  --pilcrow-strong: #666;
  scrollbar-color: #777 #333;
}
}

/* SVG Trick: a prefix match works because only black and white are allowed */
svg :is([stroke="black"], [stroke^="#000"]) {
  stroke: var(--text-color);
}
svg :is([stroke="white"], [stroke^="#fff"]) {
  stroke: var(--background-color);
}
svg :is([fill="black"], [fill^="#000"], :not([fill])) {
  fill: var(--text-color);
}
svg :is([fill="white"], [fill^="#fff"]) {
  fill: var(--background-color);
}
</style>

</head>
<body class="xml2rfc">
<table class="ears">
<thead><tr>
<td class="left">Internet-Draft</td>
<td class="center">BBR</td>
<td class="right">August 2025</td>
</tr></thead>
<tfoot><tr>
<td class="left">Cardwell, et al.</td>
<td class="center">Expires 18 February 2026</td>
<td class="right">[Page]</td>
</tr></tfoot>
</table>
<div id="external-metadata" class="document-information"></div>
<div id="internal-metadata" class="document-information">
<dl id="identifiers">
<dt class="label-workgroup">Workgroup:</dt>
<dd class="workgroup">CCWG</dd>
<dt class="label-internet-draft">Internet-Draft:</dt>
<dd class="internet-draft">draft-ietf-ccwg-bbr-latest</dd>
<dt class="label-published">Published:</dt>
<dd class="published">
<time datetime="2025-08-17" class="published">17 August 2025</time>
    </dd>
<dt class="label-intended-status">Intended Status:</dt>
<dd class="intended-status">Experimental</dd>
<dt class="label-expires">Expires:</dt>
<dd class="expires"><time datetime="2026-02-18">18 February 2026</time></dd>
<dt class="label-authors">Authors:</dt>
<dd class="authors">
<div class="author">
      <div class="author-name">N. Cardwell, <span class="editor">Ed.</span>
</div>
<div class="org">Google</div>
</div>
<div class="author">
      <div class="author-name">I. Swett, <span class="editor">Ed.</span>
</div>
<div class="org">Google</div>
</div>
<div class="author">
      <div class="author-name">J. Beshay, <span class="editor">Ed.</span>
</div>
<div class="org">Meta</div>
</div>
</dd>
</dl>
</div>
<h1 id="title">BBR Congestion Control</h1>
<section id="section-abstract">
      <h2 id="abstract"><a href="#abstract" class="selfRef">Abstract</a></h2>
<p id="section-abstract-1">This document specifies the BBR congestion control algorithm. BBR ("Bottleneck
Bandwidth and Round-trip propagation time") uses recent measurements of a
transport connection's delivery rate, round-trip time, and packet loss rate
to build an explicit model of the network path. BBR then uses this model to
control both how fast it sends data and the maximum volume of data it allows
in flight in the network at any time. Relative to loss-based congestion control
algorithms such as Reno <span>[<a href="#RFC5681" class="cite xref">RFC5681</a>]</span> or CUBIC <span>[<a href="#RFC9438" class="cite xref">RFC9438</a>]</span>, BBR offers
substantially higher throughput for bottlenecks
with shallow buffers or random losses, and substantially lower queueing delays
for bottlenecks with deep buffers (avoiding "bufferbloat"). BBR can be
implemented in any transport protocol that supports packet-delivery
acknowledgment. Thus far, open source implementations are available
for TCP <span>[<a href="#RFC9293" class="cite xref">RFC9293</a>]</span> and QUIC <span>[<a href="#RFC9000" class="cite xref">RFC9000</a>]</span>. This document
specifies version 3 of the BBR algorithm, BBRv3.<a href="#section-abstract-1" class="pilcrow">¶</a></p>
</section>
<section class="note rfcEditorRemove" id="section-note.1">
      <h2 id="name-discussion-venues">
<a href="#name-discussion-venues" class="section-name selfRef">Discussion Venues</a>
      </h2>
<p id="section-note.1-1">This note is to be removed before publishing as an RFC.<a href="#section-note.1-1" class="pilcrow">¶</a></p>
<p id="section-note.1-2">Discussion of this document takes place on the
    Congestion Control Working Group Working Group mailing list (ccwg@ietf.org),
    which is archived at <span><a href="https://mailarchive.ietf.org/arch/browse/ccwg/">https://mailarchive.ietf.org/arch/browse/ccwg/</a></span>.<a href="#section-note.1-2" class="pilcrow">¶</a></p>
<p id="section-note.1-3">Source for this draft and an issue tracker can be found at
    <span><a href="https://github.com/ietf-wg-ccwg/draft-cardwell-ccwg-bbr">https://github.com/ietf-wg-ccwg/draft-cardwell-ccwg-bbr</a></span>.<a href="#section-note.1-3" class="pilcrow">¶</a></p>
</section>
<div id="status-of-memo">
<section id="section-boilerplate.1">
        <h2 id="name-status-of-this-memo">
<a href="#name-status-of-this-memo" class="section-name selfRef">Status of This Memo</a>
        </h2>
<p id="section-boilerplate.1-1">
        This Internet-Draft is submitted in full conformance with the
        provisions of BCP 78 and BCP 79.<a href="#section-boilerplate.1-1" class="pilcrow">¶</a></p>
<p id="section-boilerplate.1-2">
        Internet-Drafts are working documents of the Internet Engineering Task
        Force (IETF). Note that other groups may also distribute working
        documents as Internet-Drafts. The list of current Internet-Drafts is
        at <span><a href="https://datatracker.ietf.org/drafts/current/">https://datatracker.ietf.org/drafts/current/</a></span>.<a href="#section-boilerplate.1-2" class="pilcrow">¶</a></p>
<p id="section-boilerplate.1-3">
        Internet-Drafts are draft documents valid for a maximum of six months
        and may be updated, replaced, or obsoleted by other documents at any
        time. It is inappropriate to use Internet-Drafts as reference
        material or to cite them other than as "work in progress."<a href="#section-boilerplate.1-3" class="pilcrow">¶</a></p>
<p id="section-boilerplate.1-4">
        This Internet-Draft will expire on 18 February 2026.<a href="#section-boilerplate.1-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="copyright">
<section id="section-boilerplate.2">
        <h2 id="name-copyright-notice">
<a href="#name-copyright-notice" class="section-name selfRef">Copyright Notice</a>
        </h2>
<p id="section-boilerplate.2-1">
            Copyright (c) 2025 IETF Trust and the persons identified as the
            document authors. All rights reserved.<a href="#section-boilerplate.2-1" class="pilcrow">¶</a></p>
<p id="section-boilerplate.2-2">
            This document is subject to BCP 78 and the IETF Trust's Legal
            Provisions Relating to IETF Documents
            (<span><a href="https://trustee.ietf.org/license-info">https://trustee.ietf.org/license-info</a></span>) in effect on the date of
            publication of this document. Please review these documents
            carefully, as they describe your rights and restrictions with
            respect to this document. Code Components extracted from this
            document must include Revised BSD License text as described in
            Section 4.e of the Trust Legal Provisions and are provided without
            warranty as described in the Revised BSD License.<a href="#section-boilerplate.2-2" class="pilcrow">¶</a></p>
</section>
</div>
<div id="toc">
<section id="section-toc.1">
        <a href="#" onclick="scroll(0,0)" class="toplink">▲</a><h2 id="name-table-of-contents">
<a href="#name-table-of-contents" class="section-name selfRef">Table of Contents</a>
        </h2>
<nav class="toc"><ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.1">
            <p id="section-toc.1-1.1.1" class="keepWithNext"><a href="#section-1" class="auto internal xref">1</a>.  <a href="#name-introduction" class="internal xref">Introduction</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2">
            <p id="section-toc.1-1.2.1"><a href="#section-2" class="auto internal xref">2</a>.  <a href="#name-terminology" class="internal xref">Terminology</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.1">
                <p id="section-toc.1-1.2.2.1.1" class="keepWithNext"><a href="#section-2.1" class="auto internal xref">2.1</a>.  <a href="#name-transport-connection-state" class="internal xref">Transport Connection State</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.2">
                <p id="section-toc.1-1.2.2.2.1" class="keepWithNext"><a href="#section-2.2" class="auto internal xref">2.2</a>.  <a href="#name-per-packet-state" class="internal xref">Per-Packet State</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.3">
                <p id="section-toc.1-1.2.2.3.1"><a href="#section-2.3" class="auto internal xref">2.3</a>.  <a href="#name-per-ack-rate-sample-state" class="internal xref">Per-ACK Rate Sample State</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.4">
                <p id="section-toc.1-1.2.2.4.1"><a href="#section-2.4" class="auto internal xref">2.4</a>.  <a href="#name-output-control-parameters" class="internal xref">Output Control Parameters</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.5">
                <p id="section-toc.1-1.2.2.5.1"><a href="#section-2.5" class="auto internal xref">2.5</a>.  <a href="#name-pacing-state-and-parameters" class="internal xref">Pacing State and Parameters</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.6">
                <p id="section-toc.1-1.2.2.6.1"><a href="#section-2.6" class="auto internal xref">2.6</a>.  <a href="#name-cwnd-state-and-parameters" class="internal xref">cwnd State and Parameters</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.7">
                <p id="section-toc.1-1.2.2.7.1"><a href="#section-2.7" class="auto internal xref">2.7</a>.  <a href="#name-general-algorithm-state" class="internal xref">General Algorithm State</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.8">
                <p id="section-toc.1-1.2.2.8.1"><a href="#section-2.8" class="auto internal xref">2.8</a>.  <a href="#name-core-algorithm-design-param" class="internal xref">Core Algorithm Design Parameters</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.9">
                <p id="section-toc.1-1.2.2.9.1"><a href="#section-2.9" class="auto internal xref">2.9</a>.  <a href="#name-network-path-model-paramete" class="internal xref">Network Path Model Parameters</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.9.2.1">
                    <p id="section-toc.1-1.2.2.9.2.1.1"><a href="#section-2.9.1" class="auto internal xref">2.9.1</a>.  <a href="#name-data-rate-network-path-mode" class="internal xref">Data Rate Network Path Model Parameters</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.9.2.2">
                    <p id="section-toc.1-1.2.2.9.2.2.1"><a href="#section-2.9.2" class="auto internal xref">2.9.2</a>.  <a href="#name-data-volume-network-path-mo" class="internal xref">Data Volume Network Path Model Parameters</a></p>
</li>
                </ul>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.10">
                <p id="section-toc.1-1.2.2.10.1"><a href="#section-2.10" class="auto internal xref">2.10</a>. <a href="#name-state-for-responding-to-con" class="internal xref">State for Responding to Congestion</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.11">
                <p id="section-toc.1-1.2.2.11.1"><a href="#section-2.11" class="auto internal xref">2.11</a>. <a href="#name-estimating-bbrmax_bw" class="internal xref">Estimating BBR.max_bw</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.12">
                <p id="section-toc.1-1.2.2.12.1"><a href="#section-2.12" class="auto internal xref">2.12</a>. <a href="#name-estimating-bbrextra_acked" class="internal xref">Estimating BBR.extra_acked</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.13">
                <p id="section-toc.1-1.2.2.13.1"><a href="#section-2.13" class="auto internal xref">2.13</a>. <a href="#name-startup-parameters-and-stat" class="internal xref">Startup Parameters and State</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.14">
                <p id="section-toc.1-1.2.2.14.1"><a href="#section-2.14" class="auto internal xref">2.14</a>. <a href="#name-probertt-and-min_rtt-parame" class="internal xref">ProbeRTT and min_rtt Parameters and State</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.14.2.1">
                    <p id="section-toc.1-1.2.2.14.2.1.1"><a href="#section-2.14.1" class="auto internal xref">2.14.1</a>.  <a href="#name-parameters-for-estimating-b" class="internal xref">Parameters for Estimating BBR.min_rtt</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.14.2.2">
                    <p id="section-toc.1-1.2.2.14.2.2.1"><a href="#section-2.14.2" class="auto internal xref">2.14.2</a>.  <a href="#name-parameters-for-scheduling-p" class="internal xref">Parameters for Scheduling ProbeRTT</a></p>
</li>
                </ul>
</li>
            </ul>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3">
            <p id="section-toc.1-1.3.1"><a href="#section-3" class="auto internal xref">3</a>.  <a href="#name-design-overview" class="internal xref">Design Overview</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.1">
                <p id="section-toc.1-1.3.2.1.1"><a href="#section-3.1" class="auto internal xref">3.1</a>.  <a href="#name-high-level-design-goals" class="internal xref">High-Level Design Goals</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.2">
                <p id="section-toc.1-1.3.2.2.1"><a href="#section-3.2" class="auto internal xref">3.2</a>.  <a href="#name-algorithm-overview" class="internal xref">Algorithm Overview</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.3">
                <p id="section-toc.1-1.3.2.3.1"><a href="#section-3.3" class="auto internal xref">3.3</a>.  <a href="#name-state-machine-overview" class="internal xref">State Machine Overview</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.4">
                <p id="section-toc.1-1.3.2.4.1"><a href="#section-3.4" class="auto internal xref">3.4</a>.  <a href="#name-network-path-model-overview" class="internal xref">Network Path Model Overview</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.4.2.1">
                    <p id="section-toc.1-1.3.2.4.2.1.1"><a href="#section-3.4.1" class="auto internal xref">3.4.1</a>.  <a href="#name-high-level-design-goals-for" class="internal xref">High-Level Design Goals for the Network Path Model</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.4.2.2">
                    <p id="section-toc.1-1.3.2.4.2.2.1"><a href="#section-3.4.2" class="auto internal xref">3.4.2</a>.  <a href="#name-time-scales-for-the-network" class="internal xref">Time Scales for the Network Model</a></p>
</li>
                </ul>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.5">
                <p id="section-toc.1-1.3.2.5.1"><a href="#section-3.5" class="auto internal xref">3.5</a>.  <a href="#name-control-parameter-overview" class="internal xref">Control Parameter Overview</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.6">
                <p id="section-toc.1-1.3.2.6.1"><a href="#section-3.6" class="auto internal xref">3.6</a>.  <a href="#name-environment-and-usage" class="internal xref">Environment and Usage</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.7">
                <p id="section-toc.1-1.3.2.7.1"><a href="#section-3.7" class="auto internal xref">3.7</a>.  <a href="#name-ecn" class="internal xref">ECN</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3.2.8">
                <p id="section-toc.1-1.3.2.8.1"><a href="#section-3.8" class="auto internal xref">3.8</a>.  <a href="#name-experimental-status" class="internal xref">Experimental Status</a></p>
</li>
            </ul>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.4">
            <p id="section-toc.1-1.4.1"><a href="#section-4" class="auto internal xref">4</a>.  <a href="#name-input-signals" class="internal xref">Input Signals</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.4.2.1">
                <p id="section-toc.1-1.4.2.1.1"><a href="#section-4.1" class="auto internal xref">4.1</a>.  <a href="#name-delivery-rate-samples" class="internal xref">Delivery Rate Samples</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.4.2.1.2.1">
                    <p id="section-toc.1-1.4.2.1.2.1.1"><a href="#section-4.1.1" class="auto internal xref">4.1.1</a>.  <a href="#name-delivery-rate-sampling-algo" class="internal xref">Delivery Rate Sampling Algorithm Overview</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.4.2.1.2.2">
                    <p id="section-toc.1-1.4.2.1.2.2.1"><a href="#section-4.1.2" class="auto internal xref">4.1.2</a>.  <a href="#name-detailed-delivery-rate-samp" class="internal xref">Detailed Delivery Rate Sampling Algorithm</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.4.2.1.2.3">
                    <p id="section-toc.1-1.4.2.1.2.3.1"><a href="#section-4.1.3" class="auto internal xref">4.1.3</a>.  <a href="#name-delivery-rate-sampling-disc" class="internal xref">Delivery Rate Sampling Discussion</a></p>
</li>
                </ul>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.4.2.2">
                <p id="section-toc.1-1.4.2.2.1"><a href="#section-4.2" class="auto internal xref">4.2</a>.  <a href="#name-rtt-samples" class="internal xref">RTT Samples</a></p>
</li>
            </ul>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5">
            <p id="section-toc.1-1.5.1"><a href="#section-5" class="auto internal xref">5</a>.  <a href="#name-detailed-algorithm" class="internal xref">Detailed Algorithm</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.1">
                <p id="section-toc.1-1.5.2.1.1"><a href="#section-5.1" class="auto internal xref">5.1</a>.  <a href="#name-state-machine" class="internal xref">State Machine</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.1.2.1">
                    <p id="section-toc.1-1.5.2.1.2.1.1"><a href="#section-5.1.1" class="auto internal xref">5.1.1</a>.  <a href="#name-state-transition-diagram" class="internal xref">State Transition Diagram</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.1.2.2">
                    <p id="section-toc.1-1.5.2.1.2.2.1"><a href="#section-5.1.2" class="auto internal xref">5.1.2</a>.  <a href="#name-state-machine-operation-ove" class="internal xref">State Machine Operation Overview</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.1.2.3">
                    <p id="section-toc.1-1.5.2.1.2.3.1"><a href="#section-5.1.3" class="auto internal xref">5.1.3</a>.  <a href="#name-state-machine-tactics" class="internal xref">State Machine Tactics</a></p>
</li>
                </ul>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.2">
                <p id="section-toc.1-1.5.2.2.1"><a href="#section-5.2" class="auto internal xref">5.2</a>.  <a href="#name-algorithm-organization" class="internal xref">Algorithm Organization</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.2.2.1">
                    <p id="section-toc.1-1.5.2.2.2.1.1"><a href="#section-5.2.1" class="auto internal xref">5.2.1</a>.  <a href="#name-initialization" class="internal xref">Initialization</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.2.2.2">
                    <p id="section-toc.1-1.5.2.2.2.2.1"><a href="#section-5.2.2" class="auto internal xref">5.2.2</a>.  <a href="#name-per-transmit-steps" class="internal xref">Per-Transmit Steps</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.2.2.3">
                    <p id="section-toc.1-1.5.2.2.2.3.1"><a href="#section-5.2.3" class="auto internal xref">5.2.3</a>.  <a href="#name-per-ack-steps" class="internal xref">Per-ACK Steps</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.2.2.4">
                    <p id="section-toc.1-1.5.2.2.2.4.1"><a href="#section-5.2.4" class="auto internal xref">5.2.4</a>.  <a href="#name-per-loss-steps" class="internal xref">Per-Loss Steps</a></p>
</li>
                </ul>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.3">
                <p id="section-toc.1-1.5.2.3.1"><a href="#section-5.3" class="auto internal xref">5.3</a>.  <a href="#name-state-machine-operation" class="internal xref">State Machine Operation</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.3.2.1">
                    <p id="section-toc.1-1.5.2.3.2.1.1"><a href="#section-5.3.1" class="auto internal xref">5.3.1</a>.  <a href="#name-startup" class="internal xref">Startup</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.3.2.2">
                    <p id="section-toc.1-1.5.2.3.2.2.1"><a href="#section-5.3.2" class="auto internal xref">5.3.2</a>.  <a href="#name-drain" class="internal xref">Drain</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.3.2.3">
                    <p id="section-toc.1-1.5.2.3.2.3.1"><a href="#section-5.3.3" class="auto internal xref">5.3.3</a>.  <a href="#name-probebw" class="internal xref">ProbeBW</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.3.2.4">
                    <p id="section-toc.1-1.5.2.3.2.4.1"><a href="#section-5.3.4" class="auto internal xref">5.3.4</a>.  <a href="#name-probertt" class="internal xref">ProbeRTT</a></p>
</li>
                </ul>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.4">
                <p id="section-toc.1-1.5.2.4.1"><a href="#section-5.4" class="auto internal xref">5.4</a>.  <a href="#name-restarting-from-idle" class="internal xref">Restarting From Idle</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.4.2.1">
                    <p id="section-toc.1-1.5.2.4.2.1.1"><a href="#section-5.4.1" class="auto internal xref">5.4.1</a>.  <a href="#name-actions-when-restarting-fro" class="internal xref">Actions when Restarting from Idle</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.4.2.2">
                    <p id="section-toc.1-1.5.2.4.2.2.1"><a href="#section-5.4.2" class="auto internal xref">5.4.2</a>.  <a href="#name-comparison-with-previous-ap" class="internal xref">Comparison with Previous Approaches</a></p>
</li>
                </ul>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5">
                <p id="section-toc.1-1.5.2.5.1"><a href="#section-5.5" class="auto internal xref">5.5</a>.  <a href="#name-updating-network-path-model" class="internal xref">Updating Network Path Model Parameters</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5.2.1">
                    <p id="section-toc.1-1.5.2.5.2.1.1"><a href="#section-5.5.1" class="auto internal xref">5.5.1</a>.  <a href="#name-bbrround_count-tracking-pac" class="internal xref">BBR.round_count: Tracking Packet-Timed Round Trips</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5.2.2">
                    <p id="section-toc.1-1.5.2.5.2.2.1"><a href="#section-5.5.2" class="auto internal xref">5.5.2</a>.  <a href="#name-bbrmax_bw-estimated-maximum" class="internal xref">BBR.max_bw: Estimated Maximum Bandwidth</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5.2.3">
                    <p id="section-toc.1-1.5.2.5.2.3.1"><a href="#section-5.5.3" class="auto internal xref">5.5.3</a>.  <a href="#name-bbrmax_bw-max-filter" class="internal xref">BBR.max_bw Max Filter</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5.2.4">
                    <p id="section-toc.1-1.5.2.5.2.4.1"><a href="#section-5.5.4" class="auto internal xref">5.5.4</a>.  <a href="#name-bbrmax_bw-and-application-l" class="internal xref">BBR.max_bw and Application-limited Delivery Rate Samples</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5.2.5">
                    <p id="section-toc.1-1.5.2.5.2.5.1"><a href="#section-5.5.5" class="auto internal xref">5.5.5</a>.  <a href="#name-updating-the-bbrmax_bw-max-" class="internal xref">Updating the BBR.max_bw Max Filter</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5.2.6">
                    <p id="section-toc.1-1.5.2.5.2.6.1"><a href="#section-5.5.6" class="auto internal xref">5.5.6</a>.  <a href="#name-tracking-time-for-the-bbrma" class="internal xref">Tracking Time for the BBR.max_bw Max Filter</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5.2.7">
                    <p id="section-toc.1-1.5.2.5.2.7.1"><a href="#section-5.5.7" class="auto internal xref">5.5.7</a>.  <a href="#name-bbrmin_rtt-estimated-minimu" class="internal xref">BBR.min_rtt: Estimated Minimum Round-Trip Time</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5.2.8">
                    <p id="section-toc.1-1.5.2.5.2.8.1"><a href="#section-5.5.8" class="auto internal xref">5.5.8</a>.  <a href="#name-bbroffload_budget" class="internal xref">BBR.offload_budget</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5.2.9">
                    <p id="section-toc.1-1.5.2.5.2.9.1"><a href="#section-5.5.9" class="auto internal xref">5.5.9</a>.  <a href="#name-bbrextra_acked" class="internal xref">BBR.extra_acked</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.5.2.10">
                    <p id="section-toc.1-1.5.2.5.2.10.1"><a href="#section-5.5.10" class="auto internal xref">5.5.10</a>. <a href="#name-updating-the-model-upon-pac" class="internal xref">Updating the Model Upon Packet Loss</a></p>
</li>
                </ul>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.6">
                <p id="section-toc.1-1.5.2.6.1"><a href="#section-5.6" class="auto internal xref">5.6</a>.  <a href="#name-updating-control-parameters" class="internal xref">Updating Control Parameters</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.6.2.1">
                    <p id="section-toc.1-1.5.2.6.2.1.1"><a href="#section-5.6.1" class="auto internal xref">5.6.1</a>.  <a href="#name-summary-of-control-behavior" class="internal xref">Summary of Control Behavior in the State Machine</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.6.2.2">
                    <p id="section-toc.1-1.5.2.6.2.2.1"><a href="#section-5.6.2" class="auto internal xref">5.6.2</a>.  <a href="#name-pacing-rate-cpacing_rate" class="internal xref">Pacing Rate: C.pacing_rate</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.6.2.3">
                    <p id="section-toc.1-1.5.2.6.2.3.1"><a href="#section-5.6.3" class="auto internal xref">5.6.3</a>.  <a href="#name-send-quantum-csend_quantum" class="internal xref">Send Quantum: C.send_quantum</a></p>
</li>
                  <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5.2.6.2.4">
                    <p id="section-toc.1-1.5.2.6.2.4.1"><a href="#section-5.6.4" class="auto internal xref">5.6.4</a>.  <a href="#name-congestion-window" class="internal xref">Congestion Window</a></p>
</li>
                </ul>
</li>
            </ul>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.6">
            <p id="section-toc.1-1.6.1"><a href="#section-6" class="auto internal xref">6</a>.  <a href="#name-implementation-status" class="internal xref">Implementation Status</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.7">
            <p id="section-toc.1-1.7.1"><a href="#section-7" class="auto internal xref">7</a>.  <a href="#name-security-considerations" class="internal xref">Security Considerations</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.8">
            <p id="section-toc.1-1.8.1"><a href="#section-8" class="auto internal xref">8</a>.  <a href="#name-iana-considerations" class="internal xref">IANA Considerations</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.9">
            <p id="section-toc.1-1.9.1"><a href="#section-9" class="auto internal xref">9</a>.  <a href="#name-acknowledgments" class="internal xref">Acknowledgments</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.10">
            <p id="section-toc.1-1.10.1"><a href="#section-10" class="auto internal xref">10</a>. <a href="#name-references" class="internal xref">References</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.10.2.1">
                <p id="section-toc.1-1.10.2.1.1"><a href="#section-10.1" class="auto internal xref">10.1</a>.  <a href="#name-normative-references" class="internal xref">Normative References</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.10.2.2">
                <p id="section-toc.1-1.10.2.2.1"><a href="#section-10.2" class="auto internal xref">10.2</a>.  <a href="#name-informative-references" class="internal xref">Informative References</a></p>
</li>
            </ul>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.11">
            <p id="section-toc.1-1.11.1"><a href="#appendix-A" class="auto internal xref"></a><a href="#name-authors-addresses" class="internal xref">Authors' Addresses</a></p>
</li>
        </ul>
</nav>
</section>
</div>
<div id="introduction">
<section id="section-1">
      <h2 id="name-introduction">
<a href="#section-1" class="section-number selfRef">1. </a><a href="#name-introduction" class="section-name selfRef">Introduction</a>
      </h2>
<p id="section-1-1">The Internet has traditionally used loss-based congestion control algorithms
like Reno (<span>[<a href="#Jac88" class="cite xref">Jac88</a>]</span>, <span>[<a href="#Jac90" class="cite xref">Jac90</a>]</span>, <span>[<a href="#WS95" class="cite xref">WS95</a>]</span>  <span>[<a href="#RFC5681" class="cite xref">RFC5681</a>]</span>) and CUBIC (<span>[<a href="#HRX08" class="cite xref">HRX08</a>]</span>,
<span>[<a href="#RFC9438" class="cite xref">RFC9438</a>]</span>). These algorithms worked well for many years because
they were sufficiently well-matched to the prevalent range of bandwidth-delay
products and degrees of buffering in Internet paths. As the Internet has
evolved, loss-based congestion control is increasingly problematic in several
important scenarios:<a href="#section-1-1" class="pilcrow">¶</a></p>
<ol start="1" type="1" class="normal type-1" id="section-1-2">
<li id="section-1-2.1">
          <p id="section-1-2.1.1">Shallow buffers: In shallow buffers, packet loss can happen even when a link
  has low utilization. With high-speed, long-haul links employing commodity
  switches with shallow buffers, loss-based congestion control can cause abysmal
  throughput because it overreacts, making large multiplicative decreases in
  sending rate upon packet loss (by 50% in Reno <span>[<a href="#RFC5681" class="cite xref">RFC5681</a>]</span> or 30%
  in CUBIC <span>[<a href="#RFC9438" class="cite xref">RFC9438</a>]</span>), and only slowly growing its sending rate
  thereafter. This can happen even if the packet loss arises from transient
  traffic bursts when the link is mostly idle.<a href="#section-1-2.1.1" class="pilcrow">¶</a></p>
</li>
        <li id="section-1-2.2">
          <p id="section-1-2.2.1">Deep buffers: At the edge of today's Internet, loss-based congestion control
  can cause the problem of  "bufferbloat", by repeatedly filling deep buffers
  in last-mile links and causing high queuing delays.<a href="#section-1-2.2.1" class="pilcrow">¶</a></p>
</li>
        <li id="section-1-2.3">
          <p id="section-1-2.3.1">Dynamic traffic workloads: With buffers of any depth, dynamic mixes of
  newly-entering flows or flights of data from recently idle flows can cause
  frequent packet loss. In such scenarios loss-based congestion control can
  fail to maintain its fair share of bandwidth, leading to poor application
  performance.<a href="#section-1-2.3.1" class="pilcrow">¶</a></p>
</li>
      </ol>
<p id="section-1-3">In both the shallow-buffer (1.) or dynamic-traffic (3.) scenarios mentioned
above it is difficult to achieve full throughput with loss-based congestion
control in practice: for CUBIC, sustaining 10Gbps over 100ms RTT needs a
packet loss rate below 0.000003% (i.e., more than 40 seconds between packet losses),
and over a 100ms RTT path a more feasible loss rate like 1% can only sustain
at most 3 Mbps <span>[<a href="#RFC9438" class="cite xref">RFC9438</a>]</span>. These limitations apply no matter what
the bottleneck link is capable of or what the connection's fair share
is. Furthermore, failure to reach the fair share can cause poor throughput
and poor tail latency for latency-sensitive applications.<a href="#section-1-3" class="pilcrow">¶</a></p>
<p id="section-1-4">The BBR ("Bottleneck Bandwidth and Round-trip propagation time") congestion
control algorithm is a model-based algorithm that takes an approach different
from loss-based congestion control: BBR uses recent measurements of a transport
connection's delivery rate,  round-trip time, and packet loss rate to build
an explicit model of the network path, including its estimated available
bandwidth, bandwidth-delay product, and the maximum volume of data that the
connection can place in flight in the network without causing excessive queue
pressure. It then uses this model in order to guide its control behavior
in seeking high throughput and low queue pressure.<a href="#section-1-4" class="pilcrow">¶</a></p>
<p id="section-1-5">This document describes the current version of the BBR algorithm, BBRv3.
The original version of the algorithm, BBRv1, was described previously at a
high level <span>[<a href="#CCGHJ16" class="cite xref">CCGHJ16</a>]</span><span>[<a href="#CCGHJ17" class="cite xref">CCGHJ17</a>]</span>. The implications of BBR
in allowing high utilization of high-speed networks with shallow buffers
have been discussed in other work <span>[<a href="#MM19" class="cite xref">MM19</a>]</span>. Active work on the BBR
algorithm is continuing.<a href="#section-1-5" class="pilcrow">¶</a></p>
<p id="section-1-6">This document is organized as follows. Section 2 provides various definitions
that will be used throughout this document. Section 3 provides an overview
of the design of the BBR algorithm, and section 4 describes the BBR algorithm
in detail, including BBR's network path model, control parameters, and state
machine. Section 5 describes the implementation status, section 6 describes
security considerations, section 7 notes that there are no IANA considerations,
and section 8 closes with Acknowledgments.<a href="#section-1-6" class="pilcrow">¶</a></p>
</section>
</div>
<div id="terminology">
<section id="section-2">
      <h2 id="name-terminology">
<a href="#section-2" class="section-number selfRef">2. </a><a href="#name-terminology" class="section-name selfRef">Terminology</a>
      </h2>
<p id="section-2-1">This document defines state variables and constants used by the BBR algorithm.<a href="#section-2-1" class="pilcrow">¶</a></p>
<p id="section-2-2">Constant values have CamelCase names and are used by BBR throughout
its operation for a given connection. Variables have snake_case names.
All names are prefixed with the context they
belong to: (C) for connection state, (P) for per-packet state, (RS) for
per-ack rate sample, or (BBR) for the algorithm's internal state.
Variables that are not defined below are defined in
<a href="#delivery-rate-samples" class="auto internal xref">Section 4.1</a>, "Delivery Rate Samples".<a href="#section-2-2" class="pilcrow">¶</a></p>
<p id="section-2-3">In this document, "acknowledged" or "delivered" data means any transmitted
data that the remote transport endpoint has confirmed that it has received,
e.g., via a QUIC ACK Range <span>[<a href="#RFC9000" class="cite xref">RFC9000</a>]</span>, TCP cumulative acknowledgment
<span>[<a href="#RFC9293" class="cite xref">RFC9293</a>]</span>, or TCP SACK ("Selective Acknowledgment") block <span>[<a href="#RFC2018" class="cite xref">RFC2018</a>]</span>.<a href="#section-2-3" class="pilcrow">¶</a></p>
<div id="transport-connection-state">
<section id="section-2.1">
        <h3 id="name-transport-connection-state">
<a href="#section-2.1" class="section-number selfRef">2.1. </a><a href="#name-transport-connection-state" class="section-name selfRef">Transport Connection State</a>
        </h3>
<p id="section-2.1-1">C.SMSS: The Sender Maximum Send Size in bytes. The maximum
size of a single packet transmission, including the portion
of the packet that the transport protocol implementation tracks for
congestion control purposes.
C.SMSS MUST include transport protocol payload data.
C.SMSS MAY include only the transport protocol payload data;
for example, for TCP BBR implementations the C.SMSS SHOULD be the
Eff.snd.MSS defined in <span>[<a href="#RFC9293" class="cite xref">RFC9293</a>], <a href="https://rfc-editor.org/rfc/rfc9293#section-3.7.1" class="relref">Section 3.7.1</a></span>,
which includes only the TCP transport protocol payload data,
but not TCP or IP headers.
C.SMSS MAY include the transport protocol payload data plus
the transport protocol headers; for example,
for QUIC BBR implementations
the C.SMSS SHOULD be the QUIC "maximum datagram size"
<span>[<a href="#RFC9000" class="cite xref">RFC9000</a>], <a href="https://rfc-editor.org/rfc/rfc9000#section-14" class="relref">Section 14</a></span>, which includes
the QUIC payload data plus the QUIC headers,
but not UDP or IP headers.
In addition to including transport protocol payload and headers,
implementations MAY include in C.SMSS the size of other headers,
such as network-layer or link-layer headers.<a href="#section-2.1-1" class="pilcrow">¶</a></p>
<p id="section-2.1-2">C.InitialCwnd: The initial congestion window set by the transport protocol
implementation for the connection at initialization time.<a href="#section-2.1-2" class="pilcrow">¶</a></p>
<p id="section-2.1-3">C.delivered: The total amount of data (tracked in octets or in packets)
delivered so far over the lifetime of the transport connection C.
This MUST NOT include pure ACK packets. It SHOULD include spurious
retransmissions that have been acknowledged as delivered.<a href="#section-2.1-3" class="pilcrow">¶</a></p>
<p id="section-2.1-4">C.inflight: The connection's best estimate of the number of bytes
outstanding in the network. This includes the number of bytes that
have been sent and have not been acknowledged or
marked as lost since their last transmission
(e.g. "pipe" from <span>[<a href="#RFC6675" class="cite xref">RFC6675</a>]</span> or "bytes_in_flight" from <span>[<a href="#RFC9002" class="cite xref">RFC9002</a>]</span>).
This MUST NOT include pure ACK packets.<a href="#section-2.1-4" class="pilcrow">¶</a></p>
<p id="section-2.1-5">C.is_cwnd_limited: True if the connection has fully utilized C.cwnd at any
point in the last packet-timed round trip.<a href="#section-2.1-5" class="pilcrow">¶</a></p>
</section>
</div>
<div id="per-packet-state">
<section id="section-2.2">
        <h3 id="name-per-packet-state">
<a href="#section-2.2" class="section-number selfRef">2.2. </a><a href="#name-per-packet-state" class="section-name selfRef">Per-Packet State</a>
        </h3>
<p id="section-2.2-1">P.delivered: C.delivered when the given packet was sent by transport
connection C.<a href="#section-2.2-1" class="pilcrow">¶</a></p>
<p id="section-2.2-2">P.departure_time: The earliest pacing departure time for the given packet.<a href="#section-2.2-2" class="pilcrow">¶</a></p>
<p id="section-2.2-3">P.tx_in_flight: C.inflight at the time of the packet transmission.<a href="#section-2.2-3" class="pilcrow">¶</a></p>
</section>
</div>
<div id="per-ack-rate-sample-state">
<section id="section-2.3">
        <h3 id="name-per-ack-rate-sample-state">
<a href="#section-2.3" class="section-number selfRef">2.3. </a><a href="#name-per-ack-rate-sample-state" class="section-name selfRef">Per-ACK Rate Sample State</a>
        </h3>
<p id="section-2.3-1">RS.delivered: The volume of data delivered between the transmission of the
packet that has just been ACKed and the current time.<a href="#section-2.3-1" class="pilcrow">¶</a></p>
<p id="section-2.3-2">RS.delivery_rate: The delivery rate (aka bandwidth) sample obtained from
the packet that has just been ACKed.<a href="#section-2.3-2" class="pilcrow">¶</a></p>
<p id="section-2.3-3">RS.rtt: The RTT sample calculated based on the most recently-sent packet
of the packets that have just been ACKed.<a href="#section-2.3-3" class="pilcrow">¶</a></p>
<p id="section-2.3-4">RS.newly_acked: The volume of data cumulatively or selectively acknowledged
upon the ACK that was just received. (This quantity is referred to as
"DeliveredData" in <span>[<a href="#RFC6937" class="cite xref">RFC6937</a>]</span>.)<a href="#section-2.3-4" class="pilcrow">¶</a></p>
<p id="section-2.3-5">RS.newly_lost: The volume of data newly marked lost upon the ACK that was
just received.<a href="#section-2.3-5" class="pilcrow">¶</a></p>
<p id="section-2.3-6">RS.tx_in_flight: C.inflight at
the time of the transmission of the packet that has just been ACKed (the
most recently sent packet among packets ACKed by the ACK that was just
received).<a href="#section-2.3-6" class="pilcrow">¶</a></p>
<p id="section-2.3-7">RS.lost: The volume of data that was declared lost between the transmission
and acknowledgment of the packet that has just been ACKed (the most recently
sent packet among packets ACKed by the ACK that was just received).<a href="#section-2.3-7" class="pilcrow">¶</a></p>
</section>
</div>
<div id="output-control-parameters">
<section id="section-2.4">
        <h3 id="name-output-control-parameters">
<a href="#section-2.4" class="section-number selfRef">2.4. </a><a href="#name-output-control-parameters" class="section-name selfRef">Output Control Parameters</a>
        </h3>
<p id="section-2.4-1">C.cwnd: The transport sender's congestion window. When transmitting data,
the sending connection ensures that C.inflight does not exceed C.cwnd.<a href="#section-2.4-1" class="pilcrow">¶</a></p>
<p id="section-2.4-2">C.pacing_rate: The current pacing rate for a BBR flow, which controls
inter-packet spacing.<a href="#section-2.4-2" class="pilcrow">¶</a></p>
<p id="section-2.4-3">C.send_quantum: The maximum size of a data aggregate scheduled and transmitted
together as a unit, e.g., to amortize per-packet transmission overheads.<a href="#section-2.4-3" class="pilcrow">¶</a></p>
</section>
</div>
<div id="pacing-state-and-parameters">
<section id="section-2.5">
        <h3 id="name-pacing-state-and-parameters">
<a href="#section-2.5" class="section-number selfRef">2.5. </a><a href="#name-pacing-state-and-parameters" class="section-name selfRef">Pacing State and Parameters</a>
        </h3>
<p id="section-2.5-1">BBR.pacing_gain: The dynamic gain factor used to scale BBR.bw to produce
C.pacing_rate.<a href="#section-2.5-1" class="pilcrow">¶</a></p>
<p id="section-2.5-2">BBR.next_departure_time: The earliest pacing departure time for the next
packet BBR schedules for transmission.<a href="#section-2.5-2" class="pilcrow">¶</a></p>
<p id="section-2.5-3">BBR.StartupPacingGain: A constant specifying the minimum gain value for
calculating the pacing rate that will allow the sending rate to double each
round (4 * ln(2) ~= 2.77) <span>[<a href="#BBRStartupPacingGain" class="cite xref">BBRStartupPacingGain</a>]</span>; used in
Startup mode for BBR.pacing_gain.<a href="#section-2.5-3" class="pilcrow">¶</a></p>
<p id="section-2.5-4">BBR.DrainPacingGain: A constant specifying the pacing gain value used in
Drain mode, to attempt to drain the estimated queue at the bottleneck link
in one round-trip or less. As noted in <span>[<a href="#BBRDrainPacingGain" class="cite xref">BBRDrainPacingGain</a>]</span>, any
value at or below 1 / BBRStartupCwndGain = 1 / 2 = 0.5 will theoretically
achieve this. BBR uses the value 0.35, which has been shown to offer good
performance when compared with other alternatives.<a href="#section-2.5-4" class="pilcrow">¶</a></p>
<p id="section-2.5-5">BBR.PacingMarginPercent: The static discount factor of 1% used to scale BBR.bw
to produce C.pacing_rate.<a href="#section-2.5-5" class="pilcrow">¶</a></p>
</section>
</div>
<div id="cwnd-state-and-parameters">
<section id="section-2.6">
        <h3 id="name-cwnd-state-and-parameters">
<a href="#section-2.6" class="section-number selfRef">2.6. </a><a href="#name-cwnd-state-and-parameters" class="section-name selfRef">cwnd State and Parameters</a>
        </h3>
<p id="section-2.6-1">BBR.cwnd_gain: The dynamic gain factor used to scale the estimated BDP to
produce a congestion window (C.cwnd).<a href="#section-2.6-1" class="pilcrow">¶</a></p>
<p id="section-2.6-2">BBR.DefaultCwndGain: A constant specifying the minimum gain value that allows
the sending rate to double each round (2) <span>[<a href="#BBRStartupCwndGain" class="cite xref">BBRStartupCwndGain</a>]</span>.
Used by default in most phases for BBR.cwnd_gain.<a href="#section-2.6-2" class="pilcrow">¶</a></p>
</section>
</div>
<div id="general-algorithm-state">
<section id="section-2.7">
        <h3 id="name-general-algorithm-state">
<a href="#section-2.7" class="section-number selfRef">2.7. </a><a href="#name-general-algorithm-state" class="section-name selfRef">General Algorithm State</a>
        </h3>
<p id="section-2.7-1">BBR.state: The current state of a BBR flow in the BBR state machine.<a href="#section-2.7-1" class="pilcrow">¶</a></p>
<p id="section-2.7-2">BBR.round_count: Count of packet-timed round trips elapsed so far.<a href="#section-2.7-2" class="pilcrow">¶</a></p>
<p id="section-2.7-3">BBR.round_start: A boolean that BBR sets to true once per packet-timed round
trip, on ACKs that advance BBR.round_count.<a href="#section-2.7-3" class="pilcrow">¶</a></p>
<p id="section-2.7-4">BBR.next_round_delivered: P.delivered value denoting the end of a
packet-timed round trip.<a href="#section-2.7-4" class="pilcrow">¶</a></p>
<p id="section-2.7-5">BBR.idle_restart: A boolean that is true if and only if a connection is
restarting after being idle.<a href="#section-2.7-5" class="pilcrow">¶</a></p>
</section>
</div>
<div id="core-algorithm-design-parameters">
<section id="section-2.8">
        <h3 id="name-core-algorithm-design-param">
<a href="#section-2.8" class="section-number selfRef">2.8. </a><a href="#name-core-algorithm-design-param" class="section-name selfRef">Core Algorithm Design Parameters</a>
        </h3>
<p id="section-2.8-1">BBR.LossThresh: A constant specifying the maximum tolerated per-round-trip
packet loss rate when probing for bandwidth (the default is 2%).<a href="#section-2.8-1" class="pilcrow">¶</a></p>
<p id="section-2.8-2">BBR.Beta: A constant specifying the default multiplicative decrease to
make upon each round trip during which the connection detects packet
loss (the value is 0.7).<a href="#section-2.8-2" class="pilcrow">¶</a></p>
<p id="section-2.8-3">BBR.Headroom: A constant specifying the multiplicative factor to
apply to BBR.inflight_longterm when calculating a volume of free headroom
to try to leave unused in the path
(e.g. free space in the bottleneck buffer or free time slots in the bottleneck
link) that can be used by cross traffic (the value is 0.15).<a href="#section-2.8-3" class="pilcrow">¶</a></p>
<p id="section-2.8-4">BBR.MinPipeCwnd: The minimal C.cwnd value BBR targets, to allow pipelining with
endpoints that follow an "ACK every other packet" delayed-ACK policy:
4 * C.SMSS.<a href="#section-2.8-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="network-path-model-parameters">
<section id="section-2.9">
        <h3 id="name-network-path-model-paramete">
<a href="#section-2.9" class="section-number selfRef">2.9. </a><a href="#name-network-path-model-paramete" class="section-name selfRef">Network Path Model Parameters</a>
        </h3>
<div id="data-rate-network-path-model-parameters">
<section id="section-2.9.1">
          <h4 id="name-data-rate-network-path-mode">
<a href="#section-2.9.1" class="section-number selfRef">2.9.1. </a><a href="#name-data-rate-network-path-mode" class="section-name selfRef">Data Rate Network Path Model Parameters</a>
          </h4>
<p id="section-2.9.1-1">The data rate model parameters together estimate both the sending rate required
to reach the full bandwidth available to the flow (BBR.max_bw), and the maximum
pacing rate control parameter that is consistent with the queue pressure
objective (BBR.bw).<a href="#section-2.9.1-1" class="pilcrow">¶</a></p>
<p id="section-2.9.1-2">BBR.max_bw: The windowed maximum recent bandwidth sample, obtained using
the BBR delivery rate sampling algorithm in <a href="#delivery-rate-samples" class="auto internal xref">Section 4.1</a>,
measured during the current or previous bandwidth probing cycle (or during
Startup, if the flow is still in that state). (Part of the long-term
model.)<a href="#section-2.9.1-2" class="pilcrow">¶</a></p>
<p id="section-2.9.1-3">BBR.bw_shortterm: The short-term maximum sending bandwidth that the algorithm
estimates is safe for matching the current network path delivery rate, based
on any loss signals in the current bandwidth probing cycle. This is generally
lower than max_bw. (Part of the short-term model.)<a href="#section-2.9.1-3" class="pilcrow">¶</a></p>
<p id="section-2.9.1-4">BBR.bw: The maximum sending bandwidth that the algorithm estimates is
appropriate for matching the current network path delivery rate, given all
available signals in the model, at any time scale. It is the min() of max_bw
and bw_shortterm.<a href="#section-2.9.1-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="data-volume-network-path-model-parameters">
<section id="section-2.9.2">
          <h4 id="name-data-volume-network-path-mo">
<a href="#section-2.9.2" class="section-number selfRef">2.9.2. </a><a href="#name-data-volume-network-path-mo" class="section-name selfRef">Data Volume Network Path Model Parameters</a>
          </h4>
<p id="section-2.9.2-1">The data volume model parameters together estimate both the inflight
required to reach the full bandwidth available to the flow
(BBR.max_inflight), and the maximum inflight that is consistent with the
queue pressure objective (C.cwnd).<a href="#section-2.9.2-1" class="pilcrow">¶</a></p>
<p id="section-2.9.2-2">BBR.min_rtt: The windowed minimum round-trip time sample measured over the
last BBR.MinRTTFilterLen = 10 seconds. This attempts to estimate the two-way
propagation delay of the network path when all connections sharing a bottleneck
are using BBR, but also allows BBR to estimate the value required for a BBR.bdp
estimate that allows full throughput if there are legacy loss-based Reno
or CUBIC flows sharing the bottleneck.<a href="#section-2.9.2-2" class="pilcrow">¶</a></p>
<p id="section-2.9.2-3">BBR.bdp: The estimate of the network path's BDP (Bandwidth-Delay Product),
computed as: BBR.bdp = BBR.bw * BBR.min_rtt.<a href="#section-2.9.2-3" class="pilcrow">¶</a></p>
<p id="section-2.9.2-4">BBR.extra_acked: A volume of data that is the estimate of the recent degree
of aggregation in the network path.<a href="#section-2.9.2-4" class="pilcrow">¶</a></p>
<p id="section-2.9.2-5">BBR.offload_budget: The estimate of the minimum volume of data necessary
to achieve full throughput when using sender (TSO/GSO)  and receiver (LRO,
GRO) host offload mechanisms.<a href="#section-2.9.2-5" class="pilcrow">¶</a></p>
<p id="section-2.9.2-6">BBR.max_inflight: The estimate of C.inflight required to
fully utilize the bottleneck bandwidth available to the flow, based on the
BDP estimate (BBR.bdp), the aggregation estimate (BBR.extra_acked), the offload
budget (BBR.offload_budget), and BBR.MinPipeCwnd.<a href="#section-2.9.2-6" class="pilcrow">¶</a></p>
<p id="section-2.9.2-7">BBR.inflight_longterm: The long-term maximum inflight that the
algorithm estimates will produce acceptable queue pressure, based on signals
in the current or previous bandwidth probing cycle, as measured by loss. That
is, if a flow is probing for bandwidth, and observes that sending a particular
inflight causes a loss rate higher than the loss rate
threshold, it sets inflight_longterm to that volume of data. (Part of the long-term
model.)<a href="#section-2.9.2-7" class="pilcrow">¶</a></p>
<p id="section-2.9.2-8">BBR.inflight_shortterm: Analogous to BBR.bw_shortterm, the short-term maximum
inflight that the algorithm estimates is safe for matching the
current network path delivery process, based on any loss signals in the current
bandwidth probing cycle. This is generally lower than max_inflight or
inflight_longterm. (Part of the short-term model.)<a href="#section-2.9.2-8" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
<div id="state-for-responding-to-congestion">
<section id="section-2.10">
        <h3 id="name-state-for-responding-to-con">
<a href="#section-2.10" class="section-number selfRef">2.10. </a><a href="#name-state-for-responding-to-con" class="section-name selfRef">State for Responding to Congestion</a>
        </h3>
<p id="section-2.10-1">RS: The rate sample calculated from the most recent acknowledgment.<a href="#section-2.10-1" class="pilcrow">¶</a></p>
<p id="section-2.10-2">BBR.bw_latest: a 1-round-trip max of delivered bandwidth (RS.delivery_rate).<a href="#section-2.10-2" class="pilcrow">¶</a></p>
<p id="section-2.10-3">BBR.inflight_latest: a 1-round-trip max of delivered volume of data
(RS.delivered).<a href="#section-2.10-3" class="pilcrow">¶</a></p>
</section>
</div>
<div id="estimating-bbrmaxbw">
<section id="section-2.11">
        <h3 id="name-estimating-bbrmax_bw">
<a href="#section-2.11" class="section-number selfRef">2.11. </a><a href="#name-estimating-bbrmax_bw" class="section-name selfRef">Estimating BBR.max_bw</a>
        </h3>
<p id="section-2.11-1">BBR.max_bw_filter: The filter for tracking the maximum recent RS.delivery_rate
sample, for estimating BBR.max_bw.<a href="#section-2.11-1" class="pilcrow">¶</a></p>
<p id="section-2.11-2">BBR.MaxBwFilterLen: A constant specifying the filter window length for
BBR.max_bw_filter = 2 (representing
up to 2 ProbeBW cycles, the current cycle and the previous full cycle).<a href="#section-2.11-2" class="pilcrow">¶</a></p>
<p id="section-2.11-3">BBR.cycle_count: The virtual time used by the BBR.max_bw filter window. Note
that BBR.cycle_count only needs to be tracked with a single bit, since the
BBR.MaxBwFilter only needs to track samples from two time slots: the previous
ProbeBW cycle and the current ProbeBW cycle.<a href="#section-2.11-3" class="pilcrow">¶</a></p>
</section>
</div>
<div id="estimating-bbrextraacked">
<section id="section-2.12">
        <h3 id="name-estimating-bbrextra_acked">
<a href="#section-2.12" class="section-number selfRef">2.12. </a><a href="#name-estimating-bbrextra_acked" class="section-name selfRef">Estimating BBR.extra_acked</a>
        </h3>
<p id="section-2.12-1">BBR.extra_acked_interval_start: the start of the time interval for estimating
the excess amount of data acknowledged due to aggregation effects.<a href="#section-2.12-1" class="pilcrow">¶</a></p>
<p id="section-2.12-2">BBR.extra_acked_delivered: the volume of data marked as delivered since
BBR.extra_acked_interval_start.<a href="#section-2.12-2" class="pilcrow">¶</a></p>
<p id="section-2.12-3">BBR.extra_acked_filter: the max filter tracking the recent maximum degree of
aggregation in the path.<a href="#section-2.12-3" class="pilcrow">¶</a></p>
<p id="section-2.12-4">BBR.ExtraAckedFilterLen = A constant specifying the window length of
the BBR.extra_acked_filter max
filter window in steady-state: 10 (in units of packet-timed round trips).<a href="#section-2.12-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="startup-parameters-and-state">
<section id="section-2.13">
        <h3 id="name-startup-parameters-and-stat">
<a href="#section-2.13" class="section-number selfRef">2.13. </a><a href="#name-startup-parameters-and-stat" class="section-name selfRef">Startup Parameters and State</a>
        </h3>
<p id="section-2.13-1">BBR.full_bw_reached: A boolean that records whether BBR estimates that it
has ever fully utilized its available bandwidth over the lifetime of the
connection.<a href="#section-2.13-1" class="pilcrow">¶</a></p>
<p id="section-2.13-2">BBR.full_bw_now: A boolean that records whether BBR estimates that it has
fully utilized its available bandwidth since it most recetly started looking.<a href="#section-2.13-2" class="pilcrow">¶</a></p>
<p id="section-2.13-3">BBR.full_bw: A recent baseline BBR.max_bw to estimate if BBR has "filled
the pipe" in Startup.<a href="#section-2.13-3" class="pilcrow">¶</a></p>
<p id="section-2.13-4">BBR.full_bw_count: The number of non-app-limited round trips without large
increases in BBR.full_bw.<a href="#section-2.13-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="probertt-and-minrtt-parameters-and-state">
<section id="section-2.14">
        <h3 id="name-probertt-and-min_rtt-parame">
<a href="#section-2.14" class="section-number selfRef">2.14. </a><a href="#name-probertt-and-min_rtt-parame" class="section-name selfRef">ProbeRTT and min_rtt Parameters and State</a>
        </h3>
<div id="parameters-for-estimating-bbrminrtt">
<section id="section-2.14.1">
          <h4 id="name-parameters-for-estimating-b">
<a href="#section-2.14.1" class="section-number selfRef">2.14.1. </a><a href="#name-parameters-for-estimating-b" class="section-name selfRef">Parameters for Estimating BBR.min_rtt</a>
          </h4>
<p id="section-2.14.1-1">BBR.min_rtt_stamp: The wall clock time at which the current BBR.min_rtt sample
was obtained.<a href="#section-2.14.1-1" class="pilcrow">¶</a></p>
<p id="section-2.14.1-2">BBR.MinRTTFilterLen: A constant specifying the length of the BBR.min_rtt min
filter window, BBR.MinRTTFilterLen is 10 secs.<a href="#section-2.14.1-2" class="pilcrow">¶</a></p>
</section>
</div>
<div id="parameters-for-scheduling-probertt">
<section id="section-2.14.2">
          <h4 id="name-parameters-for-scheduling-p">
<a href="#section-2.14.2" class="section-number selfRef">2.14.2. </a><a href="#name-parameters-for-scheduling-p" class="section-name selfRef">Parameters for Scheduling ProbeRTT</a>
          </h4>
<p id="section-2.14.2-1">BBR.ProbeRTTCwndGain = A constant specifying the gain value for calculating
C.cwnd during ProbeRTT: 0.5 (meaning that ProbeRTT attempts to reduce in-flight
data to 50% of the estimated BDP).<a href="#section-2.14.2-1" class="pilcrow">¶</a></p>
<p id="section-2.14.2-2">BBR.ProbeRTTDuration: A constant specifying the minimum duration for which ProbeRTT
state holds C.inflight to BBR.MinPipeCwnd or fewer packets: 200 ms.<a href="#section-2.14.2-2" class="pilcrow">¶</a></p>
<p id="section-2.14.2-3">BBR.ProbeRTTInterval: A constant specifying the minimum time interval between
ProbeRTT states: 5 secs.<a href="#section-2.14.2-3" class="pilcrow">¶</a></p>
<p id="section-2.14.2-4">BBR.probe_rtt_min_delay: The minimum RTT sample recorded in the last
ProbeRTTInterval.<a href="#section-2.14.2-4" class="pilcrow">¶</a></p>
<p id="section-2.14.2-5">BBR.probe_rtt_min_stamp: The wall clock time at which the current
BBR.probe_rtt_min_delay sample was obtained.<a href="#section-2.14.2-5" class="pilcrow">¶</a></p>
<p id="section-2.14.2-6">BBR.probe_rtt_expired: A boolean recording whether the BBR.probe_rtt_min_delay
has expired and is due for a refresh with an application idle period or a
transition into ProbeRTT state.<a href="#section-2.14.2-6" class="pilcrow">¶</a></p>
<p id="section-2.14.2-7">The keywords "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD",
"SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this document are to
be interpreted as described in <span>[<a href="#RFC2119" class="cite xref">RFC2119</a>]</span>.<a href="#section-2.14.2-7" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
</section>
</div>
<div id="design-overview">
<section id="section-3">
      <h2 id="name-design-overview">
<a href="#section-3" class="section-number selfRef">3. </a><a href="#name-design-overview" class="section-name selfRef">Design Overview</a>
      </h2>
<div id="high-level-design-goals">
<section id="section-3.1">
        <h3 id="name-high-level-design-goals">
<a href="#section-3.1" class="section-number selfRef">3.1. </a><a href="#name-high-level-design-goals" class="section-name selfRef">High-Level Design Goals</a>
        </h3>
<p id="section-3.1-1">The high-level goal of BBR is to achieve both:<a href="#section-3.1-1" class="pilcrow">¶</a></p>
<ol start="1" type="1" class="normal type-1" id="section-3.1-2">
<li id="section-3.1-2.1">
            <p id="section-3.1-2.1.1">The full throughput (or approximate fair share thereof) available to a flow<a href="#section-3.1-2.1.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-3.1-2.1.2.1">
                <p id="section-3.1-2.1.2.1.1">Achieved in a fast and scalable manner
(using bandwidth in O(log(BDP)) time).<a href="#section-3.1-2.1.2.1.1" class="pilcrow">¶</a></p>
</li>
              <li class="normal" id="section-3.1-2.1.2.2">
                <p id="section-3.1-2.1.2.2.1">Achieved with average packet loss rates of up to 1%.<a href="#section-3.1-2.1.2.2.1" class="pilcrow">¶</a></p>
</li>
            </ul>
</li>
          <li id="section-3.1-2.2">
            <p id="section-3.1-2.2.1">Low queue pressure (low queuing delay and low packet loss).<a href="#section-3.1-2.2.1" class="pilcrow">¶</a></p>
</li>
        </ol>
<p id="section-3.1-3">These goals are in tension: sending faster improves the odds of achieving
(1) but reduces the odds of achieving (2), while sending slower improves
the odds of achieving (2) but reduces the odds of achieving (1). Thus the
algorithm cannot maximize throughput or minimize queue pressure independently,
and must jointly optimize both.<a href="#section-3.1-3" class="pilcrow">¶</a></p>
<p id="section-3.1-4">To try to achieve these goals, and seek an operating point with high throughput
and low delay <span>[<a href="#K79" class="cite xref">K79</a>]</span> <span>[<a href="#GK81" class="cite xref">GK81</a>]</span>, BBR aims to adapt its sending process to
match the network delivery process, in two dimensions:<a href="#section-3.1-4" class="pilcrow">¶</a></p>
<ol start="1" type="1" class="normal type-1" id="section-3.1-5">
<li id="section-3.1-5.1">
            <p id="section-3.1-5.1.1">data rate: the rate at which the flow sends data should ideally match the
  rate at which the network delivers the flow's data (the available bottleneck
  bandwidth)<a href="#section-3.1-5.1.1" class="pilcrow">¶</a></p>
</li>
          <li id="section-3.1-5.2">
            <p id="section-3.1-5.2.1">data volume: the amount of data in flight in the network
  should ideally match the bandwidth-delay product (BDP) of the path<a href="#section-3.1-5.2.1" class="pilcrow">¶</a></p>
</li>
        </ol>
<p id="section-3.1-6">Both the control of the data rate (via the pacing rate) and data volume
(directly via the congestion window; and indirectly via the pacing
rate) are important. A mismatch in either dimension can cause the sender to
fail to meet its high-level design goals:<a href="#section-3.1-6" class="pilcrow">¶</a></p>
<ol start="1" type="1" class="normal type-1" id="section-3.1-7">
<li id="section-3.1-7.1">
            <p id="section-3.1-7.1.1">volume mismatch: If a sender perfectly matches its sending rate to the
  available bandwidth, but its C.inflight exceeds the BDP, then
  the sender can maintain a large standing queue, increasing network latency
  and risking packet loss.<a href="#section-3.1-7.1.1" class="pilcrow">¶</a></p>
</li>
          <li id="section-3.1-7.2">
            <p id="section-3.1-7.2.1">rate mismatch: If a sender's C.inflight matches the BDP
  perfectly but its sending rate exceeds the available bottleneck bandwidth
  (e.g. the sender transmits a BDP of data in an unpaced fashion, at the
  sender's link rate), then up to a full BDP of data can burst into the
  bottleneck queue, causing high delay and/or high loss.<a href="#section-3.1-7.2.1" class="pilcrow">¶</a></p>
</li>
        </ol>
</section>
</div>
<div id="algorithm-overview">
<section id="section-3.2">
        <h3 id="name-algorithm-overview">
<a href="#section-3.2" class="section-number selfRef">3.2. </a><a href="#name-algorithm-overview" class="section-name selfRef">Algorithm Overview</a>
        </h3>
<p id="section-3.2-1">Based on the rationale above, BBR tries to spend most of its time matching
its sending process (data rate and data volume) to the network path's delivery
process. To do this, it explores the 2-dimensional control parameter space
of (1) data rate ("bandwidth" or "throughput") and (2) data volume ("in-flight
data"), with a goal of finding the maximum values of each control parameter
that are consistent with its objective for queue pressure.<a href="#section-3.2-1" class="pilcrow">¶</a></p>
<p id="section-3.2-2">Depending on what signals a given network path manifests at a given time,
the objective for queue pressure is measured in terms of the most strict
among:<a href="#section-3.2-2" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-3.2-3.1">
            <p id="section-3.2-3.1.1">the amount of data that is estimated to be queued in the bottleneck buffer
(data_in_flight - estimated_BDP): the objective is to maintain this amount
at or below 1.5 * estimated_BDP<a href="#section-3.2-3.1.1" class="pilcrow">¶</a></p>
</li>
          <li class="normal" id="section-3.2-3.2">
            <p id="section-3.2-3.2.1">the packet loss rate: the objective is a maximum per-round-trip packet loss
rate of BBR.LossThresh=2% (and an average packet loss rate considerably lower)<a href="#section-3.2-3.2.1" class="pilcrow">¶</a></p>
</li>
        </ul>
</section>
</div>
<div id="state-machine-overview">
<section id="section-3.3">
        <h3 id="name-state-machine-overview">
<a href="#section-3.3" class="section-number selfRef">3.3. </a><a href="#name-state-machine-overview" class="section-name selfRef">State Machine Overview</a>
        </h3>
<p id="section-3.3-1">BBR varies its control parameters with a state machine that aims for high
throughput, low latency, low loss, and an approximately fair sharing of
bandwidth, while maintaining an up-to-date model of the network path.<a href="#section-3.3-1" class="pilcrow">¶</a></p>
<p id="section-3.3-2">A BBR flow starts in the Startup state, and ramps up its sending rate quickly,
to rapidly estimate the maximum available bandwidth (BBR.max_bw). When it
estimates the bottleneck bandwidth has been fully utilized, it enters the
Drain state to drain the estimated queue. In steady state a BBR flow mostly
uses the ProbeBW states, to periodically briefly send faster to probe for
higher capacity and then briefly send slower to try to drain any resulting
queue. If needed, it briefly enters the ProbeRTT state, to lower the sending
rate to probe for lower BBR.min_rtt samples. The detailed behavior for each
state is described below.<a href="#section-3.3-2" class="pilcrow">¶</a></p>
</section>
</div>
<div id="network-path-model-overview">
<section id="section-3.4">
        <h3 id="name-network-path-model-overview">
<a href="#section-3.4" class="section-number selfRef">3.4. </a><a href="#name-network-path-model-overview" class="section-name selfRef">Network Path Model Overview</a>
        </h3>
<div id="high-level-design-goals-for-the-network-path-model">
<section id="section-3.4.1">
          <h4 id="name-high-level-design-goals-for">
<a href="#section-3.4.1" class="section-number selfRef">3.4.1. </a><a href="#name-high-level-design-goals-for" class="section-name selfRef">High-Level Design Goals for the Network Path Model</a>
          </h4>
<p id="section-3.4.1-1">At a high level, the BBR model is trying to reflect two aspects of the network
path:<a href="#section-3.4.1-1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-3.4.1-2.1">
              <p id="section-3.4.1-2.1.1">Model what's required for achieving full throughput: Estimate the data rate
(BBR.max_bw) and data volume (BBR.max_inflight) required to fully utilize the
fair share of the bottleneck bandwidth available to the flow. This
incorporates estimates of the maximum available bandwidth, the BDP of the
path, and the requirements of any offload features on the end hosts or
mechanisms on the network path that produce aggregation effects.<a href="#section-3.4.1-2.1.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-3.4.1-2.2">
              <p id="section-3.4.1-2.2.1">Model what's permitted for achieving low queue pressure: Estimate the maximum
data rate (BBR.bw) and data volume (C.cwnd) consistent with the queue pressure
objective, as measured by the estimated degree of queuing and packet loss.<a href="#section-3.4.1-2.2.1" class="pilcrow">¶</a></p>
</li>
          </ul>
<p id="section-3.4.1-3">Note that those two aspects are in tension: the highest throughput is available
to the flow when it sends as fast as possible and occupies as many bottleneck
buffer slots as possible; the lowest queue pressure is achieved by the flow
when it sends as slow as possible and occupies as few bottleneck buffer slots
as possible. To resolve the tension, the algorithm aims to achieve the maximum
throughput achievable while still meeting the queue pressure objective.<a href="#section-3.4.1-3" class="pilcrow">¶</a></p>
</section>
</div>
<div id="time-scales-for-the-network-model">
<section id="section-3.4.2">
          <h4 id="name-time-scales-for-the-network">
<a href="#section-3.4.2" class="section-number selfRef">3.4.2. </a><a href="#name-time-scales-for-the-network" class="section-name selfRef">Time Scales for the Network Model</a>
          </h4>
<p id="section-3.4.2-1">At a high level, the BBR model is trying to reflect the properties of the
network path on two different time scales:<a href="#section-3.4.2-1" class="pilcrow">¶</a></p>
<div id="long-term-model">
<section id="section-3.4.2.1">
            <h5 id="name-long-term-model">
<a href="#section-3.4.2.1" class="section-number selfRef">3.4.2.1. </a><a href="#name-long-term-model" class="section-name selfRef">Long-term model</a>
            </h5>
<p id="section-3.4.2.1-1">One goal is for BBR to maintain high average utilization of the fair share
of the available bandwidth, over long time intervals. This requires estimates
of the path's data rate and volume capacities that are robust over long time
intervals. This means being robust to congestion signals that may be noisy
or may reflect short-term congestion that has already abated by the time
an ACK arrives. This also means providing a robust history of the best
recently-achievable performance on the path so that the flow can quickly and
robustly aim to re-probe that level of performance whenever it decides to probe
the capacity of the path.<a href="#section-3.4.2.1-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="short-term-model">
<section id="section-3.4.2.2">
            <h5 id="name-short-term-model">
<a href="#section-3.4.2.2" class="section-number selfRef">3.4.2.2. </a><a href="#name-short-term-model" class="section-name selfRef">Short-term model</a>
            </h5>
<p id="section-3.4.2.2-1">A second goal of BBR is to react to every congestion signal, including loss,
as if it may indicate a persistent/long-term increase in congestion and/or
decrease in the bandwidth available to the flow, because that may indeed
be the case.<a href="#section-3.4.2.2-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="time-scale-strategy">
<section id="section-3.4.2.3">
            <h5 id="name-time-scale-strategy">
<a href="#section-3.4.2.3" class="section-number selfRef">3.4.2.3. </a><a href="#name-time-scale-strategy" class="section-name selfRef">Time Scale Strategy</a>
            </h5>
<p id="section-3.4.2.3-1">BBR sequentially alternates between spending most of its time using short-term
models to conservatively respect all congestion signals in case they represent
persistent congestion, but periodically using its long-term model to robustly
probe the limits of the available path capacity in case the congestion has
abated and more capacity is available.<a href="#section-3.4.2.3-1" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
</section>
</div>
<div id="control-parameter-overview">
<section id="section-3.5">
        <h3 id="name-control-parameter-overview">
<a href="#section-3.5" class="section-number selfRef">3.5. </a><a href="#name-control-parameter-overview" class="section-name selfRef">Control Parameter Overview</a>
        </h3>
<p id="section-3.5-1">BBR uses its model to control the connection's sending behavior. Rather than
using a single control parameter, like the C.cwnd parameter that limits
C.inflight in the Reno and CUBIC congestion control algorithms,
BBR uses three distinct control parameters: C.pacing_race, C.send_quantum,
and C.cwnd, defined in (<a href="#output-control-parameters" class="auto internal xref">Section 2.4</a>):<a href="#section-3.5-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="environment-and-usage">
<section id="section-3.6">
        <h3 id="name-environment-and-usage">
<a href="#section-3.6" class="section-number selfRef">3.6. </a><a href="#name-environment-and-usage" class="section-name selfRef">Environment and Usage</a>
        </h3>
<p id="section-3.6-1">BBR is a congestion control algorithm that is agnostic to transport-layer
and link-layer technologies, requires only sender-side changes, and does
not require changes in the network. Open source implementations of BBR are
available for the TCP <span>[<a href="#RFC9293" class="cite xref">RFC9293</a>]</span> and QUIC <span>[<a href="#RFC9000" class="cite xref">RFC9000</a>]</span> transport
protocols, and these implementations have been used in production
for a large volume of Internet traffic. An open source implementation of
BBR is also available for DCCP <span>[<a href="#RFC4340" class="cite xref">RFC4340</a>]</span>  <span>[<a href="#draft-romo-iccrg-ccid5" class="cite xref">draft-romo-iccrg-ccid5</a>]</span>.<a href="#section-3.6-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="ecn">
<section id="section-3.7">
        <h3 id="name-ecn">
<a href="#section-3.7" class="section-number selfRef">3.7. </a><a href="#name-ecn" class="section-name selfRef">ECN</a>
        </h3>
<p id="section-3.7-1">This experimental version of BBR does not specify a specific response to
Classic <span>[<a href="#RFC3168" class="cite xref">RFC3168</a>]</span>, Alternative Backoff with ECN (ABE) <span>[<a href="#RFC8511" class="cite xref">RFC8511</a>]</span> or
L4S <span>[<a href="#RFC9330" class="cite xref">RFC9330</a>]</span> style ECN. However, if the connection claims ECN support
by marking packets using either the ECT(0) or ECT(1) code point,
the congestion controller response MUST treat any CE marks as congestion.<a href="#section-3.7-1" class="pilcrow">¶</a></p>
<p id="section-3.7-2"><span>[<a href="#RFC8311" class="cite xref">RFC8311</a>], <a href="https://rfc-editor.org/rfc/rfc8311#section-4.1" class="relref">Section 4.1</a></span> relaxes the requirement from RFC3168 that the
congestion response to CE marks be identical to packet loss.
The congestion response requirements of L4S are detailed in
<span>[<a href="#RFC9330" class="cite xref">RFC9330</a>], <a href="https://rfc-editor.org/rfc/rfc9330#section-4.3" class="relref">Section 4.3</a></span>.<a href="#section-3.7-2" class="pilcrow">¶</a></p>
</section>
</div>
<div id="experimental-status">
<section id="section-3.8">
        <h3 id="name-experimental-status">
<a href="#section-3.8" class="section-number selfRef">3.8. </a><a href="#name-experimental-status" class="section-name selfRef">Experimental Status</a>
        </h3>
<p id="section-3.8-1">This draft is experimental because there are some known aspects of BBR
for which the community is encouraged to conduct experiments and develop
algorithm improvements, as described below.<a href="#section-3.8-1" class="pilcrow">¶</a></p>
<p id="section-3.8-2">As noted above in <a href="#ecn" class="auto internal xref">Section 3.7</a>, BBR as described in this draft does not
specify a specific response to ECN, and instead leaves it as an area for
future work.<a href="#section-3.8-2" class="pilcrow">¶</a></p>
<p id="section-3.8-3">The delivery rate sampling algorithm in <a href="#delivery-rate-samples" class="auto internal xref">Section 4.1</a>
has an ability to over-estimate delivery rate, as described in
<a href="#compression-and-aggregation" class="auto internal xref">Section 4.1.1.2.2</a>. When combined with BBR's windowed
maximum bandwidth filter, this can cause BBR to send too quickly.
BBR mitigates this by limiting any bandwidth sample by the sending rate,
but that still might be higher than the available bandwidth,
particularly in STARTUP.<a href="#section-3.8-3" class="pilcrow">¶</a></p>
<p id="section-3.8-4">BBR does not deal well with persistently application limited traffic
<a href="#detecting-application-limited-phases" class="auto internal xref">Section 4.1.2.4</a> , such as low latency audio or
video flows.  When unable to fill the pipe for a full round trip,
BBR will not be able to measure the full link bandwidth, and will mark
a bandwidth sample as app-limited. In cases where an application enters
a phase where all bandwidth samples are app-limited, BBR will not
discard old max bandwidth samples that were not app-limited.<a href="#section-3.8-4" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
<div id="input-signals">
<section id="section-4">
      <h2 id="name-input-signals">
<a href="#section-4" class="section-number selfRef">4. </a><a href="#name-input-signals" class="section-name selfRef">Input Signals</a>
      </h2>
<p id="section-4-1">BBR uses estimated delivery rate and RTT as two critical inputs.<a href="#section-4-1" class="pilcrow">¶</a></p>
<div id="delivery-rate-samples">
<section id="section-4.1">
        <h3 id="name-delivery-rate-samples">
<a href="#section-4.1" class="section-number selfRef">4.1. </a><a href="#name-delivery-rate-samples" class="section-name selfRef">Delivery Rate Samples</a>
        </h3>
<p id="section-4.1-1">This section describes a generic algorithm for a transport protocol sender to
estimate the current delivery rate of its data on the fly. This technique is
used by BBR to get fresh, reliable, and inexpensive delivery rate information.<a href="#section-4.1-1" class="pilcrow">¶</a></p>
<p id="section-4.1-2">At a high level, the algorithm estimates the rate at which the network
delivered the most recent flight of outbound data packets for a single flow. In
addition, it tracks whether the rate sample was application-limited, meaning
the transmission rate was limited by the sending application rather than the
congestion control algorithm.<a href="#section-4.1-2" class="pilcrow">¶</a></p>
<p id="section-4.1-3">Each acknowledgment that cumulatively or selectively acknowledges that the
network has delivered new data produces a rate sample which records the amount
of data delivered over the time interval between the transmission of a data
packet and the acknowledgment of that packet. The samples reflect the recent
goodput through some bottleneck, which may reside either in the network or
on the end hosts (sender or receiver).<a href="#section-4.1-3" class="pilcrow">¶</a></p>
<div id="delivery-rate-sampling-algorithm-overview">
<section id="section-4.1.1">
          <h4 id="name-delivery-rate-sampling-algo">
<a href="#section-4.1.1" class="section-number selfRef">4.1.1. </a><a href="#name-delivery-rate-sampling-algo" class="section-name selfRef">Delivery Rate Sampling Algorithm Overview</a>
          </h4>
<div id="requirements">
<section id="section-4.1.1.1">
            <h5 id="name-requirements">
<a href="#section-4.1.1.1" class="section-number selfRef">4.1.1.1. </a><a href="#name-requirements" class="section-name selfRef">Requirements</a>
            </h5>
<p id="section-4.1.1.1-1">This algorithm can be implemented in any transport protocol that supports
packet-delivery acknowledgment (so far, implementations are available for TCP
<span>[<a href="#RFC9293" class="cite xref">RFC9293</a>]</span> and QUIC <span>[<a href="#RFC9000" class="cite xref">RFC9000</a>]</span>). This algorithm requires a small amount of
added logic on the sender, and requires that the sender maintain a small amount
of additional per-packet state for packets sent but not yet delivered. In the
most general case it requires high-precision (microsecond-granularity or
better) timestamps on the sender (though millisecond-granularity may suffice
for lower bandwidths).  It does not require any receiver or network
changes. While selective acknowledgments for out-of-order data (e.g.,
<span>[<a href="#RFC2018" class="cite xref">RFC2018</a>]</span>) are not required, such a mechanism is highly recommended for
accurate estimation during reordering and loss recovery phases.<a href="#section-4.1.1.1-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="estimating-delivery-rate">
<section id="section-4.1.1.2">
            <h5 id="name-estimating-delivery-rate">
<a href="#section-4.1.1.2" class="section-number selfRef">4.1.1.2. </a><a href="#name-estimating-delivery-rate" class="section-name selfRef">Estimating Delivery Rate</a>
            </h5>
<p id="section-4.1.1.2-1">A delivery rate sample records the estimated rate at which the network delivered
packets for a single flow, calculated over the time interval between the
transmission of a data packet and the acknowledgment of that packet. Since
the rate samples only include packets actually cumulatively and/or selectively
acknowledged, the sender knows the exact octets that were delivered to the
receiver (not lost), and the sender can compute an estimate of a bottleneck
delivery rate over that time interval.<a href="#section-4.1.1.2-1" class="pilcrow">¶</a></p>
<p id="section-4.1.1.2-2">The amount of data delivered MAY be tracked in units of either octets or
packets. Tracking data in units of octets is more accurate, since packet
sizes can vary. But for some purposes, including congestion control, tracking
data in units of packets may suffice.<a href="#section-4.1.1.2-2" class="pilcrow">¶</a></p>
<div id="ack-rate">
<section id="section-4.1.1.2.1">
              <h6 id="name-ack-rate">
<a href="#section-4.1.1.2.1" class="section-number selfRef">4.1.1.2.1. </a><a href="#name-ack-rate" class="section-name selfRef">ACK Rate</a>
              </h6>
<p id="section-4.1.1.2.1-1">First, consider the rate at which data is acknowledged by the receiver. In
this algorithm, the computation of the ACK rate models the average slope
of a hypothetical "delivered" curve that tracks the cumulative quantity of
data delivered so far on the Y axis, and time elapsed on the X axis. Since
ACKs arrive in discrete events, this "delivered" curve forms a step function,
where each ACK causes a discrete increase in the "delivered" count that causes
a vertical upward step up in the curve. This "ack_rate" computation is the
average slope of the "delivered" step function, as measured from the "knee"
of the step (ACK) preceding the transmit to the "knee" of the step (ACK)
for packet P.<a href="#section-4.1.1.2.1-1" class="pilcrow">¶</a></p>
<p id="section-4.1.1.2.1-2">Given this model, the ack rate sample "slope" is computed as the ratio between
the amount of data marked as delivered over this time interval, and the time
over which it is marked as delivered:<a href="#section-4.1.1.2.1-2" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.1.2.1-3">
<pre>
  ack_rate = data_acked / ack_elapsed
</pre><a href="#section-4.1.1.2.1-3" class="pilcrow">¶</a>
</div>
<p id="section-4.1.1.2.1-4">To calculate the amount of data ACKed over the interval, the sender records in
per-packet state "P.delivered", the amount of data that had been marked
delivered before transmitting packet P, and then records how much data had been
marked delivered by the time the ACK for the packet arrives (in "C.delivered"),
and computes the difference:<a href="#section-4.1.1.2.1-4" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.1.2.1-5">
<pre>
  data_acked = C.delivered - P.delivered
</pre><a href="#section-4.1.1.2.1-5" class="pilcrow">¶</a>
</div>
<p id="section-4.1.1.2.1-6">To compute the time interval, "ack_elapsed", one might imagine that it would
be feasible to use the round-trip time (RTT) of the packet. But it is not
safe to simply calculate a bandwidth estimate by using the time between the
transmit of a packet and the acknowledgment of that packet. Transmits and
ACKs can happen out of phase with each other, clocked in separate processes.
In general, transmissions often happen at some point later than the most
recent ACK, due to processing or pacing delays. Because of this effect, drastic
over-estimates can happen if a sender were to attempt to estimate bandwidth
by using the round-trip time.<a href="#section-4.1.1.2.1-6" class="pilcrow">¶</a></p>
<p id="section-4.1.1.2.1-7">The following approach computes "ack_elapsed". The starting time is
"P.delivered_time", the time of the delivery curve "knee" from the ACK
preceding the transmit.  The ending time is "C.delivered_time", the time of the
delivery curve "knee" from the ACK for P. Then we compute "ack_elapsed" as:<a href="#section-4.1.1.2.1-7" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.1.2.1-8">
<pre>
  ack_elapsed = C.delivered_time - P.delivered_time
</pre><a href="#section-4.1.1.2.1-8" class="pilcrow">¶</a>
</div>
<p id="section-4.1.1.2.1-9">This yields our equation for computing the ACK rate, as the "slope" from
the "knee" preceding the transmit to the "knee" at ACK:<a href="#section-4.1.1.2.1-9" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.1.2.1-10">
<pre>
  ack_rate = data_acked / ack_elapsed
  ack_rate = (C.delivered - P.delivered) /
             (C.delivered_time - P.delivered_time)
</pre><a href="#section-4.1.1.2.1-10" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="compression-and-aggregation">
<section id="section-4.1.1.2.2">
              <h6 id="name-compression-and-aggregation">
<a href="#section-4.1.1.2.2" class="section-number selfRef">4.1.1.2.2. </a><a href="#name-compression-and-aggregation" class="section-name selfRef">Compression and Aggregation</a>
              </h6>
<p id="section-4.1.1.2.2-1">For computing the delivery_rate, the sender prefers ack_rate, the rate at which
packets were acknowledged, since this usually the most reliable metric.
However, this approach of directly using "ack_rate" faces a challenge when used
with paths featuring aggregation, compression, or ACK decimation, which are
prevalent <span>[<a href="#A15" class="cite xref">A15</a>]</span>.  In such cases, ACK arrivals can temporarily make it appear
as if data packets were delivered much faster than the bottleneck rate. To
filter out such implausible ack_rate samples, we consider the send rate for
each flight of data, as follows.<a href="#section-4.1.1.2.2-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="send-rate">
<section id="section-4.1.1.2.3">
              <h6 id="name-send-rate">
<a href="#section-4.1.1.2.3" class="section-number selfRef">4.1.1.2.3. </a><a href="#name-send-rate" class="section-name selfRef">Send Rate</a>
              </h6>
<p id="section-4.1.1.2.3-1">The sender calculates the send rate, "send_rate", for a flight of data as
follows. Define "P.first_sent_time" as the time of the first send in a flight
of data, and "P.sent_time" as the time the final send in that flight of data
(the send that transmits packet "P"). The elapsed time for sending the flight
is:<a href="#section-4.1.1.2.3-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.1.2.3-2">
<pre>
  send_elapsed = (P.sent_time - P.first_sent_time)
</pre><a href="#section-4.1.1.2.3-2" class="pilcrow">¶</a>
</div>
<p id="section-4.1.1.2.3-3">Then we calculate the send_rate as:<a href="#section-4.1.1.2.3-3" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.1.2.3-4">
<pre>
  send_rate = data_acked / send_elapsed
</pre><a href="#section-4.1.1.2.3-4" class="pilcrow">¶</a>
</div>
<p id="section-4.1.1.2.3-5">Using our "delivery" curve model above, the send_rate can be viewed as the
average slope of a "send" curve that traces the amount of data sent on the Y
axis, and the time elapsed on the X axis: the average slope of the transmission
of this flight of data.<a href="#section-4.1.1.2.3-5" class="pilcrow">¶</a></p>
</section>
</div>
<div id="delivery-rate">
<section id="section-4.1.1.2.4">
              <h6 id="name-delivery-rate">
<a href="#section-4.1.1.2.4" class="section-number selfRef">4.1.1.2.4. </a><a href="#name-delivery-rate" class="section-name selfRef">Delivery Rate</a>
              </h6>
<p id="section-4.1.1.2.4-1">Since it is physically impossible to have data delivered faster than it is
sent in a sustained fashion, when the estimator notices that the ack_rate
for a flight is faster than the send rate for the flight, it filters out
the implausible ack_rate by capping the delivery rate sample to be no higher
than the send rate.<a href="#section-4.1.1.2.4-1" class="pilcrow">¶</a></p>
<p id="section-4.1.1.2.4-2">More precisely, over the interval between each transmission and corresponding
ACK, the sender calculates a delivery rate sample, "delivery_rate", using
the minimum of the rate at which packets were acknowledged or the rate at
which they were sent:<a href="#section-4.1.1.2.4-2" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.1.2.4-3">
<pre>
  delivery_rate = min(send_rate, ack_rate)
</pre><a href="#section-4.1.1.2.4-3" class="pilcrow">¶</a>
</div>
<p id="section-4.1.1.2.4-4">Since ack_rate and send_rate both have data_acked as a numerator, this can
be computed more efficiently with a single division (instead of two), as
follows:<a href="#section-4.1.1.2.4-4" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.1.2.4-5">
<pre>
  delivery_elapsed = max(ack_elapsed, send_elapsed)
  delivery_rate = data_acked / delivery_elapsed
</pre><a href="#section-4.1.1.2.4-5" class="pilcrow">¶</a>
</div>
</section>
</div>
</section>
</div>
<div id="tracking-application-limited-phases">
<section id="section-4.1.1.3">
            <h5 id="name-tracking-application-limite">
<a href="#section-4.1.1.3" class="section-number selfRef">4.1.1.3. </a><a href="#name-tracking-application-limite" class="section-name selfRef">Tracking application-limited phases</a>
            </h5>
<p id="section-4.1.1.3-1">In application-limited phases the transmission rate is limited by the
sending application rather than the congestion control algorithm. Modern
transport protocol connections are often application-limited, either due
to request/response workloads (e.g., Web traffic, RPC traffic) or because the
sender transmits data in chunks (e.g., adaptive streaming video).<a href="#section-4.1.1.3-1" class="pilcrow">¶</a></p>
<p id="section-4.1.1.3-2">Knowing whether a delivery rate sample was application-limited is crucial
for congestion control algorithms and applications to use the estimated delivery
rate samples properly. For example, congestion control algorithms likely
do not want to react to a delivery rate that is lower simply because the
sender is application-limited; for congestion control the key metric is the
rate at which the network path can deliver data, and not simply the rate
at which the application happens to be transmitting data at any moment.<a href="#section-4.1.1.3-2" class="pilcrow">¶</a></p>
<p id="section-4.1.1.3-3">To track this, the estimator marks a bandwidth sample as application-limited
if there was some moment during the sampled flight of data packets when there
was no data ready to send.<a href="#section-4.1.1.3-3" class="pilcrow">¶</a></p>
<p id="section-4.1.1.3-4">The algorithm detects that an application-limited phase has started when
the sending application requests to send new data, or the connection's
retransmission mechanisms decide to retransmit data, and the connection meets
all of the following conditions:<a href="#section-4.1.1.3-4" class="pilcrow">¶</a></p>
<ol start="1" type="1" class="normal type-1" id="section-4.1.1.3-5">
<li id="section-4.1.1.3-5.1">
                <p id="section-4.1.1.3-5.1.1">The transport send buffer has less than one C.SMSS of unsent data available
  to send.<a href="#section-4.1.1.3-5.1.1" class="pilcrow">¶</a></p>
</li>
              <li id="section-4.1.1.3-5.2">
                <p id="section-4.1.1.3-5.2.1">The sending flow is not currently in the process of transmitting a packet.<a href="#section-4.1.1.3-5.2.1" class="pilcrow">¶</a></p>
</li>
              <li id="section-4.1.1.3-5.3">
                <p id="section-4.1.1.3-5.3.1">The amount of data considered in flight is less than the congestion window
  (C.cwnd).<a href="#section-4.1.1.3-5.3.1" class="pilcrow">¶</a></p>
</li>
              <li id="section-4.1.1.3-5.4">
                <p id="section-4.1.1.3-5.4.1">All the packets considered lost have been retransmitted.<a href="#section-4.1.1.3-5.4.1" class="pilcrow">¶</a></p>
</li>
            </ol>
<p id="section-4.1.1.3-6">If these conditions are all met then the sender has run out of data to feed the
network. This would effectively create a "bubble" of idle time in the data
pipeline. This idle time means that any delivery rate sample obtained from this
data packet, and any rate sample from a packet that follows it in the next
round trip, is going to be an application-limited sample that potentially
underestimates the true available bandwidth. Thus, when the algorithm marks a
transport flow as application-limited, it marks all bandwidth samples for the
next round trip as application-limited (at which point, the "bubble" can be
said to have exited the data pipeline).<a href="#section-4.1.1.3-6" class="pilcrow">¶</a></p>
<div id="considerations-related-to-receiver-flow-control-limits">
<section id="section-4.1.1.3.1">
              <h6 id="name-considerations-related-to-r">
<a href="#section-4.1.1.3.1" class="section-number selfRef">4.1.1.3.1. </a><a href="#name-considerations-related-to-r" class="section-name selfRef">Considerations Related to Receiver Flow Control Limits</a>
              </h6>
<p id="section-4.1.1.3.1-1">In some cases receiver flow control limits (such as the TCP <span>[<a href="#RFC9293" class="cite xref">RFC9293</a>]</span>
advertised receive window, RCV.WND) are the factor limiting the
delivery rate. This algorithm treats cases where the delivery rate was constrained
by such conditions the same as it treats cases where the delivery rate is
constrained by in-network bottlenecks. That is, it treats receiver bottlenecks
the same as network bottlenecks. This has a conceptual symmetry and has worked
well in practice for congestion control and telemetry purposes.<a href="#section-4.1.1.3.1-1" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
</section>
</div>
<div id="detailed-delivery-rate-sampling-algorithm">
<section id="section-4.1.2">
          <h4 id="name-detailed-delivery-rate-samp">
<a href="#section-4.1.2" class="section-number selfRef">4.1.2. </a><a href="#name-detailed-delivery-rate-samp" class="section-name selfRef">Detailed Delivery Rate Sampling Algorithm</a>
          </h4>
<div id="variables">
<section id="section-4.1.2.1">
            <h5 id="name-variables">
<a href="#section-4.1.2.1" class="section-number selfRef">4.1.2.1. </a><a href="#name-variables" class="section-name selfRef">Variables</a>
            </h5>
<div id="per-connection-c-state">
<section id="section-4.1.2.1.1">
              <h6 id="name-per-connection-c-state">
<a href="#section-4.1.2.1.1" class="section-number selfRef">4.1.2.1.1. </a><a href="#name-per-connection-c-state" class="section-name selfRef">Per-connection (C) state</a>
              </h6>
<p id="section-4.1.2.1.1-1">This algorithm requires the following new state variables for each transport
connection:<a href="#section-4.1.2.1.1-1" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.1-2">C.delivered_time: The wall clock time when C.delivered was last updated.<a href="#section-4.1.2.1.1-2" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.1-3">C.first_sent_time: If packets are in flight, then this holds the send time of
the packet that was most recently marked as delivered. Else, if the connection
was recently idle, then this holds the send time of most recently sent packet.<a href="#section-4.1.2.1.1-3" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.1-4">C.app_limited: The index of the last transmitted packet marked as
application-limited, or 0 if the connection is not currently
application-limited.<a href="#section-4.1.2.1.1-4" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.1-5">We also assume that the transport protocol sender implementation tracks the
following state per connection. If the following state variables are not
tracked by an existing implementation, all the following parameters MUST
be tracked to implement this algorithm:<a href="#section-4.1.2.1.1-5" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.1-6">C.pending_transmissions: The number of bytes queued for transmission on the
sending host at layers lower than the transport layer (i.e. network layer,
traffic shaping layer, network device layer).<a href="#section-4.1.2.1.1-6" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.1-7">C.lost_out: The number of packets in the current outstanding window that
are marked as lost.<a href="#section-4.1.2.1.1-7" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.1-8">C.retrans_out: The number of packets in the current outstanding window that
are being retransmitted.<a href="#section-4.1.2.1.1-8" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.1-9">C.min_rtt: The minimum observed RTT over the lifetime of the connection.<a href="#section-4.1.2.1.1-9" class="pilcrow">¶</a></p>
</section>
</div>
<div id="per-packet-p-state">
<section id="section-4.1.2.1.2">
              <h6 id="name-per-packet-p-state">
<a href="#section-4.1.2.1.2" class="section-number selfRef">4.1.2.1.2. </a><a href="#name-per-packet-p-state" class="section-name selfRef">Per-packet (P) state</a>
              </h6>
<p id="section-4.1.2.1.2-1">This algorithm requires the following new state variables for each packet
that has been transmitted but has not been acknowledged:<a href="#section-4.1.2.1.2-1" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.2-2">P.delivered: C.delivered when the packet was sent from transport connection
C.<a href="#section-4.1.2.1.2-2" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.2-3">P.delivered_time: C.delivered_time when the packet was sent.<a href="#section-4.1.2.1.2-3" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.2-4">P.first_sent_time: C.first_sent_time when the packet was sent.<a href="#section-4.1.2.1.2-4" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.2-5">P.is_app_limited: true if C.app_limited was non-zero when the packet was
sent, else false.<a href="#section-4.1.2.1.2-5" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.2-6">P.sent_time: The time when the packet was sent.<a href="#section-4.1.2.1.2-6" class="pilcrow">¶</a></p>
</section>
</div>
<div id="rate-sample-rs-output">
<section id="section-4.1.2.1.3">
              <h6 id="name-rate-sample-rs-output">
<a href="#section-4.1.2.1.3" class="section-number selfRef">4.1.2.1.3. </a><a href="#name-rate-sample-rs-output" class="section-name selfRef">Rate Sample (rs) Output</a>
              </h6>
<p id="section-4.1.2.1.3-1">This algorithm provides its output in a RateSample structure rs, containing
the following fields:<a href="#section-4.1.2.1.3-1" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.3-2">RS.delivery_rate: The delivery rate sample (in most cases RS.delivered /
RS.interval).<a href="#section-4.1.2.1.3-2" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.3-3">RS.is_app_limited: The P.is_app_limited from the most recent packet delivered;
indicates whether the rate sample is application-limited.<a href="#section-4.1.2.1.3-3" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.3-4">RS.interval: The length of the sampling interval.<a href="#section-4.1.2.1.3-4" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.3-5">RS.delivered: The amount of data marked as delivered over the sampling interval.<a href="#section-4.1.2.1.3-5" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.3-6">RS.prior_delivered: The P.delivered count from the most recent packet delivered.<a href="#section-4.1.2.1.3-6" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.3-7">RS.prior_time: The P.delivered_time from the most recent packet delivered.<a href="#section-4.1.2.1.3-7" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.3-8">RS.send_elapsed: Send time interval calculated from the most recent packet
delivered (see the "Send Rate" section above).<a href="#section-4.1.2.1.3-8" class="pilcrow">¶</a></p>
<p id="section-4.1.2.1.3-9">RS.ack_elapsed: ACK time interval calculated from the most recent packet
delivered (see the "ACK Rate" section above).<a href="#section-4.1.2.1.3-9" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
<div id="transmitting-a-data-packet">
<section id="section-4.1.2.2">
            <h5 id="name-transmitting-a-data-packet">
<a href="#section-4.1.2.2" class="section-number selfRef">4.1.2.2. </a><a href="#name-transmitting-a-data-packet" class="section-name selfRef">Transmitting a data packet</a>
            </h5>
<p id="section-4.1.2.2-1">Upon transmitting a data packet, the sender snapshots the current delivery
information in per-packet state. This will allow the sender
to generate a rate sample later, in the UpdateRateSample() step, when the
packet is (S)ACKed.<a href="#section-4.1.2.2-1" class="pilcrow">¶</a></p>
<p id="section-4.1.2.2-2">If there are packets already in flight, then we need to start delivery rate
samples from the time we received the most recent ACK, to try to ensure that
we include the full time the network needs to deliver all in-flight data.
If there is no data in flight yet, then we can start the delivery rate
interval at the current time, since we know that any ACKs after now indicate
that the network was able to deliver that data completely in the sampling
interval between now and the next ACK.<a href="#section-4.1.2.2-2" class="pilcrow">¶</a></p>
<p id="section-4.1.2.2-3">After each packet transmission, the sender executes the following steps:<a href="#section-4.1.2.2-3" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.2.2-4">
<pre>
  OnPacketSent(Packet P):
    if (C.inflight == 0)
      C.first_sent_time  = C.delivered_time = P.sent_time

    P.first_sent_time = C.first_sent_time
    P.delivered_time  = C.delivered_time
    P.delivered       = C.delivered
    P.is_app_limited  = (C.app_limited != 0)
</pre><a href="#section-4.1.2.2-4" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="upon-receiving-an-ack">
<section id="section-4.1.2.3">
            <h5 id="name-upon-receiving-an-ack">
<a href="#section-4.1.2.3" class="section-number selfRef">4.1.2.3. </a><a href="#name-upon-receiving-an-ack" class="section-name selfRef">Upon receiving an ACK</a>
            </h5>
<p id="section-4.1.2.3-1">When an ACK arrives, the sender invokes GenerateRateSample() to fill in a
rate sample. For each  packet that was newly acknowledged, UpdateRateSample()
updates the rate sample based on a snapshot of connection delivery information
from the time at which the packet was last transmitted. UpdateRateSample()
is invoked multiple times when a stretched ACK acknowledges multiple data
packets. In this case we use the information from the most recently sent
packet, i.e., the packet with the highest "P.delivered" value.<a href="#section-4.1.2.3-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.2.3-2">
<pre>
  /* Upon receiving ACK, fill in delivery rate sample RS. */
  GenerateRateSample(RS):
    for each newly acknowledged packet P
      UpdateRateSample(P, RS)

    /* Clear app-limited field if bubble is ACKed and gone. */
    if (C.app_limited and C.delivered &gt; C.app_limited)
      C.app_limited = 0

    if (RS.prior_time == 0)
      return false  /* nothing delivered on this ACK */

    /* Use the longer of the send_elapsed and ack_elapsed */
    RS.interval = max(RS.send_elapsed, RS.ack_elapsed)

    RS.delivered = C.delivered - RS.prior_delivered

    /* Normally we expect interval &gt;= MinRTT.
     * Note that rate may still be overestimated when a spuriously
     * retransmitted skb was first (s)acked because "interval"
     * is under-estimated (up to an RTT). However, continuously
     * measuring the delivery rate during loss recovery is crucial
     * for connections that suffer heavy or prolonged losses.
     */
    if (RS.interval &lt;  C.min_rtt)
      RS.interval = -1
      return false  /* no reliable sample */

    if (RS.interval != 0)
      RS.delivery_rate = RS.delivered / RS.interval

    return true;  /* we filled in rs with a rate sample */

  /* Update rs when a packet is acknowledged. */
  UpdateRateSample(Packet P, RateSample rs):
    if (P.delivered_time == 0)
      return /* P already acknowledged */

    C.delivered += P.data_length
    C.delivered_time = Now()

    /* Update info using the newest packet: */
    if (!RS.has_data or IsNewestPacket(P, rs))
      RS.has_data         = true
      RS.prior_delivered  = P.delivered
      RS.prior_time       = P.delivered_time
      RS.is_app_limited   = P.is_app_limited
      RS.send_elapsed     = P.sent_time - P.first_sent_time
      RS.ack_elapsed      = C.delivered_time - P.delivered_time
      RS.last_end_seq     = P.end_seq
      C.first_sent_time   = P.sent_time

    /* Mark the packet as delivered once it's acknowleged. */
    P.delivered_time = 0

  /* Is the given Packet the most recently sent packet
   * that has been delivered? */
  IsNewestPacket(Packet P, RateSample rs):
    return (P.sent_time &gt; C.first_sent_time or
            (P.sent_time == C.first_sent_time and
             after(P.end_seq, RS.last_end_seq))
</pre><a href="#section-4.1.2.3-2" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="detecting-application-limited-phases">
<section id="section-4.1.2.4">
            <h5 id="name-detecting-application-limit">
<a href="#section-4.1.2.4" class="section-number selfRef">4.1.2.4. </a><a href="#name-detecting-application-limit" class="section-name selfRef">Detecting application-limited phases</a>
            </h5>
<p id="section-4.1.2.4-1">An application-limited phase starts when the connection decides to send more
data, at a point in time when the connection had previously run out of data.
Some decisions to send more data are triggered by the application writing
more data to the connection, and some are triggered by loss detection (during
ACK processing or upon the triggering of a timer) estimating that some sequence
ranges need to be retransmitted. To detect all such cases, the algorithm
calls CheckIfApplicationLimited() to check for application-limited behavior in
the following situations:<a href="#section-4.1.2.4-1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-4.1.2.4-2.1">
                <p id="section-4.1.2.4-2.1.1">The sending application asks the transport layer to send more data; i.e.,
upon each write from the application, before new application data is enqueued
in the transport send buffer or transmitted.<a href="#section-4.1.2.4-2.1.1" class="pilcrow">¶</a></p>
</li>
              <li class="normal" id="section-4.1.2.4-2.2">
                <p id="section-4.1.2.4-2.2.1">At the beginning of ACK processing, before updating the estimated number
of packets in flight, and before congestion control modifies C.cwnd or
C.pacing_rate.<a href="#section-4.1.2.4-2.2.1" class="pilcrow">¶</a></p>
</li>
              <li class="normal" id="section-4.1.2.4-2.3">
                <p id="section-4.1.2.4-2.3.1">At the beginning of connection timer processing, for all timers that might
result in the transmission of one or more data packets. For example: RTO
timers, TLP timers, RACK reordering timers, or Zero Window Probe timers.<a href="#section-4.1.2.4-2.3.1" class="pilcrow">¶</a></p>
</li>
            </ul>
<p id="section-4.1.2.4-3">When checking for application-limited behavior, the connection checks all the
conditions previously described in the "Tracking application-limited phases"
section, and if all are met then it marks the connection as
application-limited:<a href="#section-4.1.2.4-3" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.1.2.4-4">
<pre>
  CheckIfApplicationLimited():
    if (NoUnsentData() and
        C.pending_transmissions == 0 and
        C.inflight &lt; C.cwnd and
        C.lost_out &lt;= C.retrans_out)
      C.app_limited = (C.delivered + C.inflight) ? : 1
</pre><a href="#section-4.1.2.4-4" class="pilcrow">¶</a>
</div>
</section>
</div>
</section>
</div>
<div id="delivery-rate-sampling-discussion">
<section id="section-4.1.3">
          <h4 id="name-delivery-rate-sampling-disc">
<a href="#section-4.1.3" class="section-number selfRef">4.1.3. </a><a href="#name-delivery-rate-sampling-disc" class="section-name selfRef">Delivery Rate Sampling Discussion</a>
          </h4>
<div id="offload-mechanisms">
<section id="section-4.1.3.1">
            <h5 id="name-offload-mechanisms">
<a href="#section-4.1.3.1" class="section-number selfRef">4.1.3.1. </a><a href="#name-offload-mechanisms" class="section-name selfRef">Offload Mechanisms</a>
            </h5>
<p id="section-4.1.3.1-1">If a transport sender implementation uses an offload mechanism (such as TSO,
GSO, etc.) to combine multiple C.SMSS of data into a single packet "aggregate"
for the purposes of scheduling transmissions, then it is RECOMMENDED that
the per-packet state be tracked for each packet "aggregate" rather than each
SMSS. For simplicity this document refers to such state as "per-packet",
whether it is per "aggregate" or per C.SMSS.<a href="#section-4.1.3.1-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="impact-of-ack-losses">
<section id="section-4.1.3.2">
            <h5 id="name-impact-of-ack-losses">
<a href="#section-4.1.3.2" class="section-number selfRef">4.1.3.2. </a><a href="#name-impact-of-ack-losses" class="section-name selfRef">Impact of ACK losses</a>
            </h5>
<p id="section-4.1.3.2-1">Delivery rate samples are generated upon receiving each ACK; ACKs may contain
both cumulative and selective acknowledgment information. Losing an ACK results
in losing the delivery rate sample corresponding to that ACK, and generating a
delivery rate sample at later a time (upon the arrival of the next ACK). This
can underestimate the delivery rate due the artificially inflated
"RS.interval". The impact of this effect is mitigated using the BBR.max_bw
filter.<a href="#section-4.1.3.2-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="impact-of-packet-reordering">
<section id="section-4.1.3.3">
            <h5 id="name-impact-of-packet-reordering">
<a href="#section-4.1.3.3" class="section-number selfRef">4.1.3.3. </a><a href="#name-impact-of-packet-reordering" class="section-name selfRef">Impact of packet reordering</a>
            </h5>
<p id="section-4.1.3.3-1">This algorithm is robust to packet reordering; it makes no assumptions about
the order in which packets are delivered or ACKed. In particular, for a
particular packet P, it does not matter which packets are delivered between the
transmission of P and the ACK of packet P, since C.delivered will be
incremented appropriately in any case.<a href="#section-4.1.3.3-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="impact-of-packet-loss-and-retransmissions">
<section id="section-4.1.3.4">
            <h5 id="name-impact-of-packet-loss-and-r">
<a href="#section-4.1.3.4" class="section-number selfRef">4.1.3.4. </a><a href="#name-impact-of-packet-loss-and-r" class="section-name selfRef">Impact of packet loss and retransmissions</a>
            </h5>
<p id="section-4.1.3.4-1">There are several possible approaches for handling cases where a delivery
rate sample is based on a retransmitted packet.<a href="#section-4.1.3.4-1" class="pilcrow">¶</a></p>
<p id="section-4.1.3.4-2">If the transport protocol supports unambiguous ACKs for retransmitted data
(as in QUIC <span>[<a href="#RFC9000" class="cite xref">RFC9000</a>]</span>) then the algorithm is perfectly robust to retransmissions,
because the starting packet, P, for the sample can be unambiguously retrieved.<a href="#section-4.1.3.4-2" class="pilcrow">¶</a></p>
<p id="section-4.1.3.4-3">If the transport protocol, like TCP <span>[<a href="#RFC9293" class="cite xref">RFC9293</a>]</span>, has ambiguous ACKs for
retransmitted sequence ranges, then the following approaches MAY be used:<a href="#section-4.1.3.4-3" class="pilcrow">¶</a></p>
<ol start="1" type="1" class="normal type-1" id="section-4.1.3.4-4">
<li id="section-4.1.3.4-4.1">
                <p id="section-4.1.3.4-4.1.1">The sender MAY choose to filter out implausible delivery rate samples, as
  described in the GenerateRateSample() step in the "Upon receiving an ACK"
  section, by discarding samples whose RS.interval is lower than the minimum
  RTT seen on the connection.<a href="#section-4.1.3.4-4.1.1" class="pilcrow">¶</a></p>
</li>
              <li id="section-4.1.3.4-4.2">
                <p id="section-4.1.3.4-4.2.1">The sender MAY choose to skip the generation of a delivery rate sample for
  a retransmitted sequence range.<a href="#section-4.1.3.4-4.2.1" class="pilcrow">¶</a></p>
</li>
            </ol>
<div id="connections-without-sack">
<section id="section-4.1.3.4.1">
              <h6 id="name-tcp-connections-without-sac">
<a href="#section-4.1.3.4.1" class="section-number selfRef">4.1.3.4.1. </a><a href="#name-tcp-connections-without-sac" class="section-name selfRef">TCP Connections without SACK</a>
              </h6>
<p id="section-4.1.3.4.1-1">Whenever possibile, TCP connections using BBR as a congestion controller SHOULD
use both SACK and timestamps. Failure to do so will cause BBR's RTT and
bandwidth measurements to be much less accurate.<a href="#section-4.1.3.4.1-1" class="pilcrow">¶</a></p>
<p id="section-4.1.3.4.1-2">When using TCP without SACK (i.e., either or both ends of the connections do
not accept SACK), this algorithm can be extended to estimate approximate
delivery rates using duplicate ACKs (much like Reno and <span>[<a href="#RFC5681" class="cite xref">RFC5681</a>]</span> estimates
that each duplicate ACK indicates that a data packet has been delivered).<a href="#section-4.1.3.4.1-2" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
</section>
</div>
</section>
</div>
<div id="rtt-samples">
<section id="section-4.2">
        <h3 id="name-rtt-samples">
<a href="#section-4.2" class="section-number selfRef">4.2. </a><a href="#name-rtt-samples" class="section-name selfRef">RTT Samples</a>
        </h3>
<p id="section-4.2-1">Upon transmitting each packet, BBR or the associated transport protocol
stores in per-packet data the wall-clock scheduled transmission time of the
packet in P.departure_time (see "Pacing Rate: C.pacing_rate" in
<a href="#pacing-rate-bbrpacingrate" class="auto internal xref">Section 5.6.2</a> for how this is calculated).<a href="#section-4.2-1" class="pilcrow">¶</a></p>
<p id="section-4.2-2">For every ACK that newly acknowledges data, the sender's BBR implementation
or the associated transport protocol implementation attempts to calculate an
RTT sample. The sender MUST consider any potential retransmission ambiguities
that can arise in some transport protocols. If some of the acknowledged data
was not retransmitted, or some of the data was retransmitted but the sender
can still unambiguously determine the RTT of the data (e.g. QUIC or TCP with
timestamps <span>[<a href="#RFC7323" class="cite xref">RFC7323</a>]</span>), then the sender calculates an RTT sample, RS.rtt,
as follows:<a href="#section-4.2-2" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-4.2-3">
<pre>
  RS.rtt = Now() - P.departure_time
</pre><a href="#section-4.2-3" class="pilcrow">¶</a>
</div>
</section>
</div>
</section>
</div>
<div id="detailed-algorithm">
<section id="section-5">
      <h2 id="name-detailed-algorithm">
<a href="#section-5" class="section-number selfRef">5. </a><a href="#name-detailed-algorithm" class="section-name selfRef">Detailed Algorithm</a>
      </h2>
<div id="state-machine">
<section id="section-5.1">
        <h3 id="name-state-machine">
<a href="#section-5.1" class="section-number selfRef">5.1. </a><a href="#name-state-machine" class="section-name selfRef">State Machine</a>
        </h3>
<p id="section-5.1-1">BBR implements a state machine that uses the network path model to guide
its decisions, and the control parameters to enact its decisions.<a href="#section-5.1-1" class="pilcrow">¶</a></p>
<div id="state-transition-diagram">
<section id="section-5.1.1">
          <h4 id="name-state-transition-diagram">
<a href="#section-5.1.1" class="section-number selfRef">5.1.1. </a><a href="#name-state-transition-diagram" class="section-name selfRef">State Transition Diagram</a>
          </h4>
<p id="section-5.1.1-1">The following state transition diagram summarizes the flow of control and
the relationship between the different states:<a href="#section-5.1.1-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.1.1-2">
<pre>
             |
             V
    +---&gt; Startup  ------------+
    |        |                 |
    |        V                 |
    |     Drain  --------------+
    |        |                 |
    |        V                 |
    +---&gt; ProbeBW_DOWN  -------+
    | ^      |                 |
    | |      V                 |
    | |   ProbeBW_CRUISE ------+
    | |      |                 |
    | |      V                 |
    | |   ProbeBW_REFILL  -----+
    | |      |                 |
    | |      V                 |
    | |   ProbeBW_UP  ---------+
    | |      |                 |
    | +------+                 |
    |                          |
    +---- ProbeRTT &lt;-----------+
</pre><a href="#section-5.1.1-2" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="state-machine-operation-overview">
<section id="section-5.1.2">
          <h4 id="name-state-machine-operation-ove">
<a href="#section-5.1.2" class="section-number selfRef">5.1.2. </a><a href="#name-state-machine-operation-ove" class="section-name selfRef">State Machine Operation Overview</a>
          </h4>
<p id="section-5.1.2-1">When starting up, BBR probes to try to quickly build a model of the network
path; to adapt to later changes to the path or its traffic, BBR must continue
to probe to update its model. If the available bottleneck bandwidth increases,
BBR must send faster to discover this. Likewise, if the round-trip propagation
delay changes, this changes the BDP, and thus BBR must send slower to get
C.inflight below the new BDP in order to measure the new BBR.min_rtt. Thus,
BBR's state machine runs periodic, sequential experiments, sending faster
to check for BBR.bw increases or sending slower to yield bandwidth, drain
the queue, and check for BBR.min_rtt decreases. The frequency, magnitude,
duration, and structure of these experiments differ depending on what's already
known (startup or steady-state) and application sending behavior (intermittent
or continuous).<a href="#section-5.1.2-1" class="pilcrow">¶</a></p>
<p id="section-5.1.2-2">This state machine has several goals:<a href="#section-5.1.2-2" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.1.2-3.1">
              <p id="section-5.1.2-3.1.1">Achieve high throughput by efficiently utilizing available bandwidth.<a href="#section-5.1.2-3.1.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.1.2-3.2">
              <p id="section-5.1.2-3.2.1">Achieve low latency and packet loss rates by keeping queues bounded and small.<a href="#section-5.1.2-3.2.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.1.2-3.3">
              <p id="section-5.1.2-3.3.1">Share bandwidth with other flows in an approximately fair manner.<a href="#section-5.1.2-3.3.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.1.2-3.4">
              <p id="section-5.1.2-3.4.1">Feed samples to the model estimators to refresh and update the model.<a href="#section-5.1.2-3.4.1" class="pilcrow">¶</a></p>
</li>
          </ul>
</section>
</div>
<div id="state-machine-tactics">
<section id="section-5.1.3">
          <h4 id="name-state-machine-tactics">
<a href="#section-5.1.3" class="section-number selfRef">5.1.3. </a><a href="#name-state-machine-tactics" class="section-name selfRef">State Machine Tactics</a>
          </h4>
<p id="section-5.1.3-1">In the BBR framework, at any given time the sender can choose one of the
following tactics:<a href="#section-5.1.3-1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.1.3-2.1">
              <p id="section-5.1.3-2.1.1">Acceleration: Send faster then the network is delivering data: to probe the
maximum bandwidth available to the flow<a href="#section-5.1.3-2.1.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.1.3-2.2">
              <p id="section-5.1.3-2.2.1">Deceleration: Send slower than the network is delivering data: to reduce
the amount of data in flight, with a number of overlapping motivations:<a href="#section-5.1.3-2.2.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.1.3-2.2.2.1">
                  <p id="section-5.1.3-2.2.2.1.1">Reducing queuing delay: to reduce queuing delay, to reduce latency for
request/response cross-traffic (e.g. RPC, web traffic).<a href="#section-5.1.3-2.2.2.1.1" class="pilcrow">¶</a></p>
</li>
                <li class="normal" id="section-5.1.3-2.2.2.2">
                  <p id="section-5.1.3-2.2.2.2.1">Reducing packet loss: to reduce packet loss, to reduce tail latency for
request/response cross-traffic (e.g. RPC, web traffic) and improve
coexistence with Reno/CUBIC.<a href="#section-5.1.3-2.2.2.2.1" class="pilcrow">¶</a></p>
</li>
                <li class="normal" id="section-5.1.3-2.2.2.3">
                  <p id="section-5.1.3-2.2.2.3.1">Probing BBR.min_rtt: to probe the path's BBR.min_rtt<a href="#section-5.1.3-2.2.2.3.1" class="pilcrow">¶</a></p>
</li>
                <li class="normal" id="section-5.1.3-2.2.2.4">
                  <p id="section-5.1.3-2.2.2.4.1">Bandwidth convergence: to aid bandwidth fairness convergence, by leaving
unused capacity in the bottleneck link or bottleneck buffer, to allow other
flows that may have lower sending rates to discover and utilize the unused
capacity<a href="#section-5.1.3-2.2.2.4.1" class="pilcrow">¶</a></p>
</li>
                <li class="normal" id="section-5.1.3-2.2.2.5">
                  <p id="section-5.1.3-2.2.2.5.1">Burst tolerance: to allow bursty arrivals of cross-traffic (e.g. short web
or RPC requests) to be able to share the bottleneck link without causing
excessive queuing delay or packet loss<a href="#section-5.1.3-2.2.2.5.1" class="pilcrow">¶</a></p>
</li>
              </ul>
</li>
            <li class="normal" id="section-5.1.3-2.3">
              <p id="section-5.1.3-2.3.1">Cruising: Send at the same rate the network is delivering data: try to match
the sending rate to the flow's current available bandwidth, to try to achieve
high utilization of the available bandwidth without increasing queue pressure<a href="#section-5.1.3-2.3.1" class="pilcrow">¶</a></p>
</li>
          </ul>
<p id="section-5.1.3-3">Throughout the lifetime of a BBR flow, it sequentially cycles through all
three tactics, to measure the network path and try to optimize its operating
point.<a href="#section-5.1.3-3" class="pilcrow">¶</a></p>
<p id="section-5.1.3-4">BBR's state machine uses two control mechanisms: the BBR.pacing_gain and the
C.cwnd. Primarily, it uses BBR.pacing_gain (see the "Pacing Rate" section), which
controls how fast packets are sent relative to BBR.bw. A BBR.pacing_gain &gt; 1
decreases inter-packet time and increases C.inflight. A BBR.pacing_gain &lt; 1 has the
opposite effect, increasing inter-packet time and while aiming to decrease
C.inflight. C.cwnd is sufficiently larger than the BDP to allow the higher
pacing gain to accumulate more packets in flight. Only if the state machine
needs to quickly reduce C.inflight to a particular absolute value, it uses
C.cwnd.<a href="#section-5.1.3-4" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
<div id="algorithm-organization">
<section id="section-5.2">
        <h3 id="name-algorithm-organization">
<a href="#section-5.2" class="section-number selfRef">5.2. </a><a href="#name-algorithm-organization" class="section-name selfRef">Algorithm Organization</a>
        </h3>
<p id="section-5.2-1">The BBR algorithm is an event-driven algorithm that executes steps upon the
following events: connection initialization, upon each ACK, upon the
transmission of each quantum, and upon loss detection events. All of the
sub-steps invoked referenced below are described below.<a href="#section-5.2-1" class="pilcrow">¶</a></p>
<div id="initialization">
<section id="section-5.2.1">
          <h4 id="name-initialization">
<a href="#section-5.2.1" class="section-number selfRef">5.2.1. </a><a href="#name-initialization" class="section-name selfRef">Initialization</a>
          </h4>
<p id="section-5.2.1-1">Upon transport connection initialization, BBR executes its initialization
steps:<a href="#section-5.2.1-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.2.1-2">
<pre>
  BBROnInit():
    InitWindowedMaxFilter(filter=BBR.MaxBwFilter, value=0, time=0)
    BBR.min_rtt = SRTT ? SRTT : Infinity
    BBR.min_rtt_stamp = Now()
    BBR.probe_rtt_done_stamp = 0
    BBR.probe_rtt_round_done = false
    BBR.prior_cwnd = 0
    BBR.idle_restart = false
    BBR.extra_acked_interval_start = Now()
    BBR.extra_acked_delivered = 0
    BBR.full_bw_reached = false
    BBRResetCongestionSignals()
    BBRResetShortTermModel()
    BBRInitRoundCounting()
    BBRResetFullBW()
    BBRInitPacingRate()
    BBREnterStartup()
</pre><a href="#section-5.2.1-2" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="per-transmit-steps">
<section id="section-5.2.2">
          <h4 id="name-per-transmit-steps">
<a href="#section-5.2.2" class="section-number selfRef">5.2.2. </a><a href="#name-per-transmit-steps" class="section-name selfRef">Per-Transmit Steps</a>
          </h4>
<p id="section-5.2.2-1">Before transmitting, BBR merely needs to check for the case where the flow
is restarting from idle:<a href="#section-5.2.2-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.2.2-2">
<pre>
  BBROnTransmit():
    BBRHandleRestartFromIdle()
</pre><a href="#section-5.2.2-2" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="per-ack-steps">
<section id="section-5.2.3">
          <h4 id="name-per-ack-steps">
<a href="#section-5.2.3" class="section-number selfRef">5.2.3. </a><a href="#name-per-ack-steps" class="section-name selfRef">Per-ACK Steps</a>
          </h4>
<p id="section-5.2.3-1">On every ACK, the BBR algorithm executes the following BBRUpdateOnACK() steps
in order to update its network path model, update its state machine, and
adjust its control parameters to adapt to the updated model:<a href="#section-5.2.3-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.2.3-2">
<pre>
  BBRUpdateOnACK():
    GenerateRateSample(RS)
    BBRUpdateModelAndState()
    BBRUpdateControlParameters()

  BBRUpdateModelAndState():
    BBRUpdateLatestDeliverySignals()
    BBRUpdateCongestionSignals()
    BBRUpdateACKAggregation()
    BBRCheckFullBWReached()
    BBRCheckStartupDone()
    BBRCheckDrainDone()
    BBRUpdateProbeBWCyclePhase()
    BBRUpdateMinRTT()
    BBRCheckProbeRTT()
    BBRAdvanceLatestDeliverySignals()
    BBRBoundBWForModel()

  BBRUpdateControlParameters():
    BBRSetPacingRate()
    BBRSetSendQuantum()
    BBRSetCwnd()
</pre><a href="#section-5.2.3-2" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="per-loss-steps">
<section id="section-5.2.4">
          <h4 id="name-per-loss-steps">
<a href="#section-5.2.4" class="section-number selfRef">5.2.4. </a><a href="#name-per-loss-steps" class="section-name selfRef">Per-Loss Steps</a>
          </h4>
<p id="section-5.2.4-1">On every packet loss event, where some sequence range "packet" is marked
lost, the BBR algorithm executes the following BBRUpdateOnLoss() steps in
order to update its network path model<a href="#section-5.2.4-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.2.4-2">
<pre>
  BBRUpdateOnLoss(packet):
    BBRHandleLostPacket(packet)
</pre><a href="#section-5.2.4-2" class="pilcrow">¶</a>
</div>
</section>
</div>
</section>
</div>
<div id="state-machine-operation">
<section id="section-5.3">
        <h3 id="name-state-machine-operation">
<a href="#section-5.3" class="section-number selfRef">5.3. </a><a href="#name-state-machine-operation" class="section-name selfRef">State Machine Operation</a>
        </h3>
<div id="startup">
<section id="section-5.3.1">
          <h4 id="name-startup">
<a href="#section-5.3.1" class="section-number selfRef">5.3.1. </a><a href="#name-startup" class="section-name selfRef">Startup</a>
          </h4>
<div id="startup-dynamics">
<section id="section-5.3.1.1">
            <h5 id="name-startup-dynamics">
<a href="#section-5.3.1.1" class="section-number selfRef">5.3.1.1. </a><a href="#name-startup-dynamics" class="section-name selfRef">Startup Dynamics</a>
            </h5>
<p id="section-5.3.1.1-1">When a BBR flow starts up, it performs its first (and most rapid) sequential
probe/drain process in the Startup and Drain states. Network link bandwidths
currently span a range of at least 11 orders of magnitude, from a few bps
to hundreds of Gbps. To quickly learn BBR.max_bw, given this huge range to
explore, BBR's Startup state does an exponential search of the rate space,
doubling the sending rate each round. This finds BBR.max_bw in O(log_2(BDP))
round trips.<a href="#section-5.3.1.1-1" class="pilcrow">¶</a></p>
<p id="section-5.3.1.1-2">To achieve this rapid probing smoothly, in Startup BBR uses the minimum gain
values that will allow the sending rate to double each round: in Startup BBR
sets BBR.pacing_gain to BBR.StartupPacingGain (2.77) <span>[<a href="#BBRStartupPacingGain" class="cite xref">BBRStartupPacingGain</a>]</span>
and BBR.cwnd_gain to BBR.DefaultCwndGain (2) <span>[<a href="#BBRStartupCwndGain" class="cite xref">BBRStartupCwndGain</a>]</span>.<a href="#section-5.3.1.1-2" class="pilcrow">¶</a></p>
<p id="section-5.3.1.1-3">When initializing a connection, or upon any later entry into Startup mode,
BBR executes the following BBREnterStartup() steps:<a href="#section-5.3.1.1-3" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.1.1-4">
<pre>
  BBREnterStartup():
    BBR.state = Startup
    BBR.pacing_gain = BBR.StartupPacingGain
    BBR.cwnd_gain = BBR.DefaultCwndGain
</pre><a href="#section-5.3.1.1-4" class="pilcrow">¶</a>
</div>
<p id="section-5.3.1.1-5">As BBR grows its sending rate rapidly, it obtains higher delivery rate
samples, BBR.max_bw increases, and the C.pacing_rate and C.cwnd both adapt by
smoothly growing in proportion. Once the pipe is full, a queue typically
forms, but the BBR.cwnd_gain bounds any queue to (BBR.cwnd_gain - 1) * estimated_BDP,
which is approximately (2 - 1) * estimated_BDP = estimated_BDP.
The immediately following Drain state is designed to quickly drain that queue.<a href="#section-5.3.1.1-5" class="pilcrow">¶</a></p>
<p id="section-5.3.1.1-6">During Startup, BBR estimates whether the pipe is full using two estimators.
The first looks for a plateau in the BBR.max_bw estimate. The second looks
for packet loss. The following subsections discuss these estimators.<a href="#section-5.3.1.1-6" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.1.1-7">
<pre>
  BBRCheckStartupDone():
    BBRCheckStartupHighLoss()
    if (BBR.state == Startup and BBR.full_bw_reached)
      BBREnterDrain()
</pre><a href="#section-5.3.1.1-7" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="exiting-acceleration-based-on-bandwidth-plateau">
<section id="section-5.3.1.2">
            <h5 id="name-exiting-acceleration-based-">
<a href="#section-5.3.1.2" class="section-number selfRef">5.3.1.2. </a><a href="#name-exiting-acceleration-based-" class="section-name selfRef">Exiting Acceleration Based on Bandwidth Plateau</a>
            </h5>
<p id="section-5.3.1.2-1">In phases where BBR is accelerating to probe the available bandwidth -
Startup and ProbeBW_UP - BBR runs a state machine to estimate whether an
accelerating sending rate has saturated the available per-flow bandwidth
("filled the pipe") by looking for a plateau in the measured
RS.delivery_rate.<a href="#section-5.3.1.2-1" class="pilcrow">¶</a></p>
<p id="section-5.3.1.2-2">BBR tracks the status of the current full-pipe estimation process in the
boolean BBR.full_bw_now, and uses BBR.full_bw_now to exit ProbeBW_UP. BBR
records in the boolean BBR.full_bw_reached whether BBR estimates that it
has ever fully utilized its available bandwidth (over the lifetime of the
connection), and uses BBR.full_bw_reached to decide when to exit Startup
and enter Drain.<a href="#section-5.3.1.2-2" class="pilcrow">¶</a></p>
<p id="section-5.3.1.2-3">The full pipe estimator works as follows: if BBR counts several (three)
non-application-limited rounds where attempts to significantly increase the
delivery rate actually result in little increase (less than 25 percent),
then it estimates that it has fully utilized the per-flow available bandwidth,
and sets both BBR.full_bw_now and BBR.full_bw_reached to true.<a href="#section-5.3.1.2-3" class="pilcrow">¶</a></p>
<p id="section-5.3.1.2-4">Upon starting a full pipe detection process (either on startup or when probing
for an increase in bandwidth), the following steps are taken:<a href="#section-5.3.1.2-4" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.1.2-5">
<pre>
  BBRResetFullBW():
    BBR.full_bw = 0
    BBR.full_bw_count = 0
    BBR.full_bw_now = 0
</pre><a href="#section-5.3.1.2-5" class="pilcrow">¶</a>
</div>
<p id="section-5.3.1.2-6">While running the full pipe detection process, upon an ACK that acknowledges
new data, and when the delivery rate sample is not application-limited
(see <a href="#delivery-rate-samples" class="auto internal xref">Section 4.1</a>), BBR runs the "full pipe" estimator:<a href="#section-5.3.1.2-6" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.1.2-7">
<pre>
  BBRCheckFullBWReached():
    if (BBR.full_bw_now or !BBR.round_start or RS.is_app_limited)
      return  /* no need to check for a full pipe now */
    if (RS.delivery_rate &gt;= BBR.full_bw * 1.25)
      BBRResetFullBW()       /* bw is still growing, so reset */
      BBR.full_bw = RS.delivery_rate  /* record new baseline bw */
      return
    BBR.full_bw_count++   /* another round w/o much growth */
    BBR.full_bw_now = (BBR.full_bw_count &gt;= 3)
    if (BBR.full_bw_now)
      BBR.full_bw_reached = true
</pre><a href="#section-5.3.1.2-7" class="pilcrow">¶</a>
</div>
<p id="section-5.3.1.2-8">BBR waits three packet-timed round trips to have reasonable evidence that the
sender is not detecting a delivery-rate plateau that was temporarily imposed by
congestion or receive-window auto-tuning. This three-round threshold was
validated by experimental data to allow the receiver the chance to grow its
receive window.<a href="#section-5.3.1.2-8" class="pilcrow">¶</a></p>
</section>
</div>
<div id="exiting-startup-based-on-packet-loss">
<section id="section-5.3.1.3">
            <h5 id="name-exiting-startup-based-on-pa">
<a href="#section-5.3.1.3" class="section-number selfRef">5.3.1.3. </a><a href="#name-exiting-startup-based-on-pa" class="section-name selfRef">Exiting Startup Based on Packet Loss</a>
            </h5>
<p id="section-5.3.1.3-1">A second method BBR uses for estimating the bottleneck is full in Startup
is by looking at packet losses. Specifically, BBRCheckStartupHighLoss() checks
whether all of the following criteria are all met:<a href="#section-5.3.1.3-1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.1.3-2.1">
                <p id="section-5.3.1.3-2.1.1">The connection has been in fast recovery for at least one full packet-timed
round trip.<a href="#section-5.3.1.3-2.1.1" class="pilcrow">¶</a></p>
</li>
              <li class="normal" id="section-5.3.1.3-2.2">
                <p id="section-5.3.1.3-2.2.1">The loss rate over the time scale of a single full round trip exceeds
BBR.LossThresh (2%).<a href="#section-5.3.1.3-2.2.1" class="pilcrow">¶</a></p>
</li>
              <li class="normal" id="section-5.3.1.3-2.3">
                <p id="section-5.3.1.3-2.3.1">There are at least BBRStartupFullLossCnt=6 discontiguous sequence ranges
lost in that round trip.<a href="#section-5.3.1.3-2.3.1" class="pilcrow">¶</a></p>
</li>
            </ul>
<p id="section-5.3.1.3-3">If these criteria are all met, then BBRCheckStartupHighLoss() takes the
following steps. First, it sets BBR.full_bw_reached = true. Then it sets
BBR.inflight_longterm to its estimate of a safe level of in-flight data suggested
by these losses, which is max(BBR.bdp, BBR.inflight_latest), where
BBR.inflight_latest is the max delivered volume of data (RS.delivered) over
the last round trip. Finally, it exits Startup and enters Drain.<a href="#section-5.3.1.3-3" class="pilcrow">¶</a></p>
<p id="section-5.3.1.3-4">The algorithm waits until all three criteria are met to filter out noise
from burst losses, and to try to ensure the bottleneck is fully utilized
on a sustained basis, and the full bottleneck bandwidth has been measured,
before attempting to drain the level of in-flight data to the estimated BDP.<a href="#section-5.3.1.3-4" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
<div id="drain">
<section id="section-5.3.2">
          <h4 id="name-drain">
<a href="#section-5.3.2" class="section-number selfRef">5.3.2. </a><a href="#name-drain" class="section-name selfRef">Drain</a>
          </h4>
<p id="section-5.3.2-1">Upon exiting Startup, BBR enters its Drain state. In Drain, BBR aims to quickly
drain any queue at the bottleneck link that was created in Startup by switching
to a pacing_gain well below 1.0, until any estimated queue has been drained. It
uses a pacing_gain of BBR.DrainPacingGain = 0.35, chosen via analysis
<span>[<a href="#BBRDrainPacingGain" class="cite xref">BBRDrainPacingGain</a>]</span> and experimentation to try to drain the queue in less
than one round-trip:<a href="#section-5.3.2-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.2-2">
<pre>
  BBREnterDrain():
    BBR.state = Drain
    BBR.pacing_gain = BBR.DrainPacingGain    /* pace slowly */
    BBR.cwnd_gain = BBR.DefaultCwndGain      /* maintain cwnd */
</pre><a href="#section-5.3.2-2" class="pilcrow">¶</a>
</div>
<p id="section-5.3.2-3">In Drain, when the amount of data in flight is less than or equal to the
estimated BDP, meaning BBR estimates that the queue at the bottleneck link
has been fully drained, then BBR exits Drain and enters ProbeBW. To implement
this, upon every ACK BBR executes:<a href="#section-5.3.2-3" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.2-4">
<pre>
  BBRCheckDrainDone():
    if (BBR.state == Drain and C.inflight &lt;= BBRInflight(1.0))
      BBREnterProbeBW()  /* BBR estimates the queue was drained */
</pre><a href="#section-5.3.2-4" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="probebw">
<section id="section-5.3.3">
          <h4 id="name-probebw">
<a href="#section-5.3.3" class="section-number selfRef">5.3.3. </a><a href="#name-probebw" class="section-name selfRef">ProbeBW</a>
          </h4>
<p id="section-5.3.3-1">Long-lived BBR flows tend to spend the vast majority of their time in the
ProbeBW states. In the ProbeBW states, a BBR flow sequentially accelerates,
decelerates, and cruises, to measure the network path, improve its operating
point (increase throughput and reduce queue pressure), and converge toward a
more fair allocation of bottleneck bandwidth. To do this, the flow sequentially
cycles through all three tactics: trying to send faster than, slower than, and
at the same rate as the network delivery process. To achieve this, a BBR flow
in ProbeBW mode cycles through the four Probe bw states (DOWN, CRUISE, REFILL,
and UP) described below in turn.<a href="#section-5.3.3-1" class="pilcrow">¶</a></p>
<div id="probebwdown">
<section id="section-5.3.3.1">
            <h5 id="name-probebw_down">
<a href="#section-5.3.3.1" class="section-number selfRef">5.3.3.1. </a><a href="#name-probebw_down" class="section-name selfRef">ProbeBW_DOWN</a>
            </h5>
<p id="section-5.3.3.1-1">In the ProbeBW_DOWN phase of the cycle, a BBR flow pursues the deceleration
tactic, to try to send slower than the network is delivering data, to reduce
the amount of data in flight, with all of the standard motivations for the
deceleration tactic (discussed in "State Machine Tactics" in
<a href="#state-machine-tactics" class="auto internal xref">Section 5.1.3</a>). It does this by switching to a
BBR.pacing_gain of 0.90, sending at 90% of BBR.bw. The pacing_gain value
of 0.90 is derived based on the ProbeBW_UP pacing gain of 1.25, as the minimum
pacing_gain value that allows bandwidth-based convergence to approximate
fairness, and validated through experiments.<a href="#section-5.3.3.1-1" class="pilcrow">¶</a></p>
<p id="section-5.3.3.1-2">Exit conditions: The flow exits the ProbeBW_DOWN phase and enters CRUISE
when the flow estimates that both of the following conditions have been
met:<a href="#section-5.3.3.1-2" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.1-3.1">
                <p id="section-5.3.3.1-3.1.1">There is free headroom: If BBR.inflight_longterm is set, then BBR remains in
ProbeBW_DOWN at least until inflight is less than or
equal to a target calculated based on (1 - BBR.Headroom)*BBR.inflight_longterm.
The goal of this constraint is to ensure that in cases where loss signals
suggest an upper limit on C.inflight, then the flow attempts
to leave some free headroom in the path (e.g. free space in the bottleneck
buffer or free time slots in the bottleneck link) that can be used by
cross traffic (both for convergence of bandwidth shares and for burst tolerance).<a href="#section-5.3.3.1-3.1.1" class="pilcrow">¶</a></p>
</li>
              <li class="normal" id="section-5.3.3.1-3.2">
                <p id="section-5.3.3.1-3.2.1">C.inflight is less than or equal to BBR.bdp, i.e. the flow
estimates that it has drained any queue at the bottleneck.<a href="#section-5.3.3.1-3.2.1" class="pilcrow">¶</a></p>
</li>
            </ul>
</section>
</div>
<div id="probebwcruise">
<section id="section-5.3.3.2">
            <h5 id="name-probebw_cruise">
<a href="#section-5.3.3.2" class="section-number selfRef">5.3.3.2. </a><a href="#name-probebw_cruise" class="section-name selfRef">ProbeBW_CRUISE</a>
            </h5>
<p id="section-5.3.3.2-1">In the ProbeBW_CRUISE phase of the cycle, a BBR flow pursues the "cruising"
tactic (discussed in "State Machine Tactics" in
<a href="#state-machine-tactics" class="auto internal xref">Section 5.1.3</a>), attempting to send at the same rate the
network is delivering data. It tries to match the sending rate to the flow's
current available bandwidth, to try to achieve high utilization of the
available bandwidth without increasing queue pressure. It does this by
switching to a pacing_gain of 1.0, sending at 100% of BBR.bw. Notably, while
in this state it responds to concrete congestion signals (loss) by reducing
BBR.bw_shortterm and BBR.inflight_shortterm, because these signals suggest that
the available bandwidth and deliverable inflight have likely
reduced, and the flow needs to change to adapt, slowing down to match the
latest delivery process.<a href="#section-5.3.3.2-1" class="pilcrow">¶</a></p>
<p id="section-5.3.3.2-2">Exit conditions: The connection adaptively holds this state until it decides
that it is time to probe for bandwidth (see "Time Scale for Bandwidth Probing",
in <a href="#time-scale-for-bandwidth-probing-" class="auto internal xref">Section 5.3.3.5</a>), at which time it enters
ProbeBW_REFILL.<a href="#section-5.3.3.2-2" class="pilcrow">¶</a></p>
</section>
</div>
<div id="probebwrefill">
<section id="section-5.3.3.3">
            <h5 id="name-probebw_refill">
<a href="#section-5.3.3.3" class="section-number selfRef">5.3.3.3. </a><a href="#name-probebw_refill" class="section-name selfRef">ProbeBW_REFILL</a>
            </h5>
<p id="section-5.3.3.3-1">The goal of the ProbeBW_REFILL state is to "refill the pipe", to try to fully
utilize the network bottleneck without creating any significant queue pressure.<a href="#section-5.3.3.3-1" class="pilcrow">¶</a></p>
<p id="section-5.3.3.3-2">To do this, BBR first resets the short-term model parameters BBR.bw_shortterm and
BBR.inflight_shortterm, setting both to "Infinity". This is the key moment in the BBR
time scale strategy (see "Time Scale Strategy", <a href="#time-scale-strategy" class="auto internal xref">Section 3.4.2.3</a>)
where the flow pivots, discarding its conservative short-term BBR.bw_shortterm and
BBR.inflight_shortterm parameters and beginning to robustly probe the bottleneck's
long-term available bandwidth. During this time the estimated bandwidth and
BBR.inflight_longterm, if set, constrain the connection.<a href="#section-5.3.3.3-2" class="pilcrow">¶</a></p>
<p id="section-5.3.3.3-3">During ProbeBW_REFILL BBR uses a BBR.pacing_gain of 1.0, to send at a rate
that matches the current estimated available bandwidth, for one packet-timed
round trip. The goal is to fully utilize the bottleneck link before
transitioning into ProbeBW_UP and significantly increasing the chances of
causing loss. The motivating insight is that, as soon as a flow starts
acceleration, sending faster than the available bandwidth, it will start
building a queue at the bottleneck. And if the buffer is shallow enough,
then the flow can cause loss signals very shortly after the first accelerating
packets arrive at the bottleneck. If the flow were to neglect to fill the
pipe before it causes this loss signal, then these very quick signals of excess
queue could cause the flow's estimate of the path's capacity (i.e. BBR.inflight_longterm)
to significantly underestimate. In particular, if the flow were to transition
directly from ProbeBW_CRUISE to ProbeBW_UP, C.inflight
(at the time the first accelerating packets were sent) may often be still very
close to the C.inflight maintained in CRUISE, which may be
only (1 - BBR.Headroom)*BBR.inflight_longterm.<a href="#section-5.3.3.3-3" class="pilcrow">¶</a></p>
<p id="section-5.3.3.3-4">Exit conditions: The flow exits ProbeBW_REFILL after one packet-timed round
trip, and enters ProbeBW_UP. This is because after one full round trip of
sending in ProbeBW_REFILL the flow (if not application-limited) has had an
opportunity to place as many packets in flight as its BBR.bw and BBR.inflight_longterm
permit. Correspondingly, at this point the flow starts to see bandwidth samples
reflecting its ProbeBW_REFILL behavior, which may be putting too much data
in flight.<a href="#section-5.3.3.3-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="probebwup">
<section id="section-5.3.3.4">
            <h5 id="name-probebw_up">
<a href="#section-5.3.3.4" class="section-number selfRef">5.3.3.4. </a><a href="#name-probebw_up" class="section-name selfRef">ProbeBW_UP</a>
            </h5>
<p id="section-5.3.3.4-1">After ProbeBW_REFILL refills the pipe, ProbeBW_UP probes for possible
increases in available bandwidth by raising the sending rate, using a
BBR.pacing_gain of 1.25, to send faster than the current estimated available
bandwidth. It also raises BBR.cwnd_gain to 2.25, to ensure that the flow
can send faster than it had been, even if C.cwnd was previously limiting the
sending process.<a href="#section-5.3.3.4-1" class="pilcrow">¶</a></p>
<p id="section-5.3.3.4-2">If the flow has not set BBR.inflight_longterm, it implicitly tries to raise
C.inflight to at least BBR.pacing_gain * BBR.bdp = 1.25 *
BBR.bdp.<a href="#section-5.3.3.4-2" class="pilcrow">¶</a></p>
<p id="section-5.3.3.4-3">If the flow has set BBR.inflight_longterm and encounters that limit, it then
gradually increases the upper volume bound (BBR.inflight_longterm) using the
following approach:<a href="#section-5.3.3.4-3" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.4-4.1">
                <p id="section-5.3.3.4-4.1.1">BBR.inflight_longterm: The flow raises BBR.inflight_longterm in ProbeBW_UP in a manner
that is slow and cautious at first, but increasingly rapid and bold over time.
The initial caution is motivated by the fact that a given BBR flow may be sharing
a shallow buffer with thousands of other flows, so that the buffer space
available to the flow may be quite tight (even just a single packet or
less). The increasingly rapid growth over time is motivated by the fact that
in a high-speed WAN the increase in available bandwidth (and thus the estimated
BDP) may require the flow to grow C.inflight by up to
O(1,000,000) packets; even a high-speed WAN BDP like
10Gbps * 100ms is around 83,000 packets (with a 1500-byte MTU). The additive
increase to BBR.inflight_longterm exponentially doubles each round trip;
in each successive round trip, BBR.inflight_longterm grows by 1, 2, 4, 8, 16,
etc, with the increases spread uniformly across the entire round trip.
This helps allow BBR to utilize a larger BDP in O(log(BDP)) round trips,
meeting the design goal for scalable utilization of newly-available bandwidth.<a href="#section-5.3.3.4-4.1.1" class="pilcrow">¶</a></p>
</li>
            </ul>
<p id="section-5.3.3.4-5">Exit conditions: The BBR flow ends ProbeBW_UP bandwidth probing and
transitions to ProbeBW_DOWN to try to drain the bottleneck queue when either
of the following conditions are met:<a href="#section-5.3.3.4-5" class="pilcrow">¶</a></p>
<ol start="1" type="1" class="normal type-1" id="section-5.3.3.4-6">
<li id="section-5.3.3.4-6.1">
                <p id="section-5.3.3.4-6.1.1">Bandwidth saturation: BBRIsTimeToGoDown() (see below) uses the "full pipe"
  estimator (see <a href="#exiting-acceleration-based-on-bandwidth-plateau" class="auto internal xref">Section 5.3.1.2</a>) to
  estimate whether the flow has saturated the available per-flow bandwidth
  ("filled the pipe"), by looking for a plateau in the measured
  RS.delivery_rate. If, during this process, C.inflight is constrained
  by BBR.inflight_longterm (the flow becomes cwnd-limited while cwnd is limited by
  BBR.inflight_longterm), then the flow cannot fully explore the available bandwidth,
  and so it resets the "full pipe" estimator by calling BBRResetFullBW().<a href="#section-5.3.3.4-6.1.1" class="pilcrow">¶</a></p>
</li>
              <li id="section-5.3.3.4-6.2">
                <p id="section-5.3.3.4-6.2.1">Loss: The current loss rate, over the time scale of the last round trip,
  exceeds BBR.LossThresh (2%).<a href="#section-5.3.3.4-6.2.1" class="pilcrow">¶</a></p>
</li>
            </ol>
</section>
</div>
<div id="time-scale-for-bandwidth-probing-">
<section id="section-5.3.3.5">
            <h5 id="name-time-scale-for-bandwidth-pr">
<a href="#section-5.3.3.5" class="section-number selfRef">5.3.3.5. </a><a href="#name-time-scale-for-bandwidth-pr" class="section-name selfRef">Time Scale for Bandwidth Probing</a>
            </h5>
<p id="section-5.3.3.5-1">Choosing the time scale for probing bandwidth is tied to the question of
how to coexist with legacy Reno/CUBIC flows, since probing for bandwidth
runs a significant risk of causing packet loss, and causing packet loss can
significantly limit the throughput of such legacy Reno/CUBIC flows.<a href="#section-5.3.3.5-1" class="pilcrow">¶</a></p>
<div id="bandwidth-probing-and-coexistence-with-renocubic">
<section id="section-5.3.3.5.1">
              <h6 id="name-bandwidth-probing-and-coexi">
<a href="#section-5.3.3.5.1" class="section-number selfRef">5.3.3.5.1. </a><a href="#name-bandwidth-probing-and-coexi" class="section-name selfRef">Bandwidth Probing and Coexistence with Reno/CUBIC</a>
              </h6>
<p id="section-5.3.3.5.1-1">BBR has an explicit strategy for coexistence with Reno/CUBIC: to try to behave
in a manner so that  Reno/CUBIC flows coexisting with BBR can continue to
work well in the primary contexts where they do today:<a href="#section-5.3.3.5.1-1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.5.1-2.1">
                  <p id="section-5.3.3.5.1-2.1.1">Intra-datacenter/LAN traffic: the goal is to allow Reno/CUBIC to be able
to perform well in 100M through 40G enterprise and datacenter Ethernet:<a href="#section-5.3.3.5.1-2.1.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.5.1-2.1.2.1">
                      <p id="section-5.3.3.5.1-2.1.2.1.1">BDP = 40 Gbps * 20 us / (1514 bytes) ~= 66 packets<a href="#section-5.3.3.5.1-2.1.2.1.1" class="pilcrow">¶</a></p>
</li>
                  </ul>
</li>
                <li class="normal" id="section-5.3.3.5.1-2.2">
                  <p id="section-5.3.3.5.1-2.2.1">Public Internet last mile traffic: the goal is to allow Reno/CUBIC to be
able to support up to 25Mbps (for 4K Video) at an RTT of 30ms, typical
parameters for common CDNs for large video services:<a href="#section-5.3.3.5.1-2.2.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.5.1-2.2.2.1">
                      <p id="section-5.3.3.5.1-2.2.2.1.1">BDP = 25Mbps * 30 ms / (1514 bytes) ~= 62 packets<a href="#section-5.3.3.5.1-2.2.2.1.1" class="pilcrow">¶</a></p>
</li>
                  </ul>
</li>
              </ul>
<p id="section-5.3.3.5.1-3">The challenge in meeting these goals is that Reno/CUBIC need long periods
of no loss to utilize large BDPs. The good news is that in the environments
where Reno/CUBIC work well today (mentioned above), the BDPs are small, roughly
~100 packets or less.<a href="#section-5.3.3.5.1-3" class="pilcrow">¶</a></p>
</section>
</div>
<div id="a-dual-time-scale-approach-for-coexistence">
<section id="section-5.3.3.5.2">
              <h6 id="name-a-dual-time-scale-approach-">
<a href="#section-5.3.3.5.2" class="section-number selfRef">5.3.3.5.2. </a><a href="#name-a-dual-time-scale-approach-" class="section-name selfRef">A Dual-Time-Scale Approach for Coexistence</a>
              </h6>
<p id="section-5.3.3.5.2-1">The BBR strategy has several aspects:<a href="#section-5.3.3.5.2-1" class="pilcrow">¶</a></p>
<ol start="1" type="1" class="normal type-1" id="section-5.3.3.5.2-2">
<li id="section-5.3.3.5.2-2.1">
                  <p id="section-5.3.3.5.2-2.1.1">The highest priority is to estimate the bandwidth available to the BBR flow
  in question.<a href="#section-5.3.3.5.2-2.1.1" class="pilcrow">¶</a></p>
</li>
                <li id="section-5.3.3.5.2-2.2">
                  <p id="section-5.3.3.5.2-2.2.1">Secondarily, a given BBR flow adapts (within bounds) the frequency at which
  it probes bandwidth and knowingly risks packet loss, to allow Reno/CUBIC
  to reach a bandwidth at least as high as that given BBR flow.<a href="#section-5.3.3.5.2-2.2.1" class="pilcrow">¶</a></p>
</li>
              </ol>
<p id="section-5.3.3.5.2-3">To adapt the frequency of bandwidth probing, BBR considers two time scales:
a BBR-native time scale, and a bounded Reno-conscious time scale:<a href="#section-5.3.3.5.2-3" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.5.2-4.1">
                  <p id="section-5.3.3.5.2-4.1.1">T_bbr: BBR-native time-scale<a href="#section-5.3.3.5.2-4.1.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.5.2-4.1.2.1">
                      <p id="section-5.3.3.5.2-4.1.2.1.1">T_bbr = uniformly randomly distributed between 2 and 3 secs<a href="#section-5.3.3.5.2-4.1.2.1.1" class="pilcrow">¶</a></p>
</li>
                  </ul>
</li>
                <li class="normal" id="section-5.3.3.5.2-4.2">
                  <p id="section-5.3.3.5.2-4.2.1">T_reno: Reno-coexistence time scale<a href="#section-5.3.3.5.2-4.2.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.5.2-4.2.2.1">
                      <p id="section-5.3.3.5.2-4.2.2.1.1">T_reno_bound = pick_randomly_either({62, 63})<a href="#section-5.3.3.5.2-4.2.2.1.1" class="pilcrow">¶</a></p>
</li>
                    <li class="normal" id="section-5.3.3.5.2-4.2.2.2">
                      <p id="section-5.3.3.5.2-4.2.2.2.1">reno_bdp = min(BBR.bdp, C.cwnd)<a href="#section-5.3.3.5.2-4.2.2.2.1" class="pilcrow">¶</a></p>
</li>
                    <li class="normal" id="section-5.3.3.5.2-4.2.2.3">
                      <p id="section-5.3.3.5.2-4.2.2.3.1">T_reno = min(reno_bdp, T_reno_bound) round trips<a href="#section-5.3.3.5.2-4.2.2.3.1" class="pilcrow">¶</a></p>
</li>
                  </ul>
</li>
                <li class="normal" id="section-5.3.3.5.2-4.3">
                  <p id="section-5.3.3.5.2-4.3.1">T_probe: The time between bandwidth probe UP phases:<a href="#section-5.3.3.5.2-4.3.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.5.2-4.3.2.1">
                      <p id="section-5.3.3.5.2-4.3.2.1.1">T_probe = min(T_bbr, T_reno)<a href="#section-5.3.3.5.2-4.3.2.1.1" class="pilcrow">¶</a></p>
</li>
                  </ul>
</li>
              </ul>
<p id="section-5.3.3.5.2-5">This dual-time-scale approach is similar to that used by CUBIC, which has
a CUBIC-native time scale given by a cubic curve, and a "Reno emulation"
module that estimates what C.cwnd would give the flow Reno-equivalent throughput.
At any given moment, choose the C.cwnd implied by the more aggressive
strategy.<a href="#section-5.3.3.5.2-5" class="pilcrow">¶</a></p>
<p id="section-5.3.3.5.2-6">We randomize both the T_bbr and T_reno parameters, for better mixing and
fairness convergence.<a href="#section-5.3.3.5.2-6" class="pilcrow">¶</a></p>
</section>
</div>
<div id="design-considerations-for-choosing-constant-parameters">
<section id="section-5.3.3.5.3">
              <h6 id="name-design-considerations-for-c">
<a href="#section-5.3.3.5.3" class="section-number selfRef">5.3.3.5.3. </a><a href="#name-design-considerations-for-c" class="section-name selfRef">Design Considerations for Choosing Constant Parameters</a>
              </h6>
<p id="section-5.3.3.5.3-1">We design the maximum wall-clock bounds of BBR-native inter-bandwidth-probe
wall clock time, T_bbr, to be:<a href="#section-5.3.3.5.3-1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.5.3-2.1">
                  <p id="section-5.3.3.5.3-2.1.1">Higher than 2 sec to try to avoid causing loss for a long enough time to
allow Reno flow with RTT=30ms to get 25Mbps (4K video) throughput. For this
workload, given the Reno sawtooth that raises C.cwnd from roughly BDP to 2*BDP,
one C.SMSS per round trip,  the inter-bandwidth-probe time must be at least:
BDP * RTT = 25Mbps * .030 sec / (1514 bytes) * 0.030 sec = 1.9secs<a href="#section-5.3.3.5.3-2.1.1" class="pilcrow">¶</a></p>
</li>
                <li class="normal" id="section-5.3.3.5.3-2.2">
                  <p id="section-5.3.3.5.3-2.2.1">Lower than 3 sec to ensure flows can start probing in a reasonable amount
of time to discover unutilized bw on human-scale interactive  time-scales
(e.g. perhaps traffic from a competing web page download is now complete).<a href="#section-5.3.3.5.3-2.2.1" class="pilcrow">¶</a></p>
</li>
              </ul>
<p id="section-5.3.3.5.3-3">The maximum round-trip bounds of the Reno-coexistence time scale, T_reno,
are chosen to be 62-63 with the following considerations in mind:<a href="#section-5.3.3.5.3-3" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.3.3.5.3-4.1">
                  <p id="section-5.3.3.5.3-4.1.1">Choosing a value smaller than roughly 60 would imply that when BBR flows
coexisted with Reno/CUBIC flows on public Internet broadband links, the
Reno/CUBIC flows would not be able to achieve enough bandwidth to show 4K
video.<a href="#section-5.3.3.5.3-4.1.1" class="pilcrow">¶</a></p>
</li>
                <li class="normal" id="section-5.3.3.5.3-4.2">
                  <p id="section-5.3.3.5.3-4.2.1">Choosing a value that is too large would prevent BBR from reaching its goal
of tolerating 1% loss per round trip.
Given that the steady-state (non-bandwidth-probing) BBR response to
a non-application-limited round trip with X% packet loss is to
reduce the sending rate by X% (see "Updating the Model Upon Packet
Loss" in <a href="#updating-the-model-upon-packet-loss" class="auto internal xref">Section 5.5.10</a>), this means that the
BBR sending rate after N rounds of packet loss at a rate loss_rate
is reduced to (1 - loss_rate)^N.
A simplified model predicts that for a flow that encounters 1% loss
in N=137 round trips of ProbeBW_CRUISE, and then doubles its C.cwnd
(back to BBR.inflight_longterm) in ProbeBW_REFILL and ProbeBW_UP, we
expect that it will be able to restore and reprobe its original
sending rate, since: (1 - loss_rate)^N * 2^2 = (1 - .01)^137 * 2^2
~= 1.01.
That is, we expect the flow will be able to fully respond to packet
loss signals in ProbeBW_CRUISE while also fully re-measuring its
maximum achievable throughput in ProbeBW_UP.
However, with a larger number of round trips of ProbeBW_CRUISE, the
flow would not be able to sustain its achievable throughput.<a href="#section-5.3.3.5.3-4.2.1" class="pilcrow">¶</a></p>
</li>
              </ul>
<p id="section-5.3.3.5.3-5">The resulting behavior is that for BBR flows with small BDPs, the bandwidth
probing will be on roughly the same time scale as Reno/CUBIC; flows with
large BDPs will intentionally probe more rapidly/frequently than Reno/CUBIC
would (roughly every 62 round trips for low-RTT flows, or 2-3 secs for
high-RTT flows).<a href="#section-5.3.3.5.3-5" class="pilcrow">¶</a></p>
<p id="section-5.3.3.5.3-6">The considerations above for timing bandwidth probing can be implemented
as follows:<a href="#section-5.3.3.5.3-6" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.3.5.3-7">
<pre>
  /* Is it time to transition from DOWN or CRUISE to REFILL? */
  BBRIsTimeToProbeBW():
    if (BBRHasElapsedInPhase(BBR.bw_probe_wait) ||
        BBRIsRenoCoexistenceProbeTime())
      BBRStartProbeBW_REFILL()
      return true
    return false

  /* Randomized decision about how long to wait until
   * probing for bandwidth, using round count and wall clock.
   */
  BBRPickProbeWait():
    /* Decide random round-trip bound for wait: */
    BBR.rounds_since_bw_probe =
      random_int_between(0, 1); /* 0 or 1 */
    /* Decide the random wall clock bound for wait: */
    BBR.bw_probe_wait =
      2 + random_float_between(0.0, 1.0) /* 0..1 sec */

  BBRIsRenoCoexistenceProbeTime():
    reno_rounds = BBRTargetInflight()
    rounds = min(reno_rounds, 63)
    return BBR.rounds_since_bw_probe &gt;= rounds

  /* How much data do we want in flight?
   * Our estimated BDP, unless congestion cut C.cwnd. */
  BBRTargetInflight()
    return min(BBR.bdp, C.cwnd)
</pre><a href="#section-5.3.3.5.3-7" class="pilcrow">¶</a>
</div>
</section>
</div>
</section>
</div>
<div id="probebw-algorithm-details">
<section id="section-5.3.3.6">
            <h5 id="name-probebw-algorithm-details">
<a href="#section-5.3.3.6" class="section-number selfRef">5.3.3.6. </a><a href="#name-probebw-algorithm-details" class="section-name selfRef">ProbeBW Algorithm Details</a>
            </h5>
<p id="section-5.3.3.6-1">BBR's ProbeBW algorithm operates as follows.<a href="#section-5.3.3.6-1" class="pilcrow">¶</a></p>
<p id="section-5.3.3.6-2">Upon entering ProbeBW, BBR executes:<a href="#section-5.3.3.6-2" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.3.6-3">
<pre>
  BBREnterProbeBW():
    BBR.cwnd_gain = BBR.DefaultCwndGain
    BBRStartProbeBW_DOWN()
</pre><a href="#section-5.3.3.6-3" class="pilcrow">¶</a>
</div>
<p id="section-5.3.3.6-4">The core logic for entering each state:<a href="#section-5.3.3.6-4" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.3.6-5">
<pre>
  BBRStartProbeBW_DOWN():
    BBRResetCongestionSignals()
    BBR.probe_up_cnt = Infinity /* not growing BBR.inflight_longterm */
    BBRPickProbeWait()
    BBR.cycle_stamp = Now()  /* start wall clock */
    BBR.ack_phase  = ACKS_PROBE_STOPPING
    BBRStartRound()
    BBR.state = ProbeBW_DOWN

  BBRStartProbeBW_CRUISE():
    BBR.state = ProbeBW_CRUISE

  BBRStartProbeBW_REFILL():
    BBRResetShortTermModel()
    BBR.bw_probe_up_rounds = 0
    BBR.bw_probe_up_acks = 0
    BBR.ack_phase = ACKS_REFILLING
    BBRStartRound()
    BBR.state = ProbeBW_REFILL

  BBRStartProbeBW_UP():
    BBR.ack_phase = ACKS_PROBE_STARTING
    BBRStartRound()
    BBRResetFullBW()
    BBR.full_bw = RS.delivery_rate
    BBR.state = ProbeBW_UP
    BBRRaiseInflightLongtermSlope()
</pre><a href="#section-5.3.3.6-5" class="pilcrow">¶</a>
</div>
<p id="section-5.3.3.6-6">BBR executes the following BBRUpdateProbeBWCyclePhase() logic on each ACK
that acknowledges new data, to advance the ProbeBW state machine:<a href="#section-5.3.3.6-6" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.3.6-7">
<pre>
  /* The core state machine logic for ProbeBW: */
  BBRUpdateProbeBWCyclePhase():
    if (!BBR.full_bw_reached)
      return  /* only handling steady-state behavior here */
    BBRAdaptLongTermModel()
    if (!IsInAProbeBWState())
      return /* only handling ProbeBW states here: */

    switch (state)

    ProbeBW_DOWN:
      if (BBRIsTimeToProbeBW())
        return /* already decided state transition */
      if (BBRIsTimeToCruise())
        BBRStartProbeBW_CRUISE()

    ProbeBW_CRUISE:
      if (BBRIsTimeToProbeBW())
        return /* already decided state transition */

    ProbeBW_REFILL:
      /* After one round of REFILL, start UP */
      if (BBR.round_start)
        BBR.bw_probe_samples = 1
        BBRStartProbeBW_UP()

    ProbeBW_UP:
      if (BBRIsTimeToGoDown())
        BBRStartProbeBW_DOWN()
</pre><a href="#section-5.3.3.6-7" class="pilcrow">¶</a>
</div>
<p id="section-5.3.3.6-8">The ancillary logic to implement the ProbeBW state machine:<a href="#section-5.3.3.6-8" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.3.6-9">
<pre>
  IsInAProbeBWState()
    state = BBR.state
    return (state == ProbeBW_DOWN or
            state == ProbeBW_CRUISE or
            state == ProbeBW_REFILL or
            state == ProbeBW_UP)

  /* Time to transition from DOWN to CRUISE? */
  BBRIsTimeToCruise():
    if (C.inflight &gt; BBRInflightWithHeadroom())
      return false /* not enough headroom */
    if (C.inflight &lt;= BBRInflight(BBR.max_bw, 1.0))
      return true  /* C.inflight &lt;= estimated BDP */

  /* Time to transition from UP to DOWN? */
  BBRIsTimeToGoDown():
    if (C.is_cwnd_limited and C.cwnd &gt;= BBR.inflight_longterm)
      BBRResetFullBW()   /* bw is limited by BBR.inflight_longterm */
      BBR.full_bw = RS.delivery_rate
    else if (BBR.full_bw_now)
      return true  /* we estimate we've fully used path bw */
    return false

  BBRIsProbingBW():
    return (BBR.state == Startup or
            BBR.state == ProbeBW_REFILL or
            BBR.state == ProbeBW_UP)

  BBRHasElapsedInPhase(interval):
    return Now() &gt; BBR.cycle_stamp + interval

  /* Return a volume of data that tries to leave free
   * headroom in the bottleneck buffer or link for
   * other flows, for fairness convergence and lower
   * RTTs and loss */
  BBRInflightWithHeadroom():
    if (BBR.inflight_longterm == Infinity)
      return Infinity
    headroom = max(1*SMSS, BBR.Headroom * BBR.inflight_longterm)
    return max(BBR.inflight_longterm - headroom,
               BBR.MinPipeCwnd)

  /* Raise BBR.inflight_longterm slope if appropriate. */
  BBRRaiseInflightLongtermSlope():
    growth_this_round = 1*SMSS &lt;&lt; BBR.bw_probe_up_rounds
    BBR.bw_probe_up_rounds = min(BBR.bw_probe_up_rounds + 1, 30)
    BBR.probe_up_cnt = max(C.cwnd / growth_this_round, 1)

  /* Increase BBR.inflight_longterm if appropriate. */
  BBRProbeInflightLongtermUpward():
    if (!C.is_cwnd_limited or C.cwnd &lt; BBR.inflight_longterm)
      return  /* not fully using BBR.inflight_longterm, so don't grow it */
   BBR.bw_probe_up_acks += RS.newly_acked
   if (BBR.bw_probe_up_acks &gt;= BBR.probe_up_cnt)
     delta = BBR.bw_probe_up_acks / BBR.probe_up_cnt
     BBR.bw_probe_up_acks -= delta * BBR.bw_probe_up_cnt
     BBR.inflight_longterm += delta
   if (BBR.round_start)
     BBRRaiseInflightLongtermSlope()

  /* Track ACK state and update BBR.max_bw window and
   * BBR.inflight_longterm. */
  BBRAdaptLongTermModel():
    if (BBR.ack_phase == ACKS_PROBE_STARTING and BBR.round_start)
      /* starting to get bw probing samples */
      BBR.ack_phase = ACKS_PROBE_FEEDBACK
    if (BBR.ack_phase == ACKS_PROBE_STOPPING and BBR.round_start)
      /* end of samples from bw probing phase */
      if (IsInAProbeBWState() and !RS.is_app_limited)
        BBRAdvanceMaxBwFilter()

    if (!IsInflightTooHigh())
      /* Loss rate is safe. Adjust upper bounds upward. */
      if (BBR.inflight_longterm == Infinity)
        return /* no upper bounds to raise */
      if (RS.tx_in_flight &gt; BBR.inflight_longterm)
        BBR.inflight_longterm = RS.tx_in_flight
      if (BBR.state == ProbeBW_UP)
        BBRProbeInflightLongtermUpward()
</pre><a href="#section-5.3.3.6-9" class="pilcrow">¶</a>
</div>
</section>
</div>
</section>
</div>
<div id="probertt">
<section id="section-5.3.4">
          <h4 id="name-probertt">
<a href="#section-5.3.4" class="section-number selfRef">5.3.4. </a><a href="#name-probertt" class="section-name selfRef">ProbeRTT</a>
          </h4>
<div id="probertt-overview">
<section id="section-5.3.4.1">
            <h5 id="name-probertt-overview">
<a href="#section-5.3.4.1" class="section-number selfRef">5.3.4.1. </a><a href="#name-probertt-overview" class="section-name selfRef">ProbeRTT Overview</a>
            </h5>
<p id="section-5.3.4.1-1">To help probe for BBR.min_rtt, on an as-needed basis BBR flows enter the
ProbeRTT state to try to cooperate to periodically drain the bottleneck queue,
and thus improve their BBR.min_rtt estimate of the unloaded two-way propagation
delay.<a href="#section-5.3.4.1-1" class="pilcrow">¶</a></p>
<p id="section-5.3.4.1-2">A critical point is that before BBR raises its BBR.min_rtt
estimate (which would in turn raise its maximum permissible C.cwnd), it first
enters ProbeRTT to try to make a concerted and coordinated effort to drain
the bottleneck queue and make a robust BBR.min_rtt measurement. This allows the
BBR.min_rtt estimates of ensembles of BBR flows to converge, avoiding feedback
loops of ever-increasing queues and RTT samples.<a href="#section-5.3.4.1-2" class="pilcrow">¶</a></p>
<p id="section-5.3.4.1-3">The ProbeRTT state works in concert with BBR.min_rtt estimation. Up to once
every ProbeRTTInterval = 5 seconds, the flow enters ProbeRTT, decelerating
by setting its cwnd_gain to BBR.ProbeRTTCwndGain = 0.5 to reduce
C.inflight to half of its estimated BDP, to try to measure the unloaded
two-way propagation delay.<a href="#section-5.3.4.1-3" class="pilcrow">¶</a></p>
<p id="section-5.3.4.1-4">There are two main motivations for making the MinRTTFilterLen roughly twice
the ProbeRTTInterval. First, this ensures that during a ProbeRTT episode
the flow will "remember" the BBR.min_rtt value it measured during the previous
ProbeRTT episode, providing a robust BDP estimate for the C.cwnd = 0.5*BDP
calculation, increasing the likelihood of fully draining the bottleneck
queue. Second, this allows the flow's BBR.min_rtt filter window to generally
include RTT samples from two ProbeTT episodes, providing a more robust
estimate.<a href="#section-5.3.4.1-4" class="pilcrow">¶</a></p>
<p id="section-5.3.4.1-5">The algorithm for ProbeRTT is as follows:<a href="#section-5.3.4.1-5" class="pilcrow">¶</a></p>
<p id="section-5.3.4.1-6">Entry conditions: In any state other than ProbeRTT itself, if the
BBR.probe_rtt_min_delay estimate has not been updated (i.e., by getting a
lower RTT measurement) for more than ProbeRTTInterval = 5 seconds, then BBR
enters ProbeRTT and reduces the BBR.cwnd_gain to BBR.ProbeRTTCwndGain = 0.5.<a href="#section-5.3.4.1-6" class="pilcrow">¶</a></p>
<p id="section-5.3.4.1-7">Exit conditions: After maintaining C.inflight at
BBR.ProbeRTTCwndGain*BBR.bdp for at least BBR.ProbeRTTDuration (200 ms) and at
least one packet-timed round trip, BBR leaves ProbeRTT and transitions to
ProbeBW if it estimates the pipe was filled already, or Startup otherwise.<a href="#section-5.3.4.1-7" class="pilcrow">¶</a></p>
</section>
</div>
<div id="probertt-design-rationale">
<section id="section-5.3.4.2">
            <h5 id="name-probertt-design-rationale">
<a href="#section-5.3.4.2" class="section-number selfRef">5.3.4.2. </a><a href="#name-probertt-design-rationale" class="section-name selfRef">ProbeRTT Design Rationale</a>
            </h5>
<p id="section-5.3.4.2-1">BBR is designed to have ProbeRTT sacrifice no more than roughly 2% of a flow's
available bandwidth. It is also designed to spend the vast majority of its
time (at least roughly 96 percent) in ProbeBW and the rest in ProbeRTT, based
on a set of tradeoffs. ProbeRTT lasts long enough (at least BBR.ProbeRTTDuration
= 200 ms) to allow diverse flows (e.g., flows with different RTTs or lower
rates and thus longer inter-packet gaps) to have overlapping ProbeRTT states,
while still being short enough to bound the throughput penalty of ProbeRTT's
cwnd capping to roughly 2%, with the average throughput targeted at:<a href="#section-5.3.4.2-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.4.2-2">
<pre>
  throughput = (200ms*0.5*BBR.bw + (5s - 200ms)*BBR.bw) / 5s
             = (.1s + 4.8s)/5s * BBR.bw = 0.98 * BBR.bw
</pre><a href="#section-5.3.4.2-2" class="pilcrow">¶</a>
</div>
<p id="section-5.3.4.2-3">As discussed above, BBR's BBR.min_rtt filter window, BBR.MinRTTFilterLen, and
time interval between ProbeRTT states, ProbeRTTInterval, work in concert.
BBR uses a BBR.MinRTTFilterLen equal to or longer than BBR.ProbeRTTInterval to allow
the filter window to include at least one ProbeRTT.<a href="#section-5.3.4.2-3" class="pilcrow">¶</a></p>
<p id="section-5.3.4.2-4">To allow coordination with other BBR flows, each BBR flow MUST use the
standard BBR.ProbeRTTInterval of 5 secs.<a href="#section-5.3.4.2-4" class="pilcrow">¶</a></p>
<p id="section-5.3.4.2-5">A BBR.ProbeRTTInterval of 5 secs is short enough to allow quick convergence if
traffic levels or routes change, but long enough so that interactive
applications (e.g., Web, remote procedure calls, video chunks) often have
natural silences or low-rate periods within the window where the flow's rate
is low enough for long enough to drain its queue in the bottleneck. Then the
BBR.probe_rtt_min_delay filter opportunistically picks up these measurements,
and the BBR.probe_rtt_min_delay estimate refreshes without requiring
ProbeRTT. This way, flows typically need only pay the 2 percent throughput
penalty if there are multiple bulk flows busy sending over the entire
BBR.ProbeRTTInterval window.<a href="#section-5.3.4.2-5" class="pilcrow">¶</a></p>
<p id="section-5.3.4.2-6">As an optimization, when restarting from idle and finding that the
BBR.probe_rtt_min_delay has expired, BBR does not enter ProbeRTT; the idleness
is deemed a sufficient attempt to coordinate to drain the queue.<a href="#section-5.3.4.2-6" class="pilcrow">¶</a></p>
</section>
</div>
<div id="probertt-logic">
<section id="section-5.3.4.3">
            <h5 id="name-probertt-logic">
<a href="#section-5.3.4.3" class="section-number selfRef">5.3.4.3. </a><a href="#name-probertt-logic" class="section-name selfRef">ProbeRTT Logic</a>
            </h5>
<p id="section-5.3.4.3-1">On every ACK BBR executes BBRUpdateMinRTT() to update its ProbeRTT scheduling
state (BBR.probe_rtt_min_delay and BBR.probe_rtt_min_stamp) and its BBR.min_rtt
estimate:<a href="#section-5.3.4.3-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.4.3-2">
<pre>
  BBRUpdateMinRTT()
    BBR.probe_rtt_expired =
      Now() &gt; BBR.probe_rtt_min_stamp + ProbeRTTInterval
    if (RS.rtt &gt;= 0 and
        (RS.rtt &lt; BBR.probe_rtt_min_delay or
         BBR.probe_rtt_expired))
       BBR.probe_rtt_min_delay = RS.rtt
       BBR.probe_rtt_min_stamp = Now()

    min_rtt_expired =
      Now() &gt; BBR.min_rtt_stamp + MinRTTFilterLen
    if (BBR.probe_rtt_min_delay &lt; BBR.min_rtt or
        min_rtt_expired)
      BBR.min_rtt       = BBR.probe_rtt_min_delay
      BBR.min_rtt_stamp = BBR.probe_rtt_min_stamp
</pre><a href="#section-5.3.4.3-2" class="pilcrow">¶</a>
</div>
<p id="section-5.3.4.3-3">Here BBR.probe_rtt_expired is a boolean recording whether the
BBR.probe_rtt_min_delay has expired and is due for a refresh, via either
an application idle period or a transition into ProbeRTT state.<a href="#section-5.3.4.3-3" class="pilcrow">¶</a></p>
<p id="section-5.3.4.3-4">On every ACK BBR executes BBRCheckProbeRTT() to handle the steps related
to the ProbeRTT state as follows:<a href="#section-5.3.4.3-4" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.4.3-5">
<pre>
  BBRCheckProbeRTT():
    if (BBR.state != ProbeRTT and
        BBR.probe_rtt_expired and
        not BBR.idle_restart)
      BBREnterProbeRTT()
      BBRSaveCwnd()
      BBR.probe_rtt_done_stamp = 0
      BBR.ack_phase = ACKS_PROBE_STOPPING
      BBRStartRound()
    if (BBR.state == ProbeRTT)
      BBRHandleProbeRTT()
    if (RS.delivered &gt; 0)
      BBR.idle_restart = false

  BBREnterProbeRTT():
    BBR.state = ProbeRTT
    BBR.pacing_gain = 1
    BBR.cwnd_gain = BBRProbeRTTCwndGain  /* 0.5 */

  BBRHandleProbeRTT():
    /* Ignore low rate samples during ProbeRTT: */
    MarkConnectionAppLimited()
    if (BBR.probe_rtt_done_stamp == 0 and
        C.inflight &lt;= BBRProbeRTTCwnd())
      /* Wait for at least ProbeRTTDuration to elapse: */
      BBR.probe_rtt_done_stamp =
        Now() + ProbeRTTDuration
      /* Wait for at least one round to elapse: */
      BBR.probe_rtt_round_done = false
      BBRStartRound()
    else if (BBR.probe_rtt_done_stamp != 0)
      if (BBR.round_start)
        BBR.probe_rtt_round_done = true
      if (BBR.probe_rtt_round_done)
        BBRCheckProbeRTTDone()

  BBRCheckProbeRTTDone():
    if (BBR.probe_rtt_done_stamp != 0 and
        Now() &gt; BBR.probe_rtt_done_stamp)
      /* schedule next ProbeRTT: */
      BBR.probe_rtt_min_stamp = Now()
      BBRRestoreCwnd()
      BBRExitProbeRTT()

  MarkConnectionAppLimited():
    C.app_limited =
      (C.delivered + C.inflight) ? : 1
</pre><a href="#section-5.3.4.3-5" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="exiting-probertt">
<section id="section-5.3.4.4">
            <h5 id="name-exiting-probertt">
<a href="#section-5.3.4.4" class="section-number selfRef">5.3.4.4. </a><a href="#name-exiting-probertt" class="section-name selfRef">Exiting ProbeRTT</a>
            </h5>
<p id="section-5.3.4.4-1">When exiting ProbeRTT, BBR transitions to ProbeBW if it estimates the pipe
was filled already, or Startup otherwise.<a href="#section-5.3.4.4-1" class="pilcrow">¶</a></p>
<p id="section-5.3.4.4-2">When transitioning out of ProbeRTT, BBR calls BBRResetShortTermModel() to reset
the short-term model, since any congestion encountered in ProbeRTT may have pulled
it far below the capacity of the path.<a href="#section-5.3.4.4-2" class="pilcrow">¶</a></p>
<p id="section-5.3.4.4-3">But the algorithm is cautious in timing the next bandwidth probe: raising
C.inflight after ProbeRTT may cause loss, so the algorithm resets the
bandwidth-probing clock by starting the cycle at ProbeBW_DOWN(). But then as an
optimization, since the connection is exiting ProbeRTT, we know that infligh is
already below the estimated BDP, so the connection can proceed immediately to
ProbeBW_CRUISE.<a href="#section-5.3.4.4-3" class="pilcrow">¶</a></p>
<p id="section-5.3.4.4-4">To summarize, the logic for exiting ProbeRTT is as follows:<a href="#section-5.3.4.4-4" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.3.4.4-5">
<pre>
  BBRExitProbeRTT():
    BBRResetShortTermModel()
    if (BBR.full_bw_reached)
      BBRStartProbeBW_DOWN()
      BBRStartProbeBW_CRUISE()
    else
      BBREnterStartup()
</pre><a href="#section-5.3.4.4-5" class="pilcrow">¶</a>
</div>
</section>
</div>
</section>
</div>
</section>
</div>
<div id="restarting-from-idle">
<section id="section-5.4">
        <h3 id="name-restarting-from-idle">
<a href="#section-5.4" class="section-number selfRef">5.4. </a><a href="#name-restarting-from-idle" class="section-name selfRef">Restarting From Idle</a>
        </h3>
<div id="actions-when-restarting-from-idle">
<section id="section-5.4.1">
          <h4 id="name-actions-when-restarting-fro">
<a href="#section-5.4.1" class="section-number selfRef">5.4.1. </a><a href="#name-actions-when-restarting-fro" class="section-name selfRef">Actions when Restarting from Idle</a>
          </h4>
<p id="section-5.4.1-1">When restarting from idle in ProbeBW states, BBR leaves C.cwnd as-is and
paces packets at exactly BBR.bw, aiming to return as quickly as possible
to its target operating point of rate balance and a full pipe. Specifically, if
the flow's BBR.state is ProbeBW, and the flow is application-limited, and there
are no packets in flight currently, then before the flow sends one or more
packets BBR sets C.pacing_rate to exactly BBR.bw.<a href="#section-5.4.1-1" class="pilcrow">¶</a></p>
<p id="section-5.4.1-2">Also, when restarting from idle BBR checks to see if the connection is in
ProbeRTT and has met the exit conditions for ProbeRTT. If a connection goes
idle during ProbeRTT then often it will have met those exit conditions by
the time it restarts, so that the connection can restore C.cwnd to its full
value before it starts transmitting a new flight of data.<a href="#section-5.4.1-2" class="pilcrow">¶</a></p>
<p id="section-5.4.1-3">More precisely, the BBR algorithm takes the following steps in
BBRHandleRestartFromIdle() before sending a packet for a flow:<a href="#section-5.4.1-3" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.4.1-4">
<pre>
  BBRHandleRestartFromIdle():
    if (C.inflight == 0 and C.app_limited)
      BBR.idle_restart = true
      BBR.extra_acked_interval_start = Now()
      if (IsInAProbeBWState())
        BBRSetPacingRateWithGain(1)
      else if (BBR.state == ProbeRTT)
        BBRCheckProbeRTTDone()
</pre><a href="#section-5.4.1-4" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="previous-idle-restart">
<section id="section-5.4.2">
          <h4 id="name-comparison-with-previous-ap">
<a href="#section-5.4.2" class="section-number selfRef">5.4.2. </a><a href="#name-comparison-with-previous-ap" class="section-name selfRef">Comparison with Previous Approaches</a>
          </h4>
<p id="section-5.4.2-1">The "Restarting Idle Connections" section of <span>[<a href="#RFC5681" class="cite xref">RFC5681</a>]</span> suggests restarting
from idle by slow-starting from the initial window. However, this approach was
assuming a congestion control algorithm that had no estimate of the bottleneck
bandwidth and no pacing, and thus resorted to relying on slow-starting driven
by an ACK clock. The long (log_2(BDP)*RTT) delays required to reach full
utilization with that "slow start after idle" approach caused many large
deployments to disable this mechanism, resulting in a "BDP-scale line-rate
burst" approach instead. Instead of these two approaches, BBR restarts by
pacing at BBR.bw, typically achieving approximate rate balance and a full pipe
after only one BBR.min_rtt has elapsed.<a href="#section-5.4.2-1" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
<div id="updating-network-path-model-parameters">
<section id="section-5.5">
        <h3 id="name-updating-network-path-model">
<a href="#section-5.5" class="section-number selfRef">5.5. </a><a href="#name-updating-network-path-model" class="section-name selfRef">Updating Network Path Model Parameters</a>
        </h3>
<p id="section-5.5-1">BBR is a model-based congestion control algorithm: it is based on an explicit
model of the network path over which a transport flow travels. The following
is a summary of each parameter, including its meaning and how the algorithm
calculates and uses its value. We can group the parameter into three groups:<a href="#section-5.5-1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.5-2.1">
            <p id="section-5.5-2.1.1">core state machine parameters<a href="#section-5.5-2.1.1" class="pilcrow">¶</a></p>
</li>
          <li class="normal" id="section-5.5-2.2">
            <p id="section-5.5-2.2.1">parameters to model the appropriate data rate<a href="#section-5.5-2.2.1" class="pilcrow">¶</a></p>
</li>
          <li class="normal" id="section-5.5-2.3">
            <p id="section-5.5-2.3.1">parameters to model the appropriate inflight<a href="#section-5.5-2.3.1" class="pilcrow">¶</a></p>
</li>
        </ul>
<div id="bbrroundcount-tracking-packet-timed-round-trips">
<section id="section-5.5.1">
          <h4 id="name-bbrround_count-tracking-pac">
<a href="#section-5.5.1" class="section-number selfRef">5.5.1. </a><a href="#name-bbrround_count-tracking-pac" class="section-name selfRef">BBR.round_count: Tracking Packet-Timed Round Trips</a>
          </h4>
<p id="section-5.5.1-1">Several aspects of BBR depend on counting the progress of "packet-timed"
round trips, which start at the transmission of some packet, and then end
at the acknowledgment of that packet. BBR.round_count is a count of the number
of these "packet-timed" round trips elapsed so far. BBR uses this virtual
BBR.round_count because it is more robust than using wall clock time. In
particular, arbitrary intervals of wall clock time can elapse due to
application idleness, variations in RTTs, or timer delays for retransmission
timeouts, causing wall-clock-timed model parameter estimates to "time out"
or to be "forgotten" too quickly to provide robustness.<a href="#section-5.5.1-1" class="pilcrow">¶</a></p>
<p id="section-5.5.1-2">BBR counts packet-timed round trips by recording state about a sentinel packet,
and waiting for an ACK of any data packet that was sent after that sentinel
packet, using the following pseudocode:<a href="#section-5.5.1-2" class="pilcrow">¶</a></p>
<p id="section-5.5.1-3">Upon connection initialization:<a href="#section-5.5.1-3" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.1-4">
<pre>
  BBRInitRoundCounting():
    BBR.next_round_delivered = 0
    BBR.round_start = false
    BBR.round_count = 0
</pre><a href="#section-5.5.1-4" class="pilcrow">¶</a>
</div>
<p id="section-5.5.1-5">Upon sending each packet, the rate estimation algorithm in
<a href="#delivery-rate-samples" class="auto internal xref">Section 4.1</a> records the amount of data thus far
acknowledged as delivered:<a href="#section-5.5.1-5" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.1-6">
<pre>
  P.delivered = C.delivered
</pre><a href="#section-5.5.1-6" class="pilcrow">¶</a>
</div>
<p id="section-5.5.1-7">Upon receiving an ACK for a given data packet, the rate estimation algorithm
in <a href="#delivery-rate-samples" class="auto internal xref">Section 4.1</a> updates the amount of data thus far
acknowledged as delivered:<a href="#section-5.5.1-7" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.1-8">
<pre>
    C.delivered += P.size
</pre><a href="#section-5.5.1-8" class="pilcrow">¶</a>
</div>
<p id="section-5.5.1-9">Upon receiving an ACK for a given data packet, the BBR algorithm first executes
the following logic to see if a round trip has elapsed, and if so, increment
the count of such round trips elapsed:<a href="#section-5.5.1-9" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.1-10">
<pre>
  BBRUpdateRound():
    if (packet.delivered &gt;= BBR.next_round_delivered)
      BBRStartRound()
      BBR.round_count++
      BBR.rounds_since_bw_probe++
      BBR.round_start = true
    else
      BBR.round_start = false

  BBRStartRound():
    BBR.next_round_delivered = C.delivered
</pre><a href="#section-5.5.1-10" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="bbrmaxbw-estimated-maximum-bandwidth">
<section id="section-5.5.2">
          <h4 id="name-bbrmax_bw-estimated-maximum">
<a href="#section-5.5.2" class="section-number selfRef">5.5.2. </a><a href="#name-bbrmax_bw-estimated-maximum" class="section-name selfRef">BBR.max_bw: Estimated Maximum Bandwidth</a>
          </h4>
<p id="section-5.5.2-1">BBR.max_bw is BBR's estimate of the maximum bottleneck bandwidth available to
data transmissions for the transport flow. At any time, a transport
connection's data transmissions experience some slowest link or bottleneck. The
bottleneck's delivery rate determines the connection's maximum data-delivery
rate. BBR tries to closely match its sending rate to this bottleneck delivery
rate to help seek "rate balance", where the flow's packet arrival rate at the
bottleneck equals the departure rate. The bottleneck rate varies over the life
of a connection, so BBR continually estimates BBR.max_bw using recent signals.<a href="#section-5.5.2-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="bbrmaxbw-max-filter">
<section id="section-5.5.3">
          <h4 id="name-bbrmax_bw-max-filter">
<a href="#section-5.5.3" class="section-number selfRef">5.5.3. </a><a href="#name-bbrmax_bw-max-filter" class="section-name selfRef">BBR.max_bw Max Filter</a>
          </h4>
<p id="section-5.5.3-1">Delivery rate samples are often below the typical bottleneck bandwidth
available to the flow, due to "noise" introduced by random variation in
physical transmission processes (e.g. radio link layer noise) or queues or
along the network path.  To filter these effects BBR uses a max filter: BBR
estimates BBR.max_bw using the windowed maximum recent delivery rate sample
seen by the connection over recent history.<a href="#section-5.5.3-1" class="pilcrow">¶</a></p>
<p id="section-5.5.3-2">The BBR.max_bw max filter window covers a time period extending over the
past two ProbeBW cycles. The BBR.max_bw max filter window length is driven
by trade-offs among several considerations:<a href="#section-5.5.3-2" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.5.3-3.1">
              <p id="section-5.5.3-3.1.1">It is long enough to cover at least one entire ProbeBW cycle (see the
"ProbeBW" section). This ensures that the window contains at least some
delivery rate samples that are the result of data transmitted with a
super-unity pacing_gain (a pacing_gain larger than 1.0). Such super-unity
delivery rate samples are instrumental in revealing the path's underlying
available bandwidth even when there is noise from delivery rate shortfalls
due to aggregation delays, queuing delays from variable cross-traffic, lossy
link layers with uncorrected losses, or short-term buffer exhaustion (e.g.,
brief coincident bursts in a shallow buffer).<a href="#section-5.5.3-3.1.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.5.3-3.2">
              <p id="section-5.5.3-3.2.1">It aims to be long enough to cover short-term fluctuations in the network's
delivery rate due to the aforementioned sources of noise. In particular, the
delivery rate for radio link layers (e.g., wifi and cellular technologies)
can be highly variable, and the filter window needs to be long enough to
remember "good" delivery rate samples in order to be robust to such
variations.<a href="#section-5.5.3-3.2.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.5.3-3.3">
              <p id="section-5.5.3-3.3.1">It aims to be short enough to respond in a timely manner to sustained
reductions in the bandwidth available to a flow, whether this is because
other flows are using a larger share of the bottleneck, or the bottleneck
link service rate has reduced due to layer 1 or layer 2 changes, policy
changes, or routing changes. In any of these cases, existing BBR flows
traversing the bottleneck should, in a timely manner, reduce their BBR.max_bw
estimates and thus pacing rate and in-flight data, in order to match the
sending behavior to the new available bandwidth.<a href="#section-5.5.3-3.3.1" class="pilcrow">¶</a></p>
</li>
          </ul>
</section>
</div>
<div id="bbrmaxbw-and-application-limited-delivery-rate-samples">
<section id="section-5.5.4">
          <h4 id="name-bbrmax_bw-and-application-l">
<a href="#section-5.5.4" class="section-number selfRef">5.5.4. </a><a href="#name-bbrmax_bw-and-application-l" class="section-name selfRef">BBR.max_bw and Application-limited Delivery Rate Samples</a>
          </h4>
<p id="section-5.5.4-1">Transmissions can be application-limited, meaning the transmission rate is
limited by the application rather than the congestion control algorithm.  This
is quite common because of request/response traffic. When there is a
transmission opportunity but no data to send, the delivery rate sampler marks
the corresponding bandwidth sample(s) as application-limited
<a href="#delivery-rate-samples" class="auto internal xref">Section 4.1</a>.  The BBR.max_bw estimator carefully decides which
samples to include in the bandwidth model to ensure that BBR.max_bw reflects
network limits, not application limits. By default, the estimator discards
application-limited samples, since by definition they reflect application
limits. However, the estimator does use application-limited samples if the
measured delivery rate happens to be larger than the current BBR.max_bw
estimate, since this indicates the current BBR.Max_bw estimate is too low.<a href="#section-5.5.4-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="updating-the-bbrmaxbw-max-filter">
<section id="section-5.5.5">
          <h4 id="name-updating-the-bbrmax_bw-max-">
<a href="#section-5.5.5" class="section-number selfRef">5.5.5. </a><a href="#name-updating-the-bbrmax_bw-max-" class="section-name selfRef">Updating the BBR.max_bw Max Filter</a>
          </h4>
<p id="section-5.5.5-1">For every ACK that acknowledges some data packets as delivered, BBR invokes
BBRUpdateMaxBw() to update the BBR.max_bw estimator as follows:<a href="#section-5.5.5-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.5-2">
<pre>
  BBRUpdateMaxBw()
    BBRUpdateRound()
    if (RS.delivery_rate &gt;= BBR.max_bw || !RS.is_app_limited)
        BBR.max_bw = UpdateWindowedMaxFilter(
                      filter=BBR.MaxBwFilter,
                      value=RS.delivery_rate,
                      time=BBR.cycle_count,
                      window_length=MaxBwFilterLen)
</pre><a href="#section-5.5.5-2" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="tracking-time-for-the-bbrmaxbw-max-filter">
<section id="section-5.5.6">
          <h4 id="name-tracking-time-for-the-bbrma">
<a href="#section-5.5.6" class="section-number selfRef">5.5.6. </a><a href="#name-tracking-time-for-the-bbrma" class="section-name selfRef">Tracking Time for the BBR.max_bw Max Filter</a>
          </h4>
<p id="section-5.5.6-1">BBR tracks time for the BBR.max_bw filter window using a virtual
(non-wall-clock) time tracked by counting the cyclical progression through
ProbeBW cycles.  Each time through the Probe bw cycle, one round trip after
exiting ProbeBW_UP (the point at which the flow has its best chance to measure
the highest throughput of the cycle), BBR increments BBR.cycle_count, the
virtual time used by the BBR.max_bw filter window. Note that BBR.cycle_count
only needs to be tracked with a single bit, since the BBR.max_bw filter only
needs to track samples from two time slots: the previous ProbeBW cycle and the
current ProbeBW cycle:<a href="#section-5.5.6-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.6-2">
<pre>
  BBRAdvanceMaxBwFilter():
    BBR.cycle_count++
</pre><a href="#section-5.5.6-2" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="bbrminrtt-estimated-minimum-round-trip-time">
<section id="section-5.5.7">
          <h4 id="name-bbrmin_rtt-estimated-minimu">
<a href="#section-5.5.7" class="section-number selfRef">5.5.7. </a><a href="#name-bbrmin_rtt-estimated-minimu" class="section-name selfRef">BBR.min_rtt: Estimated Minimum Round-Trip Time</a>
          </h4>
<p id="section-5.5.7-1">BBR.min_rtt is BBR's estimate of the round-trip propagation delay of the path
over which a transport connection is sending. The path's round-trip propagation
delay determines the minimum amount of time over which the connection must be
willing to sustain transmissions at the BBR.bw rate, and thus the minimum
amount of data needed in flight, for the connection to reach full utilization
(a "Full Pipe"). The round-trip propagation delay can vary over the life of a
connection, so BBR continually estimates BBR.min_rtt using recent round-trip
delay samples.<a href="#section-5.5.7-1" class="pilcrow">¶</a></p>
<div id="round-trip-time-samples-for-estimating-bbrminrtt">
<section id="section-5.5.7.1">
            <h5 id="name-round-trip-time-samples-for">
<a href="#section-5.5.7.1" class="section-number selfRef">5.5.7.1. </a><a href="#name-round-trip-time-samples-for" class="section-name selfRef">Round-Trip Time Samples for Estimating BBR.min_rtt</a>
            </h5>
<p id="section-5.5.7.1-1">For every data packet a connection sends, BBR calculates an RTT sample that
measures the time interval from sending a data packet until that packet is
acknowledged.<a href="#section-5.5.7.1-1" class="pilcrow">¶</a></p>
<p id="section-5.5.7.1-2">The only divergence from RTT estimation for retransmission timeouts is in the
case where a given acknowledgment ACKs more than one data packet. In order to
be conservative and schedule long timeouts to avoid spurious retransmissions,
the maximum among such potential RTT samples is typically used for computing
retransmission timeouts; i.e., SRTT is typically calculated using the data
packet with the earliest transmission time. By contrast, in order for BBR to
try to reach the minimum amount of data in flight to fill the pipe, BBR uses
the minimum among such potential RTT samples; i.e., BBR calculates the RTT
using the data packet with the latest transmission time.<a href="#section-5.5.7.1-2" class="pilcrow">¶</a></p>
</section>
</div>
<div id="bbrminrtt-min-filter">
<section id="section-5.5.7.2">
            <h5 id="name-bbrmin_rtt-min-filter">
<a href="#section-5.5.7.2" class="section-number selfRef">5.5.7.2. </a><a href="#name-bbrmin_rtt-min-filter" class="section-name selfRef">BBR.min_rtt Min Filter</a>
            </h5>
<p id="section-5.5.7.2-1">RTT samples tend to be above the round-trip propagation delay of the path,
due to "noise" introduced by random variation in physical transmission processes
(e.g. radio link layer noise), queues along the network path, the receiver's
delayed ack strategy, ack aggregation, etc. Thus to filter out these effects
BBR uses a min filter: BBR estimates BBR.min_rtt using the minimum recent
RTT sample seen by the connection over that past BBR.MinRTTFilterLen seconds.
(Many of the same network effects that can decrease delivery rate measurements
can increase RTT samples, which is why BBR's min-filtering approach for RTTs
is the complement of its max-filtering approach for delivery rates.)<a href="#section-5.5.7.2-1" class="pilcrow">¶</a></p>
<p id="section-5.5.7.2-2">The length of the BBR.min_rtt min filter window is BBR.MinRTTFilterLen = 10 secs.
This is driven by trade-offs among several considerations:<a href="#section-5.5.7.2-2" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.5.7.2-3.1">
                <p id="section-5.5.7.2-3.1.1">The BBR.MinRTTFilterLen is longer than BBR.ProbeRTTInterval, so that it covers an
entire ProbeRTT cycle (see the "ProbeRTT" section below). This helps ensure
that the window can contain RTT samples that are the result of data
transmitted with C.inflight below the estimated BDP of the flow. Such RTT
samples are important for helping to reveal the path's underlying two-way
propagation delay even when the aforementioned "noise" effects can often
obscure it.<a href="#section-5.5.7.2-3.1.1" class="pilcrow">¶</a></p>
</li>
              <li class="normal" id="section-5.5.7.2-3.2">
                <p id="section-5.5.7.2-3.2.1">The BBR.MinRTTFilterLen aims to be long enough to avoid needing to reduce in-flight
data and throughput often. Measuring two-way propagation delay requires in-flight
data to be at or below the BDP, which risks  some amount of underutilization, so BBR
uses a filter window long enough that such underutilization events can be
rare.<a href="#section-5.5.7.2-3.2.1" class="pilcrow">¶</a></p>
</li>
              <li class="normal" id="section-5.5.7.2-3.3">
                <p id="section-5.5.7.2-3.3.1">The BBR.MinRTTFilterLen aims to be long enough that many applications have a
"natural" moment of silence or low utilization that can reduce in-flight data below
the BDP and naturally serve to refresh the BBR.min_rtt, without requiring BBR to
force an artificial reduction in in-flight data. This applies to many popular
applications, including Web, RPC, or chunked audio/video traffic.<a href="#section-5.5.7.2-3.3.1" class="pilcrow">¶</a></p>
</li>
              <li class="normal" id="section-5.5.7.2-3.4">
                <p id="section-5.5.7.2-3.4.1">The BBR.MinRTTFilterLen aims to be short enough to respond in a timely manner to
real increases in the two-way propagation delay of the path, e.g. due to
route changes, which are expected to typically happen on longer time scales.<a href="#section-5.5.7.2-3.4.1" class="pilcrow">¶</a></p>
</li>
            </ul>
<p id="section-5.5.7.2-4">A BBR implementation MAY use a generic windowed min filter to track BBR.min_rtt.
However, a significant savings in space and improvement in freshness can
be achieved by integrating the BBR.min_rtt estimation into the ProbeRTT state
machine, so this document discusses that approach in the ProbeRTT section.<a href="#section-5.5.7.2-4" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
<div id="bbroffloadbudget">
<section id="section-5.5.8">
          <h4 id="name-bbroffload_budget">
<a href="#section-5.5.8" class="section-number selfRef">5.5.8. </a><a href="#name-bbroffload_budget" class="section-name selfRef">BBR.offload_budget</a>
          </h4>
<p id="section-5.5.8-1">BBR.offload_budget is the estimate of the minimum volume of data necessary
to achieve full throughput using sender (TSO/GSO) and receiver (LRO, GRO)
host offload mechanisms.  This varies based on the transport protocol and
operating environment.<a href="#section-5.5.8-1" class="pilcrow">¶</a></p>
<p id="section-5.5.8-2">For TCP, offload_budget can be computed as follows:<a href="#section-5.5.8-2" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.8-3">
<pre>
    BBRUpdateOffloadBudget():
      BBR.offload_budget = 3 * C.send_quantum
</pre><a href="#section-5.5.8-3" class="pilcrow">¶</a>
</div>
<p id="section-5.5.8-4">The factor of 3 is chosen to allow maintaining at least:<a href="#section-5.5.8-4" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.5.8-5.1">
              <p id="section-5.5.8-5.1.1">1 quantum in the sending host's queuing discipline layer<a href="#section-5.5.8-5.1.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.5.8-5.2">
              <p id="section-5.5.8-5.2.1">1 quantum being segmented in the sending host TSO/GSO engine<a href="#section-5.5.8-5.2.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.5.8-5.3">
              <p id="section-5.5.8-5.3.1">1 quantum being reassembled or otherwise remaining unacknowledged due to
the receiver host's LRO/GRO/delayed-ACK engine<a href="#section-5.5.8-5.3.1" class="pilcrow">¶</a></p>
</li>
          </ul>
</section>
</div>
<div id="bbrextraacked">
<section id="section-5.5.9">
          <h4 id="name-bbrextra_acked">
<a href="#section-5.5.9" class="section-number selfRef">5.5.9. </a><a href="#name-bbrextra_acked" class="section-name selfRef">BBR.extra_acked</a>
          </h4>
<p id="section-5.5.9-1">BBR.extra_acked is a volume of data that is the estimate of the recent degree
of aggregation in the network path. For each ACK, the algorithm computes
a sample of the estimated extra ACKed data beyond the amount of data that
the sender expected to be ACKed over the timescale of a round-trip, given
the BBR.bw. Then it computes BBR.extra_acked as the windowed maximum sample
over the last BBRExtraAckedFilterLen=10 packet-timed round-trips. If the
ACK rate falls below the expected bandwidth, then the algorithm estimates
an aggregation episode has terminated, and resets the sampling interval to
start from the current time.<a href="#section-5.5.9-1" class="pilcrow">¶</a></p>
<p id="section-5.5.9-2">The BBR.extra_acked thus reflects the recently-measured magnitude of data
and ACK aggregation effects such as batching and slotting at shared-medium
L2 hops (wifi, cellular, DOCSIS), as well as end-host offload mechanisms
(TSO, GSO, LRO, GRO), and end host or middlebox ACK decimation/thinning.<a href="#section-5.5.9-2" class="pilcrow">¶</a></p>
<p id="section-5.5.9-3">BBR augments C.cwnd by BBR.extra_acked to allow the connection to keep
sending during inter-ACK silences, to an extent that matches the recently
measured degree of aggregation.<a href="#section-5.5.9-3" class="pilcrow">¶</a></p>
<p id="section-5.5.9-4">More precisely, this is computed as:<a href="#section-5.5.9-4" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.9-5">
<pre>
  BBRUpdateACKAggregation():
    /* Find excess ACKed beyond expected amount over this interval */
    interval = (Now() - BBR.extra_acked_interval_start)
    expected_delivered = BBR.bw * interval
    /* Reset interval if ACK rate is below expected rate: */
    if (BBR.extra_acked_delivered &lt;= expected_delivered)
        BBR.extra_acked_delivered = 0
        BBR.extra_acked_interval_start = Now()
        expected_delivered = 0
    BBR.extra_acked_delivered += RS.newly_acked
    extra = BBR.extra_acked_delivered - expected_delivered
    extra = min(extra, C.cwnd)
    if (BBR.full_bw_reached)
      filter_len = BBRExtraAckedFilterLen
    else
      filter_len = 1  /* in Startup, just remember 1 round */
    BBR.extra_acked =
      UpdateWindowedMaxFilter(
        filter=BBR.ExtraACKedFilter,
        value=extra,
        time=BBR.round_count,
        window_length=filter_len)
</pre><a href="#section-5.5.9-5" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="updating-the-model-upon-packet-loss">
<section id="section-5.5.10">
          <h4 id="name-updating-the-model-upon-pac">
<a href="#section-5.5.10" class="section-number selfRef">5.5.10. </a><a href="#name-updating-the-model-upon-pac" class="section-name selfRef">Updating the Model Upon Packet Loss</a>
          </h4>
<p id="section-5.5.10-1">In every state, BBR responds to (filtered) congestion signals, including
loss. The response to those congestion signals depends on the flow's current
state, since the information that the flow can infer depends on what the
flow was doing when the flow experienced the signal.<a href="#section-5.5.10-1" class="pilcrow">¶</a></p>
<div id="probing-for-bandwidth-in-startup">
<section id="section-5.5.10.1">
            <h5 id="name-probing-for-bandwidth-in-st">
<a href="#section-5.5.10.1" class="section-number selfRef">5.5.10.1. </a><a href="#name-probing-for-bandwidth-in-st" class="section-name selfRef">Probing for Bandwidth In Startup</a>
            </h5>
<p id="section-5.5.10.1-1">In Startup, if the congestion signals meet the Startup exit criteria, the flow
exits Startup and enters Drain (see <a href="#exiting-startup-based-on-packet-loss" class="auto internal xref">Section 5.3.1.3</a>).<a href="#section-5.5.10.1-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="probing-for-bandwidth-in-probebw">
<section id="section-5.5.10.2">
            <h5 id="name-probing-for-bandwidth-in-pr">
<a href="#section-5.5.10.2" class="section-number selfRef">5.5.10.2. </a><a href="#name-probing-for-bandwidth-in-pr" class="section-name selfRef">Probing for Bandwidth In ProbeBW</a>
            </h5>
<p id="section-5.5.10.2-1">BBR searches for the maximum volume of data that can be sensibly placed
in flight in the network. A key precondition is that the flow is actually
trying robustly to find that operating point. To implement this, when a flow is
in ProbeBW, and an ACK covers data sent in one of the accelerating phases
(REFILL or UP), and the ACK indicates that the loss rate over the past round
trip exceeds the queue pressure objective, and the flow is not application
limited, and has not yet responded to congestion signals from the most recent
REFILL or UP phase, then the flow estimates that the volume of data it allowed
in flight exceeded what matches the current delivery process on the path, and
reduces BBR.inflight_longterm:<a href="#section-5.5.10.2-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.10.2-2">
<pre>
  /* Do loss signals suggest C.inflight is too high? */
  IsInflightTooHigh():
    return (RS.lost &gt; RS.tx_in_flight * BBR.LossThresh)

  BBRHandleInflightTooHigh():
    BBR.bw_probe_samples = 0;  /* only react once per bw probe */
    if (!RS.is_app_limited)
      BBR.inflight_longterm = max(RS.tx_in_flight,
                            BBRTargetInflight() * BBR.Beta))
    If (BBR.state == ProbeBW_UP)
      BBRStartProbeBW_DOWN()
</pre><a href="#section-5.5.10.2-2" class="pilcrow">¶</a>
</div>
<p id="section-5.5.10.2-3">Here RS.tx_in_flight is the C.inflight value
when the most recently ACKed packet was sent. And the BBR.Beta (0.7x) bound
is to try to ensure that BBR does not react more dramatically than CUBIC's
0.7x multiplicative decrease factor.<a href="#section-5.5.10.2-3" class="pilcrow">¶</a></p>
<p id="section-5.5.10.2-4">Some loss detection algorithms, including RACK <span>[<a href="#RFC8985" class="cite xref">RFC8985</a>]</span> or QUIC loss
detection <span>[<a href="#RFC9002" class="cite xref">RFC9002</a>]</span>, delay loss marking to wait for potential
reordering, so packets can be declared lost long after the loss itself.
happened. In such cases, the tx_in_flight for the delivered sequence range
that allowed the loss to be detected may be considerably smaller than the
tx_in_flight of the lost packet itself. In such cases using the former
tx_in_flight rather than the latter can cause BBR.inflight_longterm to be
significantly underestimated. To avoid such issues, BBR processes each loss
detection event to more precisely estimate C.inflight at
which loss rates cross BBR.LossThresh, noting that this may have happened
mid-way through some TSO/GSO offload burst (represented as a "packet" in
the pseudocode in this document). To estimate this threshold volume of data,
we can solve for "lost_prefix" in the following way, where inflight_prev
represents C.inflight preceding this packet, and lost_prev
represents the data lost among that previous in-flight data.<a href="#section-5.5.10.2-4" class="pilcrow">¶</a></p>
<p id="section-5.5.10.2-5">First we start with:<a href="#section-5.5.10.2-5" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.10.2-6">
<pre>
  lost / C.inflight &gt;= BBR.LossThresh
</pre><a href="#section-5.5.10.2-6" class="pilcrow">¶</a>
</div>
<p id="section-5.5.10.2-7">Expanding this, we get:<a href="#section-5.5.10.2-7" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.10.2-8">
<pre>
  (lost_prev + lost_prefix) /    &gt;= BBR.LossThresh
  (inflight_prev + lost_prefix)
</pre><a href="#section-5.5.10.2-8" class="pilcrow">¶</a>
</div>
<p id="section-5.5.10.2-9">Solving for lost_prefix, we arrive at:<a href="#section-5.5.10.2-9" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.10.2-10">
<pre>
  lost_prefix &gt;= (BBR.LossThresh * inflight_prev - lost_prev) /
                    (1 - BBR.LossThresh)
</pre><a href="#section-5.5.10.2-10" class="pilcrow">¶</a>
</div>
<p id="section-5.5.10.2-11">In pseudocode:<a href="#section-5.5.10.2-11" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.10.2-12">
<pre>
  BBRNoteLoss()
    if (!BBR.loss_in_round)   /* first loss in this round trip? */
      BBR.loss_round_delivered = C.delivered
    BBR.loss_in_round = 1

  BBRHandleLostPacket(packet):
    BBRNoteLoss()
    if (!BBR.bw_probe_samples)
      return /* not a packet sent while probing bandwidth */
    RS.tx_in_flight = P.tx_in_flight /* C.inflight at transmit */
    RS.lost = C.lost - P.lost /* data lost since transmit */
    RS.is_app_limited = P.is_app_limited;
    if (IsInflightTooHigh())
      RS.tx_in_flight = BBRInflightLongtermFromLostPacket(rs, packet)
      BBRHandleInflightTooHigh()

  /* At what prefix of packet did losses exceed BBR.LossThresh? */
  BBRInflightLongtermFromLostPacket(rs, packet):
    size = packet.size
    /* What was in flight before this packet? */
    inflight_prev = RS.tx_in_flight - size
    /* What was lost before this packet? */
    lost_prev = RS.lost - size
    lost_prefix = (BBR.LossThresh * inflight_prev - lost_prev) /
                  (1 - BB.RLossThresh)
    /* At what C.inflight value did losses cross BBR.LossThresh? */
    inflight_at_loss = inflight_prev + lost_prefix
    return inflight_at_loss
</pre><a href="#section-5.5.10.2-12" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="when-not-probing-for-bandwidth">
<section id="section-5.5.10.3">
            <h5 id="name-when-not-probing-for-bandwi">
<a href="#section-5.5.10.3" class="section-number selfRef">5.5.10.3. </a><a href="#name-when-not-probing-for-bandwi" class="section-name selfRef">When not Probing for Bandwidth</a>
            </h5>
<p id="section-5.5.10.3-1">When not explicitly accelerating to probe for bandwidth (Drain, ProbeRTT,
ProbeBW_DOWN, ProbeBW_CRUISE), BBR  responds to loss by slowing down to some
extent. This is because loss suggests that the available bandwidth and safe
C.inflight may have decreased recently, and the flow needs
to adapt, slowing down toward the latest delivery process. BBR flows implement
this response by reducing the short-term model parameters, BBR.bw_shortterm and
BBR.inflight_shortterm.<a href="#section-5.5.10.3-1" class="pilcrow">¶</a></p>
<p id="section-5.5.10.3-2">When encountering packet loss when the flow is not probing for bandwidth,
the strategy is to gradually adapt to the current measured delivery process
(the rate and volume of data that is delivered through the network path over
the last round trip). This applies generally: whether in fast recovery, RTO
recovery, TLP recovery; whether application-limited or not.<a href="#section-5.5.10.3-2" class="pilcrow">¶</a></p>
<p id="section-5.5.10.3-3">There are two key parameters the algorithm tracks, to measure the current
delivery process:<a href="#section-5.5.10.3-3" class="pilcrow">¶</a></p>
<p id="section-5.5.10.3-4">BBR.bw_latest: a 1-round-trip max of delivered bandwidth (RS.delivery_rate).<a href="#section-5.5.10.3-4" class="pilcrow">¶</a></p>
<p id="section-5.5.10.3-5">BBR.inflight_latest: a 1-round-trip max of delivered volume of data
(RS.delivered).<a href="#section-5.5.10.3-5" class="pilcrow">¶</a></p>
<p id="section-5.5.10.3-6">Upon the ACK at the end of each round that encountered a newly-marked loss,
the flow updates its model (BBR.bw_shortterm and BBR.inflight_shortterm) as follows:<a href="#section-5.5.10.3-6" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.10.3-7">
<pre>
      bw_shortterm = max(       bw_latest, BBR.Beta *       BBR.bw_shortterm )
inflight_shortterm = max( inflight_latest, BBR.Beta * BBR.inflight_shortterm )
</pre><a href="#section-5.5.10.3-7" class="pilcrow">¶</a>
</div>
<p id="section-5.5.10.3-8">This logic can be represented as follows:<a href="#section-5.5.10.3-8" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.5.10.3-9">
<pre>
  /* Near start of ACK processing: */
  BBRUpdateLatestDeliverySignals():
    BBR.loss_round_start = 0
    BBR.bw_latest       = max(BBR.bw_latest,       RS.delivery_rate)
    BBR.inflight_latest = max(BBR.inflight_latest, RS.delivered)
    if (RS.prior_delivered &gt;= BBR.loss_round_delivered)
      BBR.loss_round_delivered = C.delivered
      BBR.loss_round_start = 1

  /* Near end of ACK processing: */
  BBRAdvanceLatestDeliverySignals():
    if (BBR.loss_round_start)
      BBR.bw_latest       = RS.delivery_rate
      BBR.inflight_latest = RS.delivered

  BBRResetCongestionSignals():
    BBR.loss_in_round = 0
    BBR.bw_latest = 0
    BBR.inflight_latest = 0

  /* Update congestion state on every ACK */
  BBRUpdateCongestionSignals():
    BBRUpdateMaxBw()
    if (!BBR.loss_round_start)
      return  /* wait until end of round trip */
    BBRAdaptLowerBoundsFromCongestion()  /* once per round, adapt */
    BBR.loss_in_round = 0

  /* Once per round-trip respond to congestion */
  BBRAdaptLowerBoundsFromCongestion():
    if (BBRIsProbingBW())
      return
    if (BBR.loss_in_round)
      BBRInitLowerBounds()
      BBRLossLowerBounds()

  /* Handle the first congestion episode in this cycle */
  BBRInitLowerBounds():
    if (BBR.bw_shortterm == Infinity)
      BBR.bw_shortterm = BBR.max_bw
    if (BBR.inflight_shortterm == Infinity)
      BBR.inflight_shortterm = C.cwnd

  /* Adjust model once per round based on loss */
  BBRLossLowerBounds()
    BBR.bw_shortterm       = max(BBR.bw_latest,
                          BBR.Beta * BBR.bw_shortterm)
    BBR.inflight_shortterm = max(BBR.inflight_latest,
                          BBR.Beta * BBR.inflight_shortterm)

  BBRResetShortTermModel():
    BBR.bw_shortterm       = Infinity
    BBR.inflight_shortterm = Infinity

  BBRBoundBWForModel():
    BBR.bw = min(BBR.max_bw, BBR.bw_shortterm)

</pre><a href="#section-5.5.10.3-9" class="pilcrow">¶</a>
</div>
</section>
</div>
</section>
</div>
</section>
</div>
<div id="updating-control-parameters">
<section id="section-5.6">
        <h3 id="name-updating-control-parameters">
<a href="#section-5.6" class="section-number selfRef">5.6. </a><a href="#name-updating-control-parameters" class="section-name selfRef">Updating Control Parameters</a>
        </h3>
<p id="section-5.6-1">BBR uses three distinct but interrelated control parameters: pacing rate,
send quantum, and congestion window.<a href="#section-5.6-1" class="pilcrow">¶</a></p>
<div id="summary-of-control-behavior-in-the-state-machine">
<section id="section-5.6.1">
          <h4 id="name-summary-of-control-behavior">
<a href="#section-5.6.1" class="section-number selfRef">5.6.1. </a><a href="#name-summary-of-control-behavior" class="section-name selfRef">Summary of Control Behavior in the State Machine</a>
          </h4>
<p id="section-5.6.1-1">The following table summarizes how BBR modulates the control parameters in
each state. In the table below, the semantics of the columns are as follows:<a href="#section-5.6.1-1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.6.1-2.1">
              <p id="section-5.6.1-2.1.1">State: the state in the BBR state machine, as depicted in the "State
Transition Diagram" section above.<a href="#section-5.6.1-2.1.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.6.1-2.2">
              <p id="section-5.6.1-2.2.1">Tactic: The tactic chosen from the "State Machine Tactics" in
<a href="#state-machine-tactics" class="auto internal xref">Section 5.1.3</a>: "accel" refers to acceleration, "decel" to
deceleration, and "cruise" to cruising.<a href="#section-5.6.1-2.2.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.6.1-2.3">
              <p id="section-5.6.1-2.3.1">Pacing Gain: the value used for BBR.pacing_gain in the given state.<a href="#section-5.6.1-2.3.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.6.1-2.4">
              <p id="section-5.6.1-2.4.1">Cwnd Gain: the value used for BBR.cwnd_gain in the given state.<a href="#section-5.6.1-2.4.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.6.1-2.5">
              <p id="section-5.6.1-2.5.1">Rate Cap: the rate values applied as bounds on the BBR.max_bw value applied
to compute BBR.bw.<a href="#section-5.6.1-2.5.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.6.1-2.6">
              <p id="section-5.6.1-2.6.1">Volume Cap: the volume values applied as bounds on the BBR.max_inflight value
to compute C.cwnd.<a href="#section-5.6.1-2.6.1" class="pilcrow">¶</a></p>
</li>
          </ul>
<p id="section-5.6.1-3">The control behavior can be summarized as follows. Upon processing each ACK,
BBR uses the values in the table below to compute BBR.bw in
BBRBoundBWForModel(), and C.cwnd in BBRBoundCwndForModel():<a href="#section-5.6.1-3" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.1-4">
<pre>
---------------+--------+--------+------+--------------+-----------------
State          | Tactic | Pacing | Cwnd | Rate         | Volume
               |        | Gain   | Gain | Cap          | Cap
---------------+--------+--------+------+--------------+-----------------
Startup        | accel  | 2.77   | 2    | N/A          | N/A
               |        |        |      |              |
---------------+--------+--------+------+--------------+-----------------
Drain          | decel  | 0.5    | 2    | bw_shortterm | inflight_longterm,
               |        |        |      |              | inflight_shortterm
---------------+--------+--------+------+--------------+-----------------
ProbeBW_DOWN   | decel  | 0.90   | 2    | bw_shortterm | inflight_longterm,
               |        |        |      |              | inflight_shortterm
---------------+--------+--------+------+--------------+-----------------
ProbeBW_CRUISE | cruise | 1.0    | 2    | bw_shortterm | 0.85*inflight_longterm
               |        |        |      |              | inflight_shortterm
---------------+--------+--------+------+--------------+-----------------
ProbeBW_REFILL | accel  | 1.0    | 2    |              | inflight_longterm
               |        |        |      |              |
---------------+--------+--------+------+--------------+-----------------
ProbeBW_UP     | accel  | 1.25   | 2.25 |              | inflight_longterm
               |        |        |      |              |
---------------+--------+--------+------+--------------+-----------------
ProbeRTT       | decel  | 1.0    | 0.5  | bw_shortterm | 0.85*inflight_longterm
               |        |        |      |              | inflight_shortterm
---------------+--------+--------+------+--------------+-----------------
</pre><a href="#section-5.6.1-4" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="pacing-rate-bbrpacingrate">
<section id="section-5.6.2">
          <h4 id="name-pacing-rate-cpacing_rate">
<a href="#section-5.6.2" class="section-number selfRef">5.6.2. </a><a href="#name-pacing-rate-cpacing_rate" class="section-name selfRef">Pacing Rate: C.pacing_rate</a>
          </h4>
<p id="section-5.6.2-1">To help match the packet-arrival rate to the bottleneck bandwidth available
to the flow, BBR paces data packets. Pacing enforces a maximum rate at which
BBR schedules quanta of packets for transmission.<a href="#section-5.6.2-1" class="pilcrow">¶</a></p>
<p id="section-5.6.2-2">The sending host implements pacing by maintaining inter-quantum spacing at
the time each packet is scheduled for departure, calculating the next departure
time for a packet for a given flow (BBR.next_departure_time) as a function
of the most recent packet size and the current pacing rate, as follows:<a href="#section-5.6.2-2" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.2-3">
<pre>
  BBR.next_departure_time = max(Now(), BBR.next_departure_time)
  P.departure_time = BBR.next_departure_time
  pacing_delay = packet.size / C.pacing_rate
  BBR.next_departure_time = BBR.next_departure_time + pacing_delay
</pre><a href="#section-5.6.2-3" class="pilcrow">¶</a>
</div>
<p id="section-5.6.2-4">To adapt to the bottleneck, in general BBR sets the pacing rate to be
proportional to bw, with a dynamic gain, or scaling factor of proportionality,
called pacing_gain.<a href="#section-5.6.2-4" class="pilcrow">¶</a></p>
<p id="section-5.6.2-5">When a BBR flow starts it has no bw estimate (bw is 0). So in this case it
sets an initial pacing rate based on the transport sender implementation's
initial congestion window ("C.InitialCwnd", e.g. from <span>[<a href="#RFC6928" class="cite xref">RFC6928</a>]</span>), the
initial SRTT (smoothed round-trip time) after the first non-zero RTT
sample, and the initial pacing_gain:<a href="#section-5.6.2-5" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.2-6">
<pre>
  BBRInitPacingRate():
    nominal_bandwidth = C.InitialCwnd / (SRTT ? SRTT : 1ms)
    C.pacing_rate =  BBR.StartupPacingGain * nominal_bandwidth
</pre><a href="#section-5.6.2-6" class="pilcrow">¶</a>
</div>
<p id="section-5.6.2-7">After initialization, on each data ACK BBR updates its pacing rate to be
proportional to bw, as long as it estimates that it has filled the pipe
(BBR.full_bw_reached is true; see the "Startup" section for details), or
doing so increases the pacing rate. Limiting the pacing rate updates in this way
helps the connection probe robustly for bandwidth until it estimates it has
reached its full available bandwidth ("filled the pipe"). In particular,
this prevents the pacing rate from being reduced when the connection has only
seen application-limited bandwidth samples. BBR updates the pacing rate on each
ACK by executing the BBRSetPacingRate() step as follows:<a href="#section-5.6.2-7" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.2-8">
<pre>
  BBRSetPacingRateWithGain(pacing_gain):
    rate = pacing_gain * bw * (100 - BBR.PacingMarginPercent) / 100
    if (BBR.full_bw_reached || rate &gt; C.pacing_rate)
      C.pacing_rate = rate

  BBRSetPacingRate():
    BBRSetPacingRateWithGain(C.pacing_gain)
</pre><a href="#section-5.6.2-8" class="pilcrow">¶</a>
</div>
<p id="section-5.6.2-9">To help drive the network toward lower queues and low latency while maintaining
high utilization, the BBR.PacingMarginPercent constant of 1 aims to cause
BBR to pace at 1% below the bw, on average.<a href="#section-5.6.2-9" class="pilcrow">¶</a></p>
</section>
</div>
<div id="send-quantum-bbrsendquantum">
<section id="section-5.6.3">
          <h4 id="name-send-quantum-csend_quantum">
<a href="#section-5.6.3" class="section-number selfRef">5.6.3. </a><a href="#name-send-quantum-csend_quantum" class="section-name selfRef">Send Quantum: C.send_quantum</a>
          </h4>
<p id="section-5.6.3-1">In order to amortize per-packet overheads involved in the sending process (host
CPU, NIC processing, and interrupt processing delays), high-performance
transport sender implementations (e.g., Linux TCP) often schedule an aggregate
containing multiple packets (multiple C.SMSS) worth of data as a single quantum
(using TSO, GSO, or other offload mechanisms). The BBR congestion control
algorithm makes this control decision explicitly, dynamically calculating a
quantum control parameter that specifies the maximum size of these transmission
aggregates. This decision is based on a trade-off:<a href="#section-5.6.3-1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-5.6.3-2.1">
              <p id="section-5.6.3-2.1.1">A smaller quantum is preferred at lower data rates because it results in
shorter packet bursts, shorter queues, lower queueing delays, and lower rates
of packet loss.<a href="#section-5.6.3-2.1.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-5.6.3-2.2">
              <p id="section-5.6.3-2.2.1">A bigger quantum can be required at higher data rates because it results
in lower CPU overheads at the sending and receiving hosts, who can ship larger
amounts of data with a single trip through the networking stack.<a href="#section-5.6.3-2.2.1" class="pilcrow">¶</a></p>
</li>
          </ul>
<p id="section-5.6.3-3">On each ACK, BBR runs BBRSetSendQuantum() to update C.send_quantum  as
follows:<a href="#section-5.6.3-3" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.3-4">
<pre>
  BBRSetSendQuantum():
    C.send_quantum = C.pacing_rate * 1ms
    C.send_quantum = min(C.send_quantum, 64 KBytes)
    C.send_quantum = max(C.send_quantum, 2 * C.SMSS)
</pre><a href="#section-5.6.3-4" class="pilcrow">¶</a>
</div>
<p id="section-5.6.3-5">A BBR implementation MAY use alternate approaches to select a C.send_quantum,
as appropriate for the CPU overheads anticipated for senders and receivers,
and buffering considerations anticipated in the network path. However, for
the sake of the network and other users, a BBR implementation SHOULD attempt
to use the smallest feasible quanta.<a href="#section-5.6.3-5" class="pilcrow">¶</a></p>
</section>
</div>
<div id="congestion-window">
<section id="section-5.6.4">
          <h4 id="name-congestion-window">
<a href="#section-5.6.4" class="section-number selfRef">5.6.4. </a><a href="#name-congestion-window" class="section-name selfRef">Congestion Window</a>
          </h4>
<p id="section-5.6.4-1">The congestion window (C.cwnd) controls the maximum C.inflight.
It is the maximum C.inflight
that the algorithm estimates is appropriate for matching the current
network path delivery process, given all available signals in the model,
at any time scale. BBR adapts C.cwnd based on its model of the network
path and the state machine's decisions about how to probe that path.<a href="#section-5.6.4-1" class="pilcrow">¶</a></p>
<p id="section-5.6.4-2">By default, BBR grows C.cwnd to meet its BBR.max_inflight, which models
what's required for achieving full throughput, and as such is scaled to adapt
to the estimated BDP computed from its path model. But BBR's selection of C.cwnd
is designed to explicitly trade off among competing considerations that
dynamically adapt to various conditions. So in loss recovery BBR more
conservatively adjusts its sending behavior based on more recent delivery
samples, and if BBR needs to re-probe the current BBR.min_rtt of the path then
it cuts C.cwnd accordingly. The following sections describe the various
considerations that impact C.cwnd.<a href="#section-5.6.4-2" class="pilcrow">¶</a></p>
<div id="initial-cwnd">
<section id="section-5.6.4.1">
            <h5 id="name-initial-cwnd">
<a href="#section-5.6.4.1" class="section-number selfRef">5.6.4.1. </a><a href="#name-initial-cwnd" class="section-name selfRef">Initial cwnd</a>
            </h5>
<p id="section-5.6.4.1-1">BBR generally uses measurements to build a model of the network path and
then adapts control decisions to the path based on that model. As such, the
selection of the initial cwnd is considered to be outside the scope of the
BBR algorithm, since at initialization there are no measurements yet upon
which BBR can operate. Thus, at initialization, BBR uses the transport sender
implementation's initial congestion window (e.g. from <span>[<a href="#RFC6298" class="cite xref">RFC6298</a>]</span> for TCP).<a href="#section-5.6.4.1-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="computing-bbrmaxinflight">
<section id="section-5.6.4.2">
            <h5 id="name-computing-bbrmax_inflight">
<a href="#section-5.6.4.2" class="section-number selfRef">5.6.4.2. </a><a href="#name-computing-bbrmax_inflight" class="section-name selfRef">Computing BBR.max_inflight</a>
            </h5>
<p id="section-5.6.4.2-1">The BBR BBR.max_inflight is the upper bound on the volume of data BBR allows in
flight. This bound is always in place, and dominates when all other
considerations have been satisfied: the flow is not in loss recovery, does not
need to probe BBR.min_rtt, and has accumulated confidence in its model
parameters by receiving enough ACKs to gradually grow the current C.cwnd to meet
the BBR.max_inflight.<a href="#section-5.6.4.2-1" class="pilcrow">¶</a></p>
<p id="section-5.6.4.2-2">On each ACK, BBR calculates the BBR.max_inflight in BBRUpdateMaxInflight()
as follows:<a href="#section-5.6.4.2-2" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.4.2-3">
<pre>
  BBRBDPMultiple(gain):
    if (BBR.min_rtt == Infinity)
      return C.InitialCwnd /* no valid RTT samples yet */
    BBR.bdp = BBR.bw * BBR.min_rtt
    return gain * BBR.bdp

  BBRQuantizationBudget(inflight_cap)
    BBRUpdateOffloadBudget()
    inflight_cap = max(inflight_cap, BBR.offload_budget)
    inflight_cap = max(inflight_cap, BBR.MinPipeCwnd)
    if (BBR.state == ProbeBW_UP)
      inflight_cap += 2*C.SMSS
    return inflight_cap

  BBRInflight(gain):
    inflight_cap = BBRBDPMultiple(gain)
    return BBRQuantizationBudget(inflight_cap)

  BBRUpdateMaxInflight():
    inflight_cap = BBRBDPMultiple(BBR.cwnd_gain)
    inflight_cap += BBR.extra_acked
    BBR.max_inflight = BBRQuantizationBudget(inflight_cap)
</pre><a href="#section-5.6.4.2-3" class="pilcrow">¶</a>
</div>
<p id="section-5.6.4.2-4">The "estimated_bdp" term tries to allow enough packets in flight to fully
utilize the estimated BDP of the path, by allowing the flow to send at BBR.bw
for a duration of BBR.min_rtt. Scaling up the BDP by BBR.cwnd_gain bounds
in-flight data to a small multiple of the BDP, to handle common network and
receiver behavior, such as delayed, stretched, or aggregated ACKs <span>[<a href="#A15" class="cite xref">A15</a>]</span>.
The "quanta" term allows enough quanta in flight on the sending and
receiving hosts to reach high throughput even in environments using
offload mechanisms.<a href="#section-5.6.4.2-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="minimum-cwnd-for-pipelining">
<section id="section-5.6.4.3">
            <h5 id="name-minimum-cwnd-for-pipelining">
<a href="#section-5.6.4.3" class="section-number selfRef">5.6.4.3. </a><a href="#name-minimum-cwnd-for-pipelining" class="section-name selfRef">Minimum cwnd for Pipelining</a>
            </h5>
<p id="section-5.6.4.3-1">For BBR.max_inflight, BBR imposes a floor of BBR.MinPipeCwnd (4 packets, i.e.
4 * C.SMSS). This floor helps ensure that even at very low BDPs, and with
a transport like TCP where a receiver may ACK only every alternate C.SMSS of
data, there are enough packets in flight to maintain full pipelining. In
particular BBR tries to allow at least 2 data packets in flight and ACKs
for at least 2 data packets on the path from receiver to sender.<a href="#section-5.6.4.3-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="modulating-cwnd-in-loss-recovery">
<section id="section-5.6.4.4">
            <h5 id="name-modulating-cwnd-in-loss-rec">
<a href="#section-5.6.4.4" class="section-number selfRef">5.6.4.4. </a><a href="#name-modulating-cwnd-in-loss-rec" class="section-name selfRef">Modulating cwnd in Loss Recovery</a>
            </h5>
<p id="section-5.6.4.4-1">BBR interprets loss as a hint that there may be recent changes in path behavior
that are not yet fully reflected in its model of the path, and thus it needs
to be more conservative.<a href="#section-5.6.4.4-1" class="pilcrow">¶</a></p>
<p id="section-5.6.4.4-2">Upon a retransmission timeout (RTO), BBR conservatively reduces C.cwnd to a
value that will allow 1 C.SMSS to be transmitted. Then BBR gradually increases
C.cwnd using the normal approach outlined below in "cwnd Adjustment Mechanism"
in <a href="#cwnd-adjustment-mechanism" class="auto internal xref">Section 5.6.4.6</a>.<a href="#section-5.6.4.4-2" class="pilcrow">¶</a></p>
<p id="section-5.6.4.4-3">When a BBR sender is in Fast Recovery it uses the response described in
"Updating the Model Upon Packet Loss" in
<a href="#updating-the-model-upon-packet-loss" class="auto internal xref">Section 5.5.10</a>.<a href="#section-5.6.4.4-3" class="pilcrow">¶</a></p>
<p id="section-5.6.4.4-4">When BBR exits loss recovery it restores C.cwnd to the "last known good"
value that C.cwnd held before entering recovery. This applies equally whether
the flow exits loss recovery because it finishes repairing all losses or
because it executes an "undo" event after inferring that a loss recovery
event was spurious.<a href="#section-5.6.4.4-4" class="pilcrow">¶</a></p>
<p id="section-5.6.4.4-5">The high-level design for updating C.cwnd in loss recovery is as follows:<a href="#section-5.6.4.4-5" class="pilcrow">¶</a></p>
<p id="section-5.6.4.4-6">Upon retransmission timeout (RTO):<a href="#section-5.6.4.4-6" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.4.4-7">
<pre>
  BBROnEnterRTO():
    BBRSaveCwnd()
    C.cwnd = C.inflight + 1
</pre><a href="#section-5.6.4.4-7" class="pilcrow">¶</a>
</div>
<p id="section-5.6.4.4-8">Upon entering Fast Recovery:<a href="#section-5.6.4.4-8" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.4.4-9">
<pre>
  BBROnEnterFastRecovery():
    BBRSaveCwnd()
</pre><a href="#section-5.6.4.4-9" class="pilcrow">¶</a>
</div>
<p id="section-5.6.4.4-10">Upon exiting loss recovery (RTO recovery or Fast Recovery), either by repairing
all losses or undoing recovery, BBR restores the best-known cwnd value we
had upon entering loss recovery:<a href="#section-5.6.4.4-10" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.4.4-11">
<pre>
  BBRRestoreCwnd()
</pre><a href="#section-5.6.4.4-11" class="pilcrow">¶</a>
</div>
<p id="section-5.6.4.4-12">Note that exiting loss recovery happens during ACK processing, and at the
end of ACK processing BBRBoundCwndForModel() will bound the cwnd based on
the current model parameters. Thus the cwnd and pacing rate after loss recovery
will generally be smaller than the values entering loss recovery.<a href="#section-5.6.4.4-12" class="pilcrow">¶</a></p>
<p id="section-5.6.4.4-13">The BBRSaveCwnd() and BBRRestoreCwnd() helpers help remember and restore
the last-known good C.cwnd (the latest C.cwnd unmodulated by loss recovery or
ProbeRTT), and is defined as follows:<a href="#section-5.6.4.4-13" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.4.4-14">
<pre>
  BBRSaveCwnd():
    if (!InLossRecovery() and BBR.state != ProbeRTT)
      BBR.prior_cwnd = C.cwnd
    else
      BBR.prior_cwnd = max(BBR.prior_cwnd, C.cwnd)

  BBRRestoreCwnd():
    C.cwnd = max(C.cwnd, BBR.prior_cwnd)
</pre><a href="#section-5.6.4.4-14" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="modulating-cwnd-in-probertt">
<section id="section-5.6.4.5">
            <h5 id="name-modulating-cwnd-in-probertt">
<a href="#section-5.6.4.5" class="section-number selfRef">5.6.4.5. </a><a href="#name-modulating-cwnd-in-probertt" class="section-name selfRef">Modulating cwnd in ProbeRTT</a>
            </h5>
<p id="section-5.6.4.5-1">If BBR decides it needs to enter the ProbeRTT state (see the "ProbeRTT" section
below), its goal is to quickly reduce C.inflight and drain
the bottleneck queue, thereby allowing measurement of BBR.min_rtt. To implement
this mode, BBR bounds C.cwnd to BBR.MinPipeCwnd, the minimal value that
allows pipelining (see the "Minimum cwnd for Pipelining" section, above):<a href="#section-5.6.4.5-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.4.5-2">
<pre>
  BBRProbeRTTCwnd():
    probe_rtt_cwnd = BBRBDPMultiple(BBR.bw, BBR.ProbeRTTCwndGain)
    probe_rtt_cwnd = max(probe_rtt_cwnd, BBR.MinPipeCwnd)
    return probe_rtt_cwnd

  BBRBoundCwndForProbeRTT():
    if (BBR.state == ProbeRTT)
      C.cwnd = min(C.cwnd, BBRProbeRTTCwnd())
</pre><a href="#section-5.6.4.5-2" class="pilcrow">¶</a>
</div>
</section>
</div>
<div id="cwnd-adjustment-mechanism">
<section id="section-5.6.4.6">
            <h5 id="name-cwnd-adjustment-mechanism">
<a href="#section-5.6.4.6" class="section-number selfRef">5.6.4.6. </a><a href="#name-cwnd-adjustment-mechanism" class="section-name selfRef">cwnd Adjustment Mechanism</a>
            </h5>
<p id="section-5.6.4.6-1">The network path and traffic traveling over it can make sudden dramatic
changes.  To adapt to these changes smoothly and robustly, and reduce packet
losses in such cases, BBR uses a conservative strategy. When C.cwnd is above the
BBR.max_inflight derived from BBR's path model, BBR cuts C.cwnd immediately
to the BBR.max_inflight. When C.cwnd is below BBR.max_inflight, BBR raises
C.cwnd gradually and cautiously, increasing C.cwnd by no more than the amount of
data acknowledged (cumulatively or selectively) upon each ACK.<a href="#section-5.6.4.6-1" class="pilcrow">¶</a></p>
<p id="section-5.6.4.6-2">Specifically, on each ACK that acknowledges "RS.newly_acked" packets as newly
acknowledged, BBR runs the following BBRSetCwnd() steps to update C.cwnd:<a href="#section-5.6.4.6-2" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.4.6-3">
<pre>
  BBRSetCwnd():
    BBRUpdateMaxInflight()
    if (BBR.full_bw_reached)
      C.cwnd = min(C.cwnd + RS.newly_acked, BBR.max_inflight)
    else if (C.cwnd &lt; BBR.max_inflight || C.delivered &lt; C.InitialCwnd)
      C.cwnd = C.cwnd + RS.newly_acked
    C.cwnd = max(C.cwnd, BBR.MinPipeCwnd)
    BBRBoundCwndForProbeRTT()
    BBRBoundCwndForModel()
</pre><a href="#section-5.6.4.6-3" class="pilcrow">¶</a>
</div>
<p id="section-5.6.4.6-4">There are several considerations embodied in the logic above. If BBR has
measured enough samples to achieve confidence that it has filled the pipe
(see the description of BBR.full_bw_reached in the "Startup" section below), then
it increases C.cwnd based on the number of packets delivered, while bounding
C.cwnd to be no larger than the BBR.max_inflight adapted to the estimated
BDP. Otherwise, if C.cwnd is below the BBR.max_inflight, or the sender
has marked so little data delivered (less than C.InitialCwnd) that it does not
yet judge its BBR.max_bw estimate and BBR.max_inflight as useful, then it increases
C.cwnd without bounding it to be below BBR.max_inflight. Finally, BBR imposes
a floor of BBR.MinPipeCwnd in order to allow pipelining even with small BDPs
(see the "Minimum cwnd for Pipelining" section, above).<a href="#section-5.6.4.6-4" class="pilcrow">¶</a></p>
</section>
</div>
<div id="bounding-cwnd-based-on-recent-congestion">
<section id="section-5.6.4.7">
            <h5 id="name-bounding-cwnd-based-on-rece">
<a href="#section-5.6.4.7" class="section-number selfRef">5.6.4.7. </a><a href="#name-bounding-cwnd-based-on-rece" class="section-name selfRef">Bounding cwnd Based on Recent Congestion</a>
            </h5>
<p id="section-5.6.4.7-1">Finally, BBR bounds C.cwnd based on recent congestion, as outlined in the
"Volume Cap" column of the table in the "Summary of Control Behavior in the
State Machine" section:<a href="#section-5.6.4.7-1" class="pilcrow">¶</a></p>
<div class="alignLeft art-text artwork" id="section-5.6.4.7-2">
<pre>
  BBRBoundCwndForModel():
    cap = Infinity
    if (IsInAProbeBWState() and
        BBR.state != ProbeBW_CRUISE)
      cap = BBR.inflight_longterm
    else if (BBR.state == ProbeRTT or
             BBR.state == ProbeBW_CRUISE)
      cap = BBRInflightWithHeadroom()

    /* apply BBR.inflight_shortterm (possibly infinite): */
    cap = min(cap, BBR.inflight_shortterm)
    cap = max(cap, BBR.MinPipeCwnd)
    C.cwnd = min(C.cwnd, cap)
</pre><a href="#section-5.6.4.7-2" class="pilcrow">¶</a>
</div>
</section>
</div>
</section>
</div>
</section>
</div>
</section>
</div>
<div id="implementation-status">
<section id="section-6">
      <h2 id="name-implementation-status">
<a href="#section-6" class="section-number selfRef">6. </a><a href="#name-implementation-status" class="section-name selfRef">Implementation Status</a>
      </h2>
<p id="section-6-1">This section records the status of known implementations of the algorithm
defined by this specification at the time of posting of this Internet-Draft,
and is based on a proposal described in <span>[<a href="#RFC7942" class="cite xref">RFC7942</a>]</span>.
The description of implementations in this section is intended to assist
the IETF in its decision processes in progressing drafts to RFCs. Please
note that the listing of any individual implementation here does not imply
endorsement by the IETF. Furthermore, no effort has been spent to verify
the information presented here that was supplied by IETF contributors. This
is not intended as, and must not be construed to be, a catalog of available
implementations or their features.  Readers are advised to note that other
implementations may exist.<a href="#section-6-1" class="pilcrow">¶</a></p>
<p id="section-6-2">According to <span>[<a href="#RFC7942" class="cite xref">RFC7942</a>]</span>, "this will allow reviewers and working groups to
assign due consideration to documents that have the benefit of running code,
which may serve as evidence of valuable experimentation and feedback that have
made the implemented protocols more mature.  It is up to the individual working
groups to use this information as they see fit".<a href="#section-6-2" class="pilcrow">¶</a></p>
<p id="section-6-3">As of the time of writing, the following implementations of BBRv3 have been
publicly released:<a href="#section-6-3" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-6-4.1">
          <p id="section-6-4.1.1">Linux TCP<a href="#section-6-4.1.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-6-4.1.2.1">
              <p id="section-6-4.1.2.1.1">Source code URL:<a href="#section-6-4.1.2.1.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-6-4.1.2.1.2.1">
                  <p id="section-6-4.1.2.1.2.1.1">https://github.com/google/bbr/blob/v3/README.md<a href="#section-6-4.1.2.1.2.1.1" class="pilcrow">¶</a></p>
</li>
                <li class="normal" id="section-6-4.1.2.1.2.2">
                  <p id="section-6-4.1.2.1.2.2.1">https://github.com/google/bbr/blob/v3/net/ipv4/tcp_bbr.c<a href="#section-6-4.1.2.1.2.2.1" class="pilcrow">¶</a></p>
</li>
              </ul>
</li>
            <li class="normal" id="section-6-4.1.2.2">
              <p id="section-6-4.1.2.2.1">Source: Google<a href="#section-6-4.1.2.2.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-4.1.2.3">
              <p id="section-6-4.1.2.3.1">Maturity: production<a href="#section-6-4.1.2.3.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-4.1.2.4">
              <p id="section-6-4.1.2.4.1">License: dual-licensed: GPLv2 / BSD<a href="#section-6-4.1.2.4.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-4.1.2.5">
              <p id="section-6-4.1.2.5.1">Contact: https://groups.google.com/d/forum/bbr-dev<a href="#section-6-4.1.2.5.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-4.1.2.6">
              <p id="section-6-4.1.2.6.1">Last updated: November 22, 2023<a href="#section-6-4.1.2.6.1" class="pilcrow">¶</a></p>
</li>
          </ul>
</li>
        <li class="normal" id="section-6-4.2">
          <p id="section-6-4.2.1">QUIC<a href="#section-6-4.2.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-6-4.2.2.1">
              <p id="section-6-4.2.2.1.1">Source code URLs:<a href="#section-6-4.2.2.1.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-6-4.2.2.1.2.1">
                  <p id="section-6-4.2.2.1.2.1.1">https://cs.chromium.org/chromium/src/net/third_party/quiche/src/quic/core/congestion_control/bbr2_sender.cc<a href="#section-6-4.2.2.1.2.1.1" class="pilcrow">¶</a></p>
</li>
                <li class="normal" id="section-6-4.2.2.1.2.2">
                  <p id="section-6-4.2.2.1.2.2.1">https://cs.chromium.org/chromium/src/net/third_party/quiche/src/quic/core/congestion_control/bbr2_sender.h<a href="#section-6-4.2.2.1.2.2.1" class="pilcrow">¶</a></p>
</li>
              </ul>
</li>
            <li class="normal" id="section-6-4.2.2.2">
              <p id="section-6-4.2.2.2.1">Source: Google<a href="#section-6-4.2.2.2.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-4.2.2.3">
              <p id="section-6-4.2.2.3.1">Maturity: production<a href="#section-6-4.2.2.3.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-4.2.2.4">
              <p id="section-6-4.2.2.4.1">License: BSD-style<a href="#section-6-4.2.2.4.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-4.2.2.5">
              <p id="section-6-4.2.2.5.1">Contact: https://groups.google.com/d/forum/bbr-dev<a href="#section-6-4.2.2.5.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-4.2.2.6">
              <p id="section-6-4.2.2.6.1">Last updated: October 21, 2021<a href="#section-6-4.2.2.6.1" class="pilcrow">¶</a></p>
</li>
          </ul>
</li>
      </ul>
<p id="section-6-5">As of the time of writing, the following implementations of the delivery
rate sampling algorithm have been publicly released:<a href="#section-6-5" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-6-6.1">
          <p id="section-6-6.1.1">Linux TCP<a href="#section-6-6.1.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-6-6.1.2.1">
              <p id="section-6-6.1.2.1.1">Source code URL:<a href="#section-6-6.1.2.1.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-6-6.1.2.1.2.1">
                  <p id="section-6-6.1.2.1.2.1.1">GPLv2 license: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/net/ipv4/tcp_rate.c<a href="#section-6-6.1.2.1.2.1.1" class="pilcrow">¶</a></p>
</li>
                <li class="normal" id="section-6-6.1.2.1.2.2">
                  <p id="section-6-6.1.2.1.2.2.1">BSD-style license: https://groups.google.com/d/msg/bbr-dev/X0LbDptlOzo/EVgkRjVHBQAJ<a href="#section-6-6.1.2.1.2.2.1" class="pilcrow">¶</a></p>
</li>
              </ul>
</li>
            <li class="normal" id="section-6-6.1.2.2">
              <p id="section-6-6.1.2.2.1">Source: Google<a href="#section-6-6.1.2.2.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-6.1.2.3">
              <p id="section-6-6.1.2.3.1">Maturity: production<a href="#section-6-6.1.2.3.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-6.1.2.4">
              <p id="section-6-6.1.2.4.1">License: dual-licensed: GPLv2 / BSD-style<a href="#section-6-6.1.2.4.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-6.1.2.5">
              <p id="section-6-6.1.2.5.1">Contact: https://groups.google.com/d/forum/bbr-dev<a href="#section-6-6.1.2.5.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-6.1.2.6">
              <p id="section-6-6.1.2.6.1">Last updated: September 24, 2021<a href="#section-6-6.1.2.6.1" class="pilcrow">¶</a></p>
</li>
          </ul>
</li>
        <li class="normal" id="section-6-6.2">
          <p id="section-6-6.2.1">QUIC<a href="#section-6-6.2.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-6-6.2.2.1">
              <p id="section-6-6.2.2.1.1">Source code URLs:<a href="#section-6-6.2.2.1.1" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-6-6.2.2.1.2.1">
                  <p id="section-6-6.2.2.1.2.1.1">https://github.com/google/quiche/blob/main/quiche/quic/core/congestion_control/bandwidth_sampler.cc<a href="#section-6-6.2.2.1.2.1.1" class="pilcrow">¶</a></p>
</li>
                <li class="normal" id="section-6-6.2.2.1.2.2">
                  <p id="section-6-6.2.2.1.2.2.1">https://github.com/google/quiche/blob/main/quiche/quic/core/congestion_control/bandwidth_sampler.h<a href="#section-6-6.2.2.1.2.2.1" class="pilcrow">¶</a></p>
</li>
              </ul>
</li>
            <li class="normal" id="section-6-6.2.2.2">
              <p id="section-6-6.2.2.2.1">Source: Google<a href="#section-6-6.2.2.2.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-6.2.2.3">
              <p id="section-6-6.2.2.3.1">Maturity: production<a href="#section-6-6.2.2.3.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-6.2.2.4">
              <p id="section-6-6.2.2.4.1">License: BSD-style<a href="#section-6-6.2.2.4.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-6.2.2.5">
              <p id="section-6-6.2.2.5.1">Contact: https://groups.google.com/d/forum/bbr-dev<a href="#section-6-6.2.2.5.1" class="pilcrow">¶</a></p>
</li>
            <li class="normal" id="section-6-6.2.2.6">
              <p id="section-6-6.2.2.6.1">Last updated: October 5, 2021<a href="#section-6-6.2.2.6.1" class="pilcrow">¶</a></p>
</li>
          </ul>
</li>
      </ul>
</section>
</div>
<div id="security-considerations">
<section id="section-7">
      <h2 id="name-security-considerations">
<a href="#section-7" class="section-number selfRef">7. </a><a href="#name-security-considerations" class="section-name selfRef">Security Considerations</a>
      </h2>
<p id="section-7-1">This proposal makes no changes to the underlying security of transport protocols
or congestion control algorithms. BBR shares the same security considerations
as the existing standard congestion control algorithm <span>[<a href="#RFC5681" class="cite xref">RFC5681</a>]</span>.<a href="#section-7-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="iana-considerations">
<section id="section-8">
      <h2 id="name-iana-considerations">
<a href="#section-8" class="section-number selfRef">8. </a><a href="#name-iana-considerations" class="section-name selfRef">IANA Considerations</a>
      </h2>
<p id="section-8-1">This document has no IANA actions. Here we are using that phrase, suggested
by <span>[<a href="#RFC8126" class="cite xref">RFC8126</a>]</span>, because BBR does not modify or extend the wire format of
any network protocol, nor does it add new dependencies on assigned numbers.
BBR involves only a change to the congestion control algorithm of a transport
sender, and does not involve changes in the network, the receiver, or any network
protocol.<a href="#section-8-1" class="pilcrow">¶</a></p>
<p id="section-8-2">Note to RFC Editor: this section may be removed on publication as an RFC.<a href="#section-8-2" class="pilcrow">¶</a></p>
</section>
</div>
<div id="acknowledgments">
<section id="section-9">
      <h2 id="name-acknowledgments">
<a href="#section-9" class="section-number selfRef">9. </a><a href="#name-acknowledgments" class="section-name selfRef">Acknowledgments</a>
      </h2>
<p id="section-9-1">The authors are grateful to Len Kleinrock for his work on the theory underlying
congestion control. We are indebted to Larry Brakmo for pioneering work on
the Vegas <span>[<a href="#BP95" class="cite xref">BP95</a>]</span> and New Vegas <span>[<a href="#B15" class="cite xref">B15</a>]</span> congestion control algorithms,
which presaged many elements of BBR, and for Larry's advice and guidance during
BBR's early development. The authors would also like to thank Kevin Yang,
Priyaranjan Jha, Yousuk Seung, Luke Hsiao for their work on TCP BBR; Jana Iyengar,
Victor Vasiliev, Bin Wu for their work on QUIC BBR; and Matt Mathis for his
research work on the BBR algorithm and its implications <span>[<a href="#MM19" class="cite xref">MM19</a>]</span>. We would also
like to thank C. Stephen Gunn, Eric Dumazet, Nandita Dukkipati, Pawel Jurczyk,
Biren Roy, David Wetherall, Amin Vahdat, Leonidas Kontothanassis,
and the YouTube, google.com, Bandwidth Enforcer, and Google SRE teams for
their invaluable help and support. We would like to thank Randall R. Stewart,
Jim Warner, Loganaden Velvindron, Hiren Panchasara, Adrian Zapletal, Christian
Huitema, Bao Zheng, Jonathan Morton, Matt Olson, Junho Choi, Carsten Bormann,
Pouria Mousavizadeh Tehrani, Amanda Baber, Frédéric Lécaille,
and Tatsuhiro Tsujikawa
for feedback, suggestions, and edits on earlier versions of this document.<a href="#section-9-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="sec-combined-references">
<section id="section-10">
      <h2 id="name-references">
<a href="#section-10" class="section-number selfRef">10. </a><a href="#name-references" class="section-name selfRef">References</a>
      </h2>
<div id="sec-normative-references">
<section id="section-10.1">
        <h3 id="name-normative-references">
<a href="#section-10.1" class="section-number selfRef">10.1. </a><a href="#name-normative-references" class="section-name selfRef">Normative References</a>
        </h3>
<dl class="references">
<dt id="RFC2018">[RFC2018]</dt>
        <dd>
<span class="refAuthor">Mathis, M.</span>, <span class="refAuthor">Mahdavi, J.</span>, <span class="refAuthor">Floyd, S.</span>, and <span class="refAuthor">A. Romanow</span>, <span class="refTitle">"TCP Selective Acknowledgment Options"</span>, <span class="seriesInfo">RFC 2018</span>, <span class="seriesInfo">DOI 10.17487/RFC2018</span>, <time datetime="1996-10" class="refDate">October 1996</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc2018">https://www.rfc-editor.org/rfc/rfc2018</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC2119">[RFC2119]</dt>
        <dd>
<span class="refAuthor">Bradner, S.</span>, <span class="refTitle">"Key words for use in RFCs to Indicate Requirement Levels"</span>, <span class="seriesInfo">BCP 14</span>, <span class="seriesInfo">RFC 2119</span>, <span class="seriesInfo">DOI 10.17487/RFC2119</span>, <time datetime="1997-03" class="refDate">March 1997</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc2119">https://www.rfc-editor.org/rfc/rfc2119</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC3168">[RFC3168]</dt>
        <dd>
<span class="refAuthor">Ramakrishnan, K.</span>, <span class="refAuthor">Floyd, S.</span>, and <span class="refAuthor">D. Black</span>, <span class="refTitle">"The Addition of Explicit Congestion Notification (ECN) to IP"</span>, <span class="seriesInfo">RFC 3168</span>, <span class="seriesInfo">DOI 10.17487/RFC3168</span>, <time datetime="2001-09" class="refDate">September 2001</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc3168">https://www.rfc-editor.org/rfc/rfc3168</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC4340">[RFC4340]</dt>
        <dd>
<span class="refAuthor">Kohler, E.</span>, <span class="refAuthor">Handley, M.</span>, and <span class="refAuthor">S. Floyd</span>, <span class="refTitle">"Datagram Congestion Control Protocol (DCCP)"</span>, <span class="seriesInfo">RFC 4340</span>, <span class="seriesInfo">DOI 10.17487/RFC4340</span>, <time datetime="2006-03" class="refDate">March 2006</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc4340">https://www.rfc-editor.org/rfc/rfc4340</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC5681">[RFC5681]</dt>
        <dd>
<span class="refAuthor">Allman, M.</span>, <span class="refAuthor">Paxson, V.</span>, and <span class="refAuthor">E. Blanton</span>, <span class="refTitle">"TCP Congestion Control"</span>, <span class="seriesInfo">RFC 5681</span>, <span class="seriesInfo">DOI 10.17487/RFC5681</span>, <time datetime="2009-09" class="refDate">September 2009</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc5681">https://www.rfc-editor.org/rfc/rfc5681</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC6298">[RFC6298]</dt>
        <dd>
<span class="refAuthor">Paxson, V.</span>, <span class="refAuthor">Allman, M.</span>, <span class="refAuthor">Chu, J.</span>, and <span class="refAuthor">M. Sargent</span>, <span class="refTitle">"Computing TCP's Retransmission Timer"</span>, <span class="seriesInfo">RFC 6298</span>, <span class="seriesInfo">DOI 10.17487/RFC6298</span>, <time datetime="2011-06" class="refDate">June 2011</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc6298">https://www.rfc-editor.org/rfc/rfc6298</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC6675">[RFC6675]</dt>
        <dd>
<span class="refAuthor">Blanton, E.</span>, <span class="refAuthor">Allman, M.</span>, <span class="refAuthor">Wang, L.</span>, <span class="refAuthor">Jarvinen, I.</span>, <span class="refAuthor">Kojo, M.</span>, and <span class="refAuthor">Y. Nishida</span>, <span class="refTitle">"A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP"</span>, <span class="seriesInfo">RFC 6675</span>, <span class="seriesInfo">DOI 10.17487/RFC6675</span>, <time datetime="2012-08" class="refDate">August 2012</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc6675">https://www.rfc-editor.org/rfc/rfc6675</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC6928">[RFC6928]</dt>
        <dd>
<span class="refAuthor">Chu, J.</span>, <span class="refAuthor">Dukkipati, N.</span>, <span class="refAuthor">Cheng, Y.</span>, and <span class="refAuthor">M. Mathis</span>, <span class="refTitle">"Increasing TCP's Initial Window"</span>, <span class="seriesInfo">RFC 6928</span>, <span class="seriesInfo">DOI 10.17487/RFC6928</span>, <time datetime="2013-04" class="refDate">April 2013</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc6928">https://www.rfc-editor.org/rfc/rfc6928</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC6937">[RFC6937]</dt>
        <dd>
<span class="refAuthor">Mathis, M.</span>, <span class="refAuthor">Dukkipati, N.</span>, and <span class="refAuthor">Y. Cheng</span>, <span class="refTitle">"Proportional Rate Reduction for TCP"</span>, <span class="seriesInfo">RFC 6937</span>, <span class="seriesInfo">DOI 10.17487/RFC6937</span>, <time datetime="2013-05" class="refDate">May 2013</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc6937">https://www.rfc-editor.org/rfc/rfc6937</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC7323">[RFC7323]</dt>
        <dd>
<span class="refAuthor">Borman, D.</span>, <span class="refAuthor">Braden, B.</span>, <span class="refAuthor">Jacobson, V.</span>, and <span class="refAuthor">R. Scheffenegger, Ed.</span>, <span class="refTitle">"TCP Extensions for High Performance"</span>, <span class="seriesInfo">RFC 7323</span>, <span class="seriesInfo">DOI 10.17487/RFC7323</span>, <time datetime="2014-09" class="refDate">September 2014</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc7323">https://www.rfc-editor.org/rfc/rfc7323</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC7942">[RFC7942]</dt>
        <dd>
<span class="refAuthor">Sheffer, Y.</span> and <span class="refAuthor">A. Farrel</span>, <span class="refTitle">"Improving Awareness of Running Code: The Implementation Status Section"</span>, <span class="seriesInfo">BCP 205</span>, <span class="seriesInfo">RFC 7942</span>, <span class="seriesInfo">DOI 10.17487/RFC7942</span>, <time datetime="2016-07" class="refDate">July 2016</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc7942">https://www.rfc-editor.org/rfc/rfc7942</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC8126">[RFC8126]</dt>
        <dd>
<span class="refAuthor">Cotton, M.</span>, <span class="refAuthor">Leiba, B.</span>, and <span class="refAuthor">T. Narten</span>, <span class="refTitle">"Guidelines for Writing an IANA Considerations Section in RFCs"</span>, <span class="seriesInfo">BCP 26</span>, <span class="seriesInfo">RFC 8126</span>, <span class="seriesInfo">DOI 10.17487/RFC8126</span>, <time datetime="2017-06" class="refDate">June 2017</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc8126">https://www.rfc-editor.org/rfc/rfc8126</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC8511">[RFC8511]</dt>
        <dd>
<span class="refAuthor">Khademi, N.</span>, <span class="refAuthor">Welzl, M.</span>, <span class="refAuthor">Armitage, G.</span>, and <span class="refAuthor">G. Fairhurst</span>, <span class="refTitle">"TCP Alternative Backoff with ECN (ABE)"</span>, <span class="seriesInfo">RFC 8511</span>, <span class="seriesInfo">DOI 10.17487/RFC8511</span>, <time datetime="2018-12" class="refDate">December 2018</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc8511">https://www.rfc-editor.org/rfc/rfc8511</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC8985">[RFC8985]</dt>
        <dd>
<span class="refAuthor">Cheng, Y.</span>, <span class="refAuthor">Cardwell, N.</span>, <span class="refAuthor">Dukkipati, N.</span>, and <span class="refAuthor">P. Jha</span>, <span class="refTitle">"The RACK-TLP Loss Detection Algorithm for TCP"</span>, <span class="seriesInfo">RFC 8985</span>, <span class="seriesInfo">DOI 10.17487/RFC8985</span>, <time datetime="2021-02" class="refDate">February 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc8985">https://www.rfc-editor.org/rfc/rfc8985</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC9000">[RFC9000]</dt>
        <dd>
<span class="refAuthor">Iyengar, J., Ed.</span> and <span class="refAuthor">M. Thomson, Ed.</span>, <span class="refTitle">"QUIC: A UDP-Based Multiplexed and Secure Transport"</span>, <span class="seriesInfo">RFC 9000</span>, <span class="seriesInfo">DOI 10.17487/RFC9000</span>, <time datetime="2021-05" class="refDate">May 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc9000">https://www.rfc-editor.org/rfc/rfc9000</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC9002">[RFC9002]</dt>
        <dd>
<span class="refAuthor">Iyengar, J., Ed.</span> and <span class="refAuthor">I. Swett, Ed.</span>, <span class="refTitle">"QUIC Loss Detection and Congestion Control"</span>, <span class="seriesInfo">RFC 9002</span>, <span class="seriesInfo">DOI 10.17487/RFC9002</span>, <time datetime="2021-05" class="refDate">May 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc9002">https://www.rfc-editor.org/rfc/rfc9002</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC9293">[RFC9293]</dt>
        <dd>
<span class="refAuthor">Eddy, W., Ed.</span>, <span class="refTitle">"Transmission Control Protocol (TCP)"</span>, <span class="seriesInfo">STD 7</span>, <span class="seriesInfo">RFC 9293</span>, <span class="seriesInfo">DOI 10.17487/RFC9293</span>, <time datetime="2022-08" class="refDate">August 2022</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc9293">https://www.rfc-editor.org/rfc/rfc9293</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC9330">[RFC9330]</dt>
        <dd>
<span class="refAuthor">Briscoe, B., Ed.</span>, <span class="refAuthor">De Schepper, K.</span>, <span class="refAuthor">Bagnulo, M.</span>, and <span class="refAuthor">G. White</span>, <span class="refTitle">"Low Latency, Low Loss, and Scalable Throughput (L4S) Internet Service: Architecture"</span>, <span class="seriesInfo">RFC 9330</span>, <span class="seriesInfo">DOI 10.17487/RFC9330</span>, <time datetime="2023-01" class="refDate">January 2023</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc9330">https://www.rfc-editor.org/rfc/rfc9330</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC9438">[RFC9438]</dt>
      <dd>
<span class="refAuthor">Xu, L.</span>, <span class="refAuthor">Ha, S.</span>, <span class="refAuthor">Rhee, I.</span>, <span class="refAuthor">Goel, V.</span>, and <span class="refAuthor">L. Eggert, Ed.</span>, <span class="refTitle">"CUBIC for Fast and Long-Distance Networks"</span>, <span class="seriesInfo">RFC 9438</span>, <span class="seriesInfo">DOI 10.17487/RFC9438</span>, <time datetime="2023-08" class="refDate">August 2023</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc9438">https://www.rfc-editor.org/rfc/rfc9438</a>&gt;</span>. </dd>
<dd class="break"></dd>
</dl>
</section>
</div>
<div id="sec-informative-references">
<section id="section-10.2">
        <h3 id="name-informative-references">
<a href="#section-10.2" class="section-number selfRef">10.2. </a><a href="#name-informative-references" class="section-name selfRef">Informative References</a>
        </h3>
<dl class="references">
<dt id="A15">[A15]</dt>
        <dd>
<span class="refAuthor">Abrahamsson, M.</span>, <span class="refTitle">"TCP ACK suppression"</span>, <span class="refContent">IETF AQM mailing list</span>, <time datetime="2015-11" class="refDate">November 2015</time>, <span>&lt;<a href="https://www.ietf.org/mail-archive/web/aqm/current/msg01480.html">https://www.ietf.org/mail-archive/web/aqm/current/msg01480.html</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="B15">[B15]</dt>
        <dd>
<span class="refAuthor">Brakmo, L.</span>, <span class="refTitle">"TCP-NV: An Update to TCP-Vegas"</span>, <span class="seriesInfo"></span>, <time datetime="2015-08" class="refDate">August 2015</time>, <span>&lt;<a href="https://docs.google.com/document/d/1o-53jbO_xH-m9g2YCgjaf5bK8vePjWP6Mk0rYiRLK-U/edit">https://docs.google.com/document/d/1o-53jbO_xH-m9g2YCgjaf5bK8vePjWP6Mk0rYiRLK-U/edit</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="BBRDrainPacingGain">[BBRDrainPacingGain]</dt>
        <dd>
<span class="refAuthor">Cardwell, N.</span>, <span class="refAuthor">Cheng, Y.</span>, <span class="refAuthor">Hassas Yeganeh, S.</span>, and <span class="refAuthor">V. Jacobson</span>, <span class="refTitle">"BBR Drain Pacing Gain: a Derivation"</span>, <time datetime="2021-09" class="refDate">September 2021</time>, <span>&lt;<a href="https://github.com/google/bbr/blob/master/Documentation/startup/gain/analysis/bbr_drain_gain.pdf">https://github.com/google/bbr/blob/master/Documentation/startup/gain/analysis/bbr_drain_gain.pdf</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="BBRStartupCwndGain">[BBRStartupCwndGain]</dt>
        <dd>
<span class="refAuthor">Swett, I.</span>, <span class="refAuthor">Cardwell, N.</span>, <span class="refAuthor">Cheng, Y.</span>, <span class="refAuthor">Hassas Yeganeh, S.</span>, and <span class="refAuthor">V. Jacobson</span>, <span class="refTitle">"BBR Startup cwnd Gain: a Derivation"</span>, <time datetime="2018-07" class="refDate">July 2018</time>, <span>&lt;<a href="https://github.com/google/bbr/blob/master/Documentation/startup/gain/analysis/bbr_startup_cwnd_gain.pdf">https://github.com/google/bbr/blob/master/Documentation/startup/gain/analysis/bbr_startup_cwnd_gain.pdf</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="BBRStartupPacingGain">[BBRStartupPacingGain]</dt>
        <dd>
<span class="refAuthor">Cardwell, N.</span>, <span class="refAuthor">Cheng, Y.</span>, <span class="refAuthor">Hassas Yeganeh, S.</span>, and <span class="refAuthor">V. Jacobson</span>, <span class="refTitle">"BBR Startup Pacing Gain: a Derivation"</span>, <time datetime="2018-06" class="refDate">June 2018</time>, <span>&lt;<a href="https://github.com/google/bbr/blob/master/Documentation/startup/gain/analysis/bbr_startup_gain.pdf">https://github.com/google/bbr/blob/master/Documentation/startup/gain/analysis/bbr_startup_gain.pdf</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="BP95">[BP95]</dt>
        <dd>
<span class="refAuthor">Brakmo, L.</span> and <span class="refAuthor">L. Peterson</span>, <span class="refTitle">"TCP Vegas: end-to-end congestion avoidance on a global Internet"</span>, <span class="seriesInfo">IEEE Journal on Selected Areas in Communications 13(8): 1465-1480 </span>, <time datetime="1995-10" class="refDate">October 1995</time>. </dd>
<dd class="break"></dd>
<dt id="CCGHJ16">[CCGHJ16]</dt>
        <dd>
<span class="refAuthor">Cardwell, N.</span>, <span class="refAuthor">Cheng, Y.</span>, <span class="refAuthor">Gunn, C.</span>, <span class="refAuthor">Hassas Yeganeh, S.</span>, and <span class="refAuthor">V. Jacobson</span>, <span class="refTitle">"BBR: Congestion-Based Congestion Control"</span>, <span class="seriesInfo">ACM Queue Oct 2016</span>, <time datetime="2016-10" class="refDate">October 2016</time>, <span>&lt;<a href="http://queue.acm.org/detail.cfm?id=3022184">http://queue.acm.org/detail.cfm?id=3022184</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="CCGHJ17">[CCGHJ17]</dt>
        <dd>
<span class="refAuthor">Cardwell, N.</span>, <span class="refAuthor">Cheng, Y.</span>, <span class="refAuthor">Gunn, C.</span>, <span class="refAuthor">Hassas Yeganeh, S.</span>, and <span class="refAuthor">V. Jacobson</span>, <span class="refTitle">"BBR: Congestion-Based Congestion Control"</span>, <span class="seriesInfo">Communications of the ACM Feb 2017</span>, <time datetime="2017-02" class="refDate">February 2017</time>, <span>&lt;<a href="https://cacm.acm.org/magazines/2017/2/212428-bbr-congestion-based-congestion-control/pdf">https://cacm.acm.org/magazines/2017/2/212428-bbr-congestion-based-congestion-control/pdf</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="draft-romo-iccrg-ccid5">[draft-romo-iccrg-ccid5]</dt>
        <dd>
<span class="refAuthor">Moreno, N. R.</span>, <span class="refAuthor">Kim, J.</span>, and <span class="refAuthor">M. Amend</span>, <span class="refTitle">"Profile for Datagram Congestion Control Protocol (DCCP) Congestion Control ID 5"</span>, <span class="refContent">Work in Progress</span>, <span class="seriesInfo">Internet-Draft, draft-romo-iccrg-ccid5-00</span>, <time datetime="2021-10-25" class="refDate">25 October 2021</time>, <span>&lt;<a href="https://datatracker.ietf.org/doc/html/draft-romo-iccrg-ccid5-00">https://datatracker.ietf.org/doc/html/draft-romo-iccrg-ccid5-00</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="GK81">[GK81]</dt>
        <dd>
<span class="refAuthor">Gail, R.</span> and <span class="refAuthor">L. Kleinrock</span>, <span class="refTitle">"An Invariant Property of Computer Network Power"</span>, <span class="seriesInfo">Proceedings of the International Conference on Communications June, 1981</span>, <span>&lt;<a href="http://www.lk.cs.ucla.edu/data/files/Gail/power.pdf">http://www.lk.cs.ucla.edu/data/files/Gail/power.pdf</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="HRX08">[HRX08]</dt>
        <dd>
<span class="refAuthor">Ha, S.</span>, <span class="refAuthor">Rhee, I.</span>, and <span class="refAuthor">L. Xu</span>, <span class="refTitle">"CUBIC: A New TCP-Friendly High-Speed TCP Variant"</span>, <span class="seriesInfo">ACM SIGOPS Operating System Review </span>, <time datetime="2008" class="refDate">2008</time>. </dd>
<dd class="break"></dd>
<dt id="Jac88">[Jac88]</dt>
        <dd>
<span class="refAuthor">Jacobson, V.</span>, <span class="refTitle">"Congestion Avoidance and Control"</span>, <span class="seriesInfo">SIGCOMM 1988, Computer Communication Review, vol. 18, no. 4, pp. 314-329 </span>, <time datetime="1988-08" class="refDate">August 1988</time>, <span>&lt;<a href="http://ee.lbl.gov/papers/congavoid.pdf">http://ee.lbl.gov/papers/congavoid.pdf</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="Jac90">[Jac90]</dt>
        <dd>
<span class="refAuthor">Jacobson, V.</span>, <span class="refTitle">"Modified TCP Congestion Avoidance Algorithm"</span>, <span class="seriesInfo">end2end-interest mailing list </span>, <time datetime="1990-04" class="refDate">April 1990</time>, <span>&lt;<a href="ftp://ftp.isi.edu/end2end/end2end-interest-1990.mail">ftp://ftp.isi.edu/end2end/end2end-interest-1990.mail</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="K79">[K79]</dt>
        <dd>
<span class="refAuthor">Kleinrock, L.</span>, <span class="refTitle">"Power and deterministic rules of thumb for probabilistic problems in computer communications"</span>, <span class="seriesInfo">Proceedings of the International Conference on Communications 1979</span>. </dd>
<dd class="break"></dd>
<dt id="MM19">[MM19]</dt>
        <dd>
<span class="refAuthor">Mathis, M.</span> and <span class="refAuthor">J. Mahdavi</span>, <span class="refTitle">"Deprecating The TCP Macroscopic Model"</span>, <span class="seriesInfo">Computer Communication Review, vol. 49, no. 5, pp. 63-68 </span>, <time datetime="2019-10" class="refDate">October 2019</time>. </dd>
<dd class="break"></dd>
<dt id="RFC8311">[RFC8311]</dt>
        <dd>
<span class="refAuthor">Black, D.</span>, <span class="refTitle">"Relaxing Restrictions on Explicit Congestion Notification (ECN) Experimentation"</span>, <span class="seriesInfo">RFC 8311</span>, <span class="seriesInfo">DOI 10.17487/RFC8311</span>, <time datetime="2018-01" class="refDate">January 2018</time>, <span>&lt;<a href="https://www.rfc-editor.org/rfc/rfc8311">https://www.rfc-editor.org/rfc/rfc8311</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="WS95">[WS95]</dt>
      <dd>
<span class="refAuthor">Wright, G.</span> and <span class="refAuthor">W. Stevens</span>, <span class="refTitle">"TCP/IP Illustrated, Volume 2: The Implementation"</span>, <span class="seriesInfo">Addison-Wesley </span>, <time datetime="1995" class="refDate">1995</time>. </dd>
<dd class="break"></dd>
</dl>
</section>
</div>
</section>
</div>
<div id="authors-addresses">
<section id="appendix-A">
      <h2 id="name-authors-addresses">
<a href="#name-authors-addresses" class="section-name selfRef">Authors' Addresses</a>
      </h2>
<address class="vcard">
        <div dir="auto" class="left"><span class="fn nameRole">Neal Cardwell (<span class="role">editor</span>)</span></div>
<div dir="auto" class="left"><span class="org">Google</span></div>
<div class="email">
<span>Email:</span>
<a href="mailto:ncardwell@google.com" class="email">ncardwell@google.com</a>
</div>
</address>
<address class="vcard">
        <div dir="auto" class="left"><span class="fn nameRole">Ian Swett (<span class="role">editor</span>)</span></div>
<div dir="auto" class="left"><span class="org">Google</span></div>
<div class="email">
<span>Email:</span>
<a href="mailto:ianswett@google.com" class="email">ianswett@google.com</a>
</div>
</address>
<address class="vcard">
        <div dir="auto" class="left"><span class="fn nameRole">Joseph Beshay (<span class="role">editor</span>)</span></div>
<div dir="auto" class="left"><span class="org">Meta</span></div>
<div class="email">
<span>Email:</span>
<a href="mailto:jbeshay@meta.com" class="email">jbeshay@meta.com</a>
</div>
</address>
</section>
</div>
<script>const toc = document.getElementById("toc");
toc.querySelector("h2").addEventListener("click", e => {
  toc.classList.toggle("active");
});
toc.querySelector("nav").addEventListener("click", e => {
  toc.classList.remove("active");
});
</script>
</body>
</html>
